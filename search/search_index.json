{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A tiny, modern kernel for Raspberry Pi 3 Experiment descriptions are for you to read & reproduce. The assignments will be on Collab. They include Q&A and coding assignments. Get the code : git clone https://github.com/fxlin/p1-kernel A tiny kernel incrementally built for OS education. Start with minimal, baremetal code. Then add kernel features in small doses. Each experiment is a self-contained and can run on both Rpi3 hardware and QEMU. Rationale The kernel must run on cheap & modern hardware. Showing the kernel's evolution path is important. Along the path, each version must be self-contained runnable. We deem the following kernel functions crucial to implement: * protection modes * interrupt handling * preemptive scheduling * virtual memory Experimenting with these features is difficult with commodity kernels due to their complexity. Goals Primary: * Learning by doing: the core concepts of a modern OS kernel * Experiencing OS engineering: hands-on programming & debugging at the hardware/software boundary * Daring to plumb: working with baremetal hardware: CPU protection modes, registers, IO, MMU, etc. Secondary: * Armv8 programming. Arm is everywhere, including future Mac. * Working with C and assembly * Cross-platform development Non-goals: Non-core or advanced functions of OS kernel, e.g. filesystem or power management, which can be learnt via experimenting with commodity OS. Rpi3-specific hardware details. The SoC of Rpi3 is notoriously unfriendly to kernel hackers. Implementation details of commodity kernels, e.g. Linux or Windows. Experiments Sharpen your tools! (p1 exp0) Helloworld from baremetal (p1 exp1) Power on + UART bring up Simplifying dev workflow Exception elevated (p1 exp2) CPU initialization, exception levels Heartbeats on (p1 exp3) Interrupt handling Interrupt-driven animation Process scheduler (p1 exp4) A. Cooperative B. Preemptive A world of two lands (p1 exp5) User processes and system calls Into virtual (p1 exp6) Virtual memory management Assignment weights Exp Weights 00 Sharpen your tools 10 01 Helloworld from baremetal 10 02 Exception elevated 10 03 Heartbeats on 10 04a Process scheduler - cooperative 10 04b Process scheduler - preemptive 10 05 A world of two lands 20 06 Into virtual 20 The weights are relative and may not necessarily add up to 100. Acknowledgement Derived from the RPi OS project and its tutorials, which is modeled after the Linux kernel .","title":"A tiny, modern kernel for Raspberry Pi 3"},{"location":"#a-tiny-modern-kernel-for-raspberry-pi-3","text":"Experiment descriptions are for you to read & reproduce. The assignments will be on Collab. They include Q&A and coding assignments. Get the code : git clone https://github.com/fxlin/p1-kernel A tiny kernel incrementally built for OS education. Start with minimal, baremetal code. Then add kernel features in small doses. Each experiment is a self-contained and can run on both Rpi3 hardware and QEMU.","title":"A tiny, modern kernel for Raspberry Pi 3"},{"location":"#rationale","text":"The kernel must run on cheap & modern hardware. Showing the kernel's evolution path is important. Along the path, each version must be self-contained runnable. We deem the following kernel functions crucial to implement: * protection modes * interrupt handling * preemptive scheduling * virtual memory Experimenting with these features is difficult with commodity kernels due to their complexity.","title":"Rationale"},{"location":"#goals","text":"Primary: * Learning by doing: the core concepts of a modern OS kernel * Experiencing OS engineering: hands-on programming & debugging at the hardware/software boundary * Daring to plumb: working with baremetal hardware: CPU protection modes, registers, IO, MMU, etc. Secondary: * Armv8 programming. Arm is everywhere, including future Mac. * Working with C and assembly * Cross-platform development Non-goals: Non-core or advanced functions of OS kernel, e.g. filesystem or power management, which can be learnt via experimenting with commodity OS. Rpi3-specific hardware details. The SoC of Rpi3 is notoriously unfriendly to kernel hackers. Implementation details of commodity kernels, e.g. Linux or Windows.","title":"Goals"},{"location":"#experiments","text":"Sharpen your tools! (p1 exp0) Helloworld from baremetal (p1 exp1) Power on + UART bring up Simplifying dev workflow Exception elevated (p1 exp2) CPU initialization, exception levels Heartbeats on (p1 exp3) Interrupt handling Interrupt-driven animation Process scheduler (p1 exp4) A. Cooperative B. Preemptive A world of two lands (p1 exp5) User processes and system calls Into virtual (p1 exp6) Virtual memory management","title":"Experiments"},{"location":"#assignment-weights","text":"Exp Weights 00 Sharpen your tools 10 01 Helloworld from baremetal 10 02 Exception elevated 10 03 Heartbeats on 10 04a Process scheduler - cooperative 10 04b Process scheduler - preemptive 10 05 A world of two lands 20 06 Into virtual 20 The weights are relative and may not necessarily add up to 100.","title":"Assignment weights"},{"location":"#acknowledgement","text":"Derived from the RPi OS project and its tutorials, which is modeled after the Linux kernel .","title":"Acknowledgement"},{"location":"cheatsheet/","text":"ARMv8 cheat sheet General purpose registers x0 - x30: 64-bit general purpose registers, where: x0-x18. callee can corrupt x0-x7 Arguments and return values. additional arguments are on the stack x8: Indirect result. For syscalls, the syscall number is in r8 x19-x29: callee must preserve x9-x28: caller-saved registers. In general okay to use in your code x29 (FP): frame pointer, pointing to the base of the current stack frame x30 (LR): link register SP Stack pointer PC Program counter Our GDB customization color-codes the registers. White highlight (x0-x7): parameter/results; red background (x19-x29): callee saved. (Green reg values: the values have changed since the last instruction) Special purpose registers Control and Translation Registers SCTLR EL{1..3} System Control ACTLR EL{1..3} Auxiliary Control 64 CPACR EL1 Architectural Feature Access Control HCR EL2 Hypervisor Configuration 64 CPTR EL{2,3} Architectural Feature Trap HSTR EL2 Hypervisor System Trap HACR EL2 Hypervisor Auxiliary Control SCR EL3 Secure Configuration TTBR0 EL{1..3} Translation Table Base 0 (4/16/64kb aligned) 64 TTBR1 EL1 Translation Table Base 1 (4/16/64kb aligned) 64 TCR EL{1..3} Translation Control 64 VTTBR EL2 Virt Translation Table Base (4/16/64kb aligned) 64 VTCR EL2 Virt Translation Control {A}MAIR EL{1..3} {Auxiliary} Memory Attribute Indirection 64 LOR{S,E}A EL1 LORegion {Start,End} Address 64,1 LOR{C,N,ID} EL1 LORegion {Control,Number,ID} 64,1 System Control Register (SCTLR) M 0x00000001 MMU enabled A 0x00000002 Alignment check enabled C 0x00000004 Data and unified caches enabled SA 0x00000008 Enable SP alignment check SA0 0x00000010 Enable SP alignment check for EL0 E1 UMA 0x00000200 Trap EL0 access of DAIF to EL1 E1 I 0x00001000 Instruction cache enabled DZE 0x00004000 Trap EL0 DC instruction to EL1 E1 UCT 0x00008000 Trap EL0 access of CTR EL0 to EL1 E1 nTWI 0x00010000 Trap EL0 WFI instruction to EL1 E1 nTWE 0x00040000 Trap EL0 WFE instruction to EL1 E1 WXN 0x00080000 Write permission implies XN SPAN 0x00800000 Set privileged access never E1,1 E0E 0x01000000 Data at EL0 is big-endian E1 EE 0x02000000 Data at EL1 is big-endian UCI 0x04000000 Trap EL0 cache instructions to EL1 E1 Secure Configuration Registers (SCR) NS 0x0001 System state is non-secure unless in EL3 IRQ 0x0002 IRQs taken to EL3 FIQ 0x0004 FIQs taken to EL3 EA 0x0008 External aborts and SError taken to EL3 SMD 0x0080 Secure monitor call disable HCE 0x0100 Hyp Call enable SIF 0x0200 Secure instruction fetch RW 0x0400 Lower level is AArch64 ST 0x0800 Trap secure EL1 to CNTPS registers to EL3 TWI 0x1000 Trap EL{0..2} WFI instruction to EL3 TWE 0x2000 Trap EL{0..2} WFE instruction to EL3 TLOR 0x4000 Trap LOR registers 1 Generic Timer Registers CNTFRQ EL0 Ct Frequency (in Hz) CNT{P,V}CT EL0 Ct {Physical,Virtual} Count RO,64 CNTVOFF EL2 Ct Virtual Offset 64 CNTHCTL EL2 Ct Hypervisor Control CNTKCTL EL1 Ct Kernel Control CNT{P,V} {TVAL,CTL,CVAL} EL0 Ct {Physical,Virtual} Timer CNTHP {TVAL,CTL,CVAL} EL2 Ct Hypervisor Physical Timer CNTPS {TVAL,CTL,CVAL} EL1 Ct Physical Secure Timer CNTHV {TVAL,CTL,CVAL} EL2 Ct Virtual Timer 1 Exception levels AArch64/ARMv8 name remarks EL3 highest exception level, mostly for firmware EL2 exception level for hypervisors like Xen (or parts of KVM) EL1 the Linux kernel is running in this EL0 for unprivileged userland Exception vectors EL1t Exception is taken from EL1 while stack pointer was shared with EL0. This happens when SPSel register holds the value 0. EL1h Exception is taken from EL1 at the time when dedicated stack pointer was allocated for EL1. This means that SPSel holds the value 1 and this is the mode that we are currently using. EL0_64 Exception is taken from EL0 executing in 64-bit mode. EL0_32 Exception is taken from EL0 executing in 32-bit mode. PSTATE See \"Fundamentals of ARMv8-A\", Chapter \"Processor state\" Return from exceptions ELR_EL1 , Exception Link Register. \"When taking an exception to EL1, holds the address to return to.\" SPSR_EL1, status regs, including irq enable/disable eret . Returns from an exception. It restores the processor state based on SPSR_ELn and branches to ELR_ELn, where n is the current exception level. Common instructions A more detailed instruction quick reference mrs Load value from a system register to one of the general purpose registers (x0\u2013x30) and Perform the logical AND operation. cbz Compare the result of the previously executed operation to 0 and jump (or branch in ARM terminology) to the provided label if the comparison yields true. b Perform an unconditional branch to some label. adr Load a label's relative address into the target register. In this case, we want pointers to the start and end of the .bss region. sub Subtract values from two registers. bl \"Branch with a link\": perform an unconditional branch and store the return address in x30 (the link register). When the subroutine is finished, use the ret instruction to jump back to the return address. mov Move a value between registers or from a constant to a register. cbz, cbnz Compare and Branch on Zero, Compare and Branch on Non-Zero. stp store a pair of registers Condition Codes EQ Equal Z NE Not equal !Z CS/HS Carry set, Unsigned higher or same C CC/LO Carry clear, Unsigned lower !C MI Minus, Negative N PL Plus, Positive or zero !N VS Overflow V VC No overflow !V HI Unsigned higher C & !Z LS Unsigned lower or same !C | Z GE Signed greater than or equal N = V LT Signed less than N /= V GT Signed greater than !Z & N = V LE Signed less than or equal Z | N /= V AL Always (default) 1 Architecture naming There is an updated ARM architecture revision called \"ARMv8\", which evolved from the ARMv7 architecture. Among other things it introduces a new execution state called \"AArch64\", which provides a full 64-bit architecture. ARMv8 compliant implementations can provide this state or not, also they are free to implement the \"AArch32\" state, which closely resembles the ARMv7 architecture. So both 32-bit and 64-bit states are optional - but you should of course have at least one ;-). ARM Cortex cores provide both states, while there are implementations from other vendors which do not provide AArch32, for instance. The Linux kernel chose to call this new architecture \"arm64\", the same name got picked up by Debian for their architecture port name. The GNU toolchain however elected the official \"aarch64\" name for the port, so the GCC (cross-)compiler is usually called \"aarch64-linux-gnu-gcc\". So although the arm64 name is not official, it can be used interchangeably for aarch64. References This page incorporates many contents from various sources. \"arm64 assembly crash course\", https://github.com/Siguza/ios-resources/blob/master/bits/arm64.md https://linux-sunxi.org/Arm64#ARM64_cheat_sheet https://wiki.cdot.senecacollege.ca/wiki/AArch64_Register_and_Instruction_Quick_Start https://tc.gts3.org/cs3210/2020/spring/r/AArch64-ISA-Cheat-Sheet.pdf \"ARMv8 A64 Quick Reference\", https://github.com/flynd/asmsheets","title":"/aarch64"},{"location":"cheatsheet/#armv8-cheat-sheet","text":"","title":"ARMv8 cheat sheet"},{"location":"cheatsheet/#general-purpose-registers","text":"x0 - x30: 64-bit general purpose registers, where: x0-x18. callee can corrupt x0-x7 Arguments and return values. additional arguments are on the stack x8: Indirect result. For syscalls, the syscall number is in r8 x19-x29: callee must preserve x9-x28: caller-saved registers. In general okay to use in your code x29 (FP): frame pointer, pointing to the base of the current stack frame x30 (LR): link register SP Stack pointer PC Program counter Our GDB customization color-codes the registers. White highlight (x0-x7): parameter/results; red background (x19-x29): callee saved. (Green reg values: the values have changed since the last instruction)","title":"General purpose registers"},{"location":"cheatsheet/#special-purpose-registers","text":"Control and Translation Registers SCTLR EL{1..3} System Control ACTLR EL{1..3} Auxiliary Control 64 CPACR EL1 Architectural Feature Access Control HCR EL2 Hypervisor Configuration 64 CPTR EL{2,3} Architectural Feature Trap HSTR EL2 Hypervisor System Trap HACR EL2 Hypervisor Auxiliary Control SCR EL3 Secure Configuration TTBR0 EL{1..3} Translation Table Base 0 (4/16/64kb aligned) 64 TTBR1 EL1 Translation Table Base 1 (4/16/64kb aligned) 64 TCR EL{1..3} Translation Control 64 VTTBR EL2 Virt Translation Table Base (4/16/64kb aligned) 64 VTCR EL2 Virt Translation Control {A}MAIR EL{1..3} {Auxiliary} Memory Attribute Indirection 64 LOR{S,E}A EL1 LORegion {Start,End} Address 64,1 LOR{C,N,ID} EL1 LORegion {Control,Number,ID} 64,1 System Control Register (SCTLR) M 0x00000001 MMU enabled A 0x00000002 Alignment check enabled C 0x00000004 Data and unified caches enabled SA 0x00000008 Enable SP alignment check SA0 0x00000010 Enable SP alignment check for EL0 E1 UMA 0x00000200 Trap EL0 access of DAIF to EL1 E1 I 0x00001000 Instruction cache enabled DZE 0x00004000 Trap EL0 DC instruction to EL1 E1 UCT 0x00008000 Trap EL0 access of CTR EL0 to EL1 E1 nTWI 0x00010000 Trap EL0 WFI instruction to EL1 E1 nTWE 0x00040000 Trap EL0 WFE instruction to EL1 E1 WXN 0x00080000 Write permission implies XN SPAN 0x00800000 Set privileged access never E1,1 E0E 0x01000000 Data at EL0 is big-endian E1 EE 0x02000000 Data at EL1 is big-endian UCI 0x04000000 Trap EL0 cache instructions to EL1 E1 Secure Configuration Registers (SCR) NS 0x0001 System state is non-secure unless in EL3 IRQ 0x0002 IRQs taken to EL3 FIQ 0x0004 FIQs taken to EL3 EA 0x0008 External aborts and SError taken to EL3 SMD 0x0080 Secure monitor call disable HCE 0x0100 Hyp Call enable SIF 0x0200 Secure instruction fetch RW 0x0400 Lower level is AArch64 ST 0x0800 Trap secure EL1 to CNTPS registers to EL3 TWI 0x1000 Trap EL{0..2} WFI instruction to EL3 TWE 0x2000 Trap EL{0..2} WFE instruction to EL3 TLOR 0x4000 Trap LOR registers 1 Generic Timer Registers CNTFRQ EL0 Ct Frequency (in Hz) CNT{P,V}CT EL0 Ct {Physical,Virtual} Count RO,64 CNTVOFF EL2 Ct Virtual Offset 64 CNTHCTL EL2 Ct Hypervisor Control CNTKCTL EL1 Ct Kernel Control CNT{P,V} {TVAL,CTL,CVAL} EL0 Ct {Physical,Virtual} Timer CNTHP {TVAL,CTL,CVAL} EL2 Ct Hypervisor Physical Timer CNTPS {TVAL,CTL,CVAL} EL1 Ct Physical Secure Timer CNTHV {TVAL,CTL,CVAL} EL2 Ct Virtual Timer 1","title":"Special purpose registers"},{"location":"cheatsheet/#exception-levels","text":"AArch64/ARMv8 name remarks EL3 highest exception level, mostly for firmware EL2 exception level for hypervisors like Xen (or parts of KVM) EL1 the Linux kernel is running in this EL0 for unprivileged userland","title":"Exception levels"},{"location":"cheatsheet/#exception-vectors","text":"EL1t Exception is taken from EL1 while stack pointer was shared with EL0. This happens when SPSel register holds the value 0. EL1h Exception is taken from EL1 at the time when dedicated stack pointer was allocated for EL1. This means that SPSel holds the value 1 and this is the mode that we are currently using. EL0_64 Exception is taken from EL0 executing in 64-bit mode. EL0_32 Exception is taken from EL0 executing in 32-bit mode.","title":"Exception vectors"},{"location":"cheatsheet/#pstate","text":"See \"Fundamentals of ARMv8-A\", Chapter \"Processor state\"","title":"PSTATE"},{"location":"cheatsheet/#return-from-exceptions","text":"ELR_EL1 , Exception Link Register. \"When taking an exception to EL1, holds the address to return to.\" SPSR_EL1, status regs, including irq enable/disable eret . Returns from an exception. It restores the processor state based on SPSR_ELn and branches to ELR_ELn, where n is the current exception level.","title":"Return from exceptions"},{"location":"cheatsheet/#common-instructions","text":"A more detailed instruction quick reference mrs Load value from a system register to one of the general purpose registers (x0\u2013x30) and Perform the logical AND operation. cbz Compare the result of the previously executed operation to 0 and jump (or branch in ARM terminology) to the provided label if the comparison yields true. b Perform an unconditional branch to some label. adr Load a label's relative address into the target register. In this case, we want pointers to the start and end of the .bss region. sub Subtract values from two registers. bl \"Branch with a link\": perform an unconditional branch and store the return address in x30 (the link register). When the subroutine is finished, use the ret instruction to jump back to the return address. mov Move a value between registers or from a constant to a register. cbz, cbnz Compare and Branch on Zero, Compare and Branch on Non-Zero. stp store a pair of registers Condition Codes EQ Equal Z NE Not equal !Z CS/HS Carry set, Unsigned higher or same C CC/LO Carry clear, Unsigned lower !C MI Minus, Negative N PL Plus, Positive or zero !N VS Overflow V VC No overflow !V HI Unsigned higher C & !Z LS Unsigned lower or same !C | Z GE Signed greater than or equal N = V LT Signed less than N /= V GT Signed greater than !Z & N = V LE Signed less than or equal Z | N /= V AL Always (default) 1","title":"Common instructions"},{"location":"cheatsheet/#architecture-naming","text":"There is an updated ARM architecture revision called \"ARMv8\", which evolved from the ARMv7 architecture. Among other things it introduces a new execution state called \"AArch64\", which provides a full 64-bit architecture. ARMv8 compliant implementations can provide this state or not, also they are free to implement the \"AArch32\" state, which closely resembles the ARMv7 architecture. So both 32-bit and 64-bit states are optional - but you should of course have at least one ;-). ARM Cortex cores provide both states, while there are implementations from other vendors which do not provide AArch32, for instance. The Linux kernel chose to call this new architecture \"arm64\", the same name got picked up by Debian for their architecture port name. The GNU toolchain however elected the official \"aarch64\" name for the port, so the GCC (cross-)compiler is usually called \"aarch64-linux-gnu-gcc\". So although the arm64 name is not official, it can be used interchangeably for aarch64.","title":"Architecture naming"},{"location":"cheatsheet/#references","text":"This page incorporates many contents from various sources. \"arm64 assembly crash course\", https://github.com/Siguza/ios-resources/blob/master/bits/arm64.md https://linux-sunxi.org/Arm64#ARM64_cheat_sheet https://wiki.cdot.senecacollege.ca/wiki/AArch64_Register_and_Instruction_Quick_Start https://tc.gts3.org/cs3210/2020/spring/r/AArch64-ISA-Cheat-Sheet.pdf \"ARMv8 A64 Quick Reference\", https://github.com/flynd/asmsheets","title":"References"},{"location":"dump/","text":"Inspect kernel binary Lookup source line given an address addr2line -e build/kernel8.elf 0x80038 Explanation: -e specifies the ELF file with debugging info, followed by a given address List all symbols & addresses $ nm build/kernel8.elf Sample output: kernel8.nm ffff000000082934 t a2d ffff0000000829b4 t a2i ... ffff000000085130 B bss_begin ffff000000102944 B bss_end ... ffff000000081000 T user_begin ffff0000000810c8 T user_delay ffff00000008112e R user_end ffff00000008105c T user_process Format: \"link address\" - \"symbol type\" - \"symbol name\" Kernel disassembly Disassemble the whole kernel aarch64-linux-gnu-objdump -dS build/kernel8.elf Explanation: -d disassembly; -S interleave assembly instructions with source Sample output: kernel8.objdump build/kernel8.elf: file format elf64-littleaarch64 Disassembly of section .text.boot: ffff000000080000 <_start>: .section \".text.boot\" .globl _start _start: mrs x0, mpidr_el1 ffff000000080000: d53800a0 mrs x0, mpidr_el1 and x0, x0,#0xFF // Check processor id ffff000000080004: 92401c00 and x0, x0, #0xff ... void user_process() { ffff00000008105c: a9be7bfd stp x29, x30, [sp, #-32]! ffff000000081060: 910003fd mov x29, sp call_sys_write(\"User process\\n\\r\"); ffff000000081064: 90000000 adrp x0, ffff000000081000 <loop> ffff000000081068: 9103e000 add x0, x0, #0xf8 ffff00000008106c: 9400001a bl ffff0000000810d4 <call_sys_write> int pid = call_sys_fork(); ffff000000081070: 9400001f bl ffff0000000810ec <call_sys_fork> ffff000000081074: b9001fa0 str w0, [x29, #28] ... Disassemble a specific address range aarch64-linux-gnu-objdump -dS build/kernel8.elf \\ --start-address=0xffff000000081000 \\ --stop-address=0xffff00000008112e Sample output: build/kernel8.elf: file format elf64-littleaarch64 Disassembly of section .text.user: ffff000000081000 <loop>: #include \"user_sys.h\" #include \"user.h\" #include \"printf.h\" void loop(char* str) { ffff000000081000: a9bd7bfd stp x29, x30, [sp, #-48]! ffff000000081004: 910003fd mov x29, sp ffff000000081008: f9000fa0 str x0, [x29, #24] char buf[2] = {\"\"}; ffff00000008100c: 790053bf strh wzr, [x29, #40] while (1){ Disassemble a specific function gdb -batch -ex 'file build/kernel8.elf' -ex 'disassemble /mr loop' Sample output: Dump of assembler code for function loop: 6 { 0x00081000 <+0>: fd std 0x00081001 <+1>: 7b bd jnp 0x80fc0 0x00081003 <+3>: a9 fd 03 00 91 test $0x910003fd,%eax 0x00081008 <+8>: a0 0f 00 f9 bf mov 0xbff9000f,%al 7 char buf[2] = {\"\"}; Dump a section as raw bytes aarch64-linux-gnu-objdump -s -j .rodata build/kernel8.elf Explanation: -j specify which elf section (.rodata in this example) to dump. Sample output: Contents of section .rodata: [0/1839] ffff0000000849a8 4b65726e 656c2070 726f6365 73732073 Kernel process s ffff0000000849b8 74617274 65642e20 454c2025 640d0a00 tarted. EL %d... ffff0000000849c8 4572726f 72207768 696c6520 6d6f7669 Error while movi ffff0000000849d8 6e672070 726f6365 73732074 6f207573 ng process to us ffff0000000849e8 6572206d 6f64650a 0d000000 00000000 er mode......... ffff0000000849f8 6b65726e 656c2062 6f6f7473 202e2e2e kernel boots ... ffff000000084a08 0a0d0000 00000000 6572726f 72207768 ........error wh ffff000000084a18 696c6520 73746172 74696e67 206b6572 ile starting ker Online disassembler (ODA) https://onlinedisassembler.com/odaweb/ A nice web UI for disassembling ELF files Download kernel8.elf to your local machine, if you build it on the course server. Command line users: use the scp command. VSCode users: right click on kernel8.elf->Download. Then, upload the file to ODA. Figure above: upload file to ODA. Figure above: ODA recognizes the uploaded file as ELF for aarch64. Figure above: kernel8.elf disassembled. Top (the blue bar): a mini map of memory layout. Left: a list of symbols. Right: the list of instructions at the specified symbol. Figure above: ODA shows ELF sections of kernel8.elf. Figure above: ODA visualizes the memory layout of IRQ vectors","title":"/ker dump"},{"location":"dump/#inspect-kernel-binary","text":"","title":"Inspect kernel binary"},{"location":"dump/#lookup-source-line-given-an-address","text":"addr2line -e build/kernel8.elf 0x80038 Explanation: -e specifies the ELF file with debugging info, followed by a given address","title":"Lookup source line given an address"},{"location":"dump/#list-all-symbols-addresses","text":"$ nm build/kernel8.elf Sample output: kernel8.nm ffff000000082934 t a2d ffff0000000829b4 t a2i ... ffff000000085130 B bss_begin ffff000000102944 B bss_end ... ffff000000081000 T user_begin ffff0000000810c8 T user_delay ffff00000008112e R user_end ffff00000008105c T user_process Format: \"link address\" - \"symbol type\" - \"symbol name\"","title":"List all symbols &amp; addresses"},{"location":"dump/#kernel-disassembly","text":"","title":"Kernel disassembly"},{"location":"dump/#disassemble-the-whole-kernel","text":"aarch64-linux-gnu-objdump -dS build/kernel8.elf Explanation: -d disassembly; -S interleave assembly instructions with source Sample output: kernel8.objdump build/kernel8.elf: file format elf64-littleaarch64 Disassembly of section .text.boot: ffff000000080000 <_start>: .section \".text.boot\" .globl _start _start: mrs x0, mpidr_el1 ffff000000080000: d53800a0 mrs x0, mpidr_el1 and x0, x0,#0xFF // Check processor id ffff000000080004: 92401c00 and x0, x0, #0xff ... void user_process() { ffff00000008105c: a9be7bfd stp x29, x30, [sp, #-32]! ffff000000081060: 910003fd mov x29, sp call_sys_write(\"User process\\n\\r\"); ffff000000081064: 90000000 adrp x0, ffff000000081000 <loop> ffff000000081068: 9103e000 add x0, x0, #0xf8 ffff00000008106c: 9400001a bl ffff0000000810d4 <call_sys_write> int pid = call_sys_fork(); ffff000000081070: 9400001f bl ffff0000000810ec <call_sys_fork> ffff000000081074: b9001fa0 str w0, [x29, #28] ...","title":"Disassemble the whole kernel"},{"location":"dump/#disassemble-a-specific-address-range","text":"aarch64-linux-gnu-objdump -dS build/kernel8.elf \\ --start-address=0xffff000000081000 \\ --stop-address=0xffff00000008112e Sample output: build/kernel8.elf: file format elf64-littleaarch64 Disassembly of section .text.user: ffff000000081000 <loop>: #include \"user_sys.h\" #include \"user.h\" #include \"printf.h\" void loop(char* str) { ffff000000081000: a9bd7bfd stp x29, x30, [sp, #-48]! ffff000000081004: 910003fd mov x29, sp ffff000000081008: f9000fa0 str x0, [x29, #24] char buf[2] = {\"\"}; ffff00000008100c: 790053bf strh wzr, [x29, #40] while (1){","title":"Disassemble a specific address range"},{"location":"dump/#disassemble-a-specific-function","text":"gdb -batch -ex 'file build/kernel8.elf' -ex 'disassemble /mr loop' Sample output: Dump of assembler code for function loop: 6 { 0x00081000 <+0>: fd std 0x00081001 <+1>: 7b bd jnp 0x80fc0 0x00081003 <+3>: a9 fd 03 00 91 test $0x910003fd,%eax 0x00081008 <+8>: a0 0f 00 f9 bf mov 0xbff9000f,%al 7 char buf[2] = {\"\"};","title":"Disassemble a specific function"},{"location":"dump/#dump-a-section-as-raw-bytes","text":"aarch64-linux-gnu-objdump -s -j .rodata build/kernel8.elf Explanation: -j specify which elf section (.rodata in this example) to dump. Sample output: Contents of section .rodata: [0/1839] ffff0000000849a8 4b65726e 656c2070 726f6365 73732073 Kernel process s ffff0000000849b8 74617274 65642e20 454c2025 640d0a00 tarted. EL %d... ffff0000000849c8 4572726f 72207768 696c6520 6d6f7669 Error while movi ffff0000000849d8 6e672070 726f6365 73732074 6f207573 ng process to us ffff0000000849e8 6572206d 6f64650a 0d000000 00000000 er mode......... ffff0000000849f8 6b65726e 656c2062 6f6f7473 202e2e2e kernel boots ... ffff000000084a08 0a0d0000 00000000 6572726f 72207768 ........error wh ffff000000084a18 696c6520 73746172 74696e67 206b6572 ile starting ker","title":"Dump a section as raw bytes"},{"location":"dump/#online-disassembler-oda","text":"https://onlinedisassembler.com/odaweb/ A nice web UI for disassembling ELF files Download kernel8.elf to your local machine, if you build it on the course server. Command line users: use the scp command. VSCode users: right click on kernel8.elf->Download. Then, upload the file to ODA. Figure above: upload file to ODA. Figure above: ODA recognizes the uploaded file as ELF for aarch64. Figure above: kernel8.elf disassembled. Top (the blue bar): a mini map of memory layout. Left: a list of symbols. Right: the list of instructions at the specified symbol. Figure above: ODA shows ELF sections of kernel8.elf. Figure above: ODA visualizes the memory layout of IRQ vectors","title":"Online disassembler (ODA)"},{"location":"gdb/","text":"Using GDB to debug kernel NOTE : Read the whole document before you attempt GDB. WSL users who want to develop on local machines instead of the server : gdbserver may not play well with WSL. See \"troubleshooting\" below. You are fine if you develop on the server. GDB Installation We've done this on the server already. Do this if developing on local machines (Linux or WSL). sudo apt install gdb-multiarch gcc-aarch64-linux-gnu build-essential Note: the gdb for aarch64 is NOT called aarch64-XXXX-gdb. The workflow Launch QEMU + the kernel and wait for the debugger # will wait for gdb to connect at local tcp 1234 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S # OR, will wait for gdb to connect at local tcp 5678 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -gdb tcp::5678 -S Explanation: -S not starting the guest until you tell it to from gdb. -s listening for an incoming connection from gdb on TCP port 1234 WARNING If multiple students run the first command on the server machine, they all attempt to listen on tcp port 1234. Only one will succeed. If you see such a failure, use the second form to specify a different TCP port number (not necessarily 5678 which may be in use as well). xzl@granger1[~]$ netstat -tulpn|grep 5678 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 0.0.0.0:5678 0.0.0.0:* LISTEN - tcp6 0 0 :::5678 :::* LISTEN - xzl@granger1[~]$ netstat -tulpn|grep 1234 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 2 0 0.0.0.0:1234 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:12345 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:12346 0.0.0.0:* LISTEN - tcp6 0 0 :::1234 :::* LISTEN - Launch GDB From another terminal gdb-multiarch build/kernel8.elf (gdb) target remote :1234 (gdb) layout asm The port number (e.g. 1234) must match what you specified for QEMU. Single step (gdb) si Dump register contents (gdb) info reg show reg information at each step. This example shows (gdb) display/10i $sp Dump memory You can specify a symbol or a raw addr ... as instructions x/20i _start ... as hex (bytes) x/20xb _start ... as hex (words) x/20xw _start ... as a textual string x/s _start x/s $x0 Print out variables/structures print *mem_map print the first 10 elements of mem_map, a pointer of type short* print (short[10])*mem_map Set a breakpoint at addr b *0xffff0000 Function/source lookup Look up type of a given symbol ptype mem_map Find out function name at a given addr info line *0x10000000 List source at a given addr list *0x10000000 list *fn The GDB \"dashboard\" enhancement The basic GDB UI is too primitive to beginners. We provide you an enhancement called GDB-dashboard. The upstream source is here . I adapted it for aarch64. Screenshot: Installation Grab from my repository: wget -P ~ https://raw.githubusercontent.com/fxlin/gdb-dashboard-aarch64/master/.gdbinit There's only one file: .gdbinit . It's the initial script that GDB will load upon start. The above line download it to your home directory. Usage All GDB commands still apply , e.g. \"si\" is single step per instruction; \"b\" is to set a breakpoint; \"c\" for continuing execution. See below for more. The major features here are multiple views: for registers, stack, assembly, and source. Customize Open ~/.gdbinit. Go to near line 2500 where you can see initialization commands for GDB, e.g. file build/kernel8.elf target remote :1234 The port number (e.g. 1234) must match what you specified for QEMU. GDB execute these commands whenever it starts, so you do not have to type them every time. In the above example, GDB loads the ELF file kernel8.elf (only for parsing symbols and debugging info); it connects to a remote target at local port 1234. Lines below customize gdb-dashboard behaviors, e.g. dashboard source -style height 15 dashboard assembly -style height 8 These lines set the height of the \"source\" panel and the \"assembly\" panel. The best documentation of gdb-dashboard seems from typing help dashboard in the GDB console. e.g. In GDB, type: >>> help dashboard expressions Cannot connect? See \"troubleshooting\" below. Other enhancement (FYI) GEF (https://github.com/hugsy/gef) is also viable. Both GEF and GDB-dashboard: Both enhanced GDB significantly. GEF understands aarch64 semantics (e.g. CPU flags) very well. It can even tell why a branch was taken/not taken. However, GEF does not parse aarch64 callstack properly (at least I cannot get it work). GDB-dashboard nicely parses the callstack. It, however, does not display aarch64 registers properly. GEF screenshot (note the CPU flags it recognized) Troubleshooting Cannot connect and need help? Report the following: Your QEMU version. i.e. the output of \"qemu-system-aarch64 --version\" Have you tried other kernel binaries, e.g. from p1exp1? And the binaries provided by us? https://github.com/fxlin/p1-kernel/releases The full commands you use to launch QEMU. Have you tried different port numbers? Launch GDB w/o loading .gdbinit: gdb-multiarch -n Then enter GDB commands manually, e.g. load, target remote, etc. Does the problem persist? What's the output? Attach screenshot(s) of the above steps, if possible. WSL caveat: \"gdbserver: Target description specified unknown architecture \u201caarch64\u201d https://stackoverflow.com/questions/53524546/gdbserver-target-description-specified-unknown-architecture-aarch64 It seems GDB server does not play well with WSL\u2026 be aware! Reference Launch qemu with gdb https://en.wikibooks.org/wiki/QEMU/Debugging_with_QEMU#Launching_QEMU_from_GDB more info about gdb for kernel debugging https://wiki.osdev.org/Kernel_Debugging Good article https://interrupt.memfault.com/blog/advanced-gdb#source-files","title":"/gdb"},{"location":"gdb/#using-gdb-to-debug-kernel","text":"NOTE : Read the whole document before you attempt GDB. WSL users who want to develop on local machines instead of the server : gdbserver may not play well with WSL. See \"troubleshooting\" below. You are fine if you develop on the server.","title":"Using GDB to debug kernel"},{"location":"gdb/#gdb-installation","text":"We've done this on the server already. Do this if developing on local machines (Linux or WSL). sudo apt install gdb-multiarch gcc-aarch64-linux-gnu build-essential Note: the gdb for aarch64 is NOT called aarch64-XXXX-gdb.","title":"GDB Installation"},{"location":"gdb/#the-workflow","text":"","title":"The workflow"},{"location":"gdb/#launch-qemu-the-kernel-and-wait-for-the-debugger","text":"# will wait for gdb to connect at local tcp 1234 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S # OR, will wait for gdb to connect at local tcp 5678 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -gdb tcp::5678 -S Explanation: -S not starting the guest until you tell it to from gdb. -s listening for an incoming connection from gdb on TCP port 1234 WARNING If multiple students run the first command on the server machine, they all attempt to listen on tcp port 1234. Only one will succeed. If you see such a failure, use the second form to specify a different TCP port number (not necessarily 5678 which may be in use as well). xzl@granger1[~]$ netstat -tulpn|grep 5678 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 0.0.0.0:5678 0.0.0.0:* LISTEN - tcp6 0 0 :::5678 :::* LISTEN - xzl@granger1[~]$ netstat -tulpn|grep 1234 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 2 0 0.0.0.0:1234 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:12345 0.0.0.0:* LISTEN - tcp 0 0 127.0.0.1:12346 0.0.0.0:* LISTEN - tcp6 0 0 :::1234 :::* LISTEN -","title":"Launch QEMU + the kernel and wait for the debugger"},{"location":"gdb/#launch-gdb","text":"From another terminal gdb-multiarch build/kernel8.elf (gdb) target remote :1234 (gdb) layout asm The port number (e.g. 1234) must match what you specified for QEMU. Single step (gdb) si","title":"Launch GDB"},{"location":"gdb/#dump-register-contents","text":"(gdb) info reg show reg information at each step. This example shows (gdb) display/10i $sp","title":"Dump register contents"},{"location":"gdb/#dump-memory","text":"You can specify a symbol or a raw addr ... as instructions x/20i _start ... as hex (bytes) x/20xb _start ... as hex (words) x/20xw _start ... as a textual string x/s _start x/s $x0","title":"Dump memory"},{"location":"gdb/#print-out-variablesstructures","text":"print *mem_map print the first 10 elements of mem_map, a pointer of type short* print (short[10])*mem_map","title":"Print out variables/structures"},{"location":"gdb/#set-a-breakpoint-at-addr","text":"b *0xffff0000","title":"Set a breakpoint at addr"},{"location":"gdb/#functionsource-lookup","text":"Look up type of a given symbol ptype mem_map Find out function name at a given addr info line *0x10000000 List source at a given addr list *0x10000000 list *fn","title":"Function/source lookup"},{"location":"gdb/#the-gdb-dashboard-enhancement","text":"The basic GDB UI is too primitive to beginners. We provide you an enhancement called GDB-dashboard. The upstream source is here . I adapted it for aarch64. Screenshot:","title":"The GDB \"dashboard\" enhancement"},{"location":"gdb/#installation","text":"Grab from my repository: wget -P ~ https://raw.githubusercontent.com/fxlin/gdb-dashboard-aarch64/master/.gdbinit There's only one file: .gdbinit . It's the initial script that GDB will load upon start. The above line download it to your home directory.","title":"Installation"},{"location":"gdb/#usage","text":"All GDB commands still apply , e.g. \"si\" is single step per instruction; \"b\" is to set a breakpoint; \"c\" for continuing execution. See below for more. The major features here are multiple views: for registers, stack, assembly, and source.","title":"Usage"},{"location":"gdb/#customize","text":"Open ~/.gdbinit. Go to near line 2500 where you can see initialization commands for GDB, e.g. file build/kernel8.elf target remote :1234 The port number (e.g. 1234) must match what you specified for QEMU. GDB execute these commands whenever it starts, so you do not have to type them every time. In the above example, GDB loads the ELF file kernel8.elf (only for parsing symbols and debugging info); it connects to a remote target at local port 1234. Lines below customize gdb-dashboard behaviors, e.g. dashboard source -style height 15 dashboard assembly -style height 8 These lines set the height of the \"source\" panel and the \"assembly\" panel. The best documentation of gdb-dashboard seems from typing help dashboard in the GDB console. e.g. In GDB, type: >>> help dashboard expressions Cannot connect? See \"troubleshooting\" below.","title":"Customize"},{"location":"gdb/#other-enhancement-fyi","text":"GEF (https://github.com/hugsy/gef) is also viable. Both GEF and GDB-dashboard: Both enhanced GDB significantly. GEF understands aarch64 semantics (e.g. CPU flags) very well. It can even tell why a branch was taken/not taken. However, GEF does not parse aarch64 callstack properly (at least I cannot get it work). GDB-dashboard nicely parses the callstack. It, however, does not display aarch64 registers properly. GEF screenshot (note the CPU flags it recognized)","title":"Other enhancement (FYI)"},{"location":"gdb/#troubleshooting","text":"Cannot connect and need help? Report the following: Your QEMU version. i.e. the output of \"qemu-system-aarch64 --version\" Have you tried other kernel binaries, e.g. from p1exp1? And the binaries provided by us? https://github.com/fxlin/p1-kernel/releases The full commands you use to launch QEMU. Have you tried different port numbers? Launch GDB w/o loading .gdbinit: gdb-multiarch -n Then enter GDB commands manually, e.g. load, target remote, etc. Does the problem persist? What's the output? Attach screenshot(s) of the above steps, if possible. WSL caveat: \"gdbserver: Target description specified unknown architecture \u201caarch64\u201d https://stackoverflow.com/questions/53524546/gdbserver-target-description-specified-unknown-architecture-aarch64 It seems GDB server does not play well with WSL\u2026 be aware!","title":"Troubleshooting"},{"location":"gdb/#reference","text":"Launch qemu with gdb https://en.wikibooks.org/wiki/QEMU/Debugging_with_QEMU#Launching_QEMU_from_GDB more info about gdb for kernel debugging https://wiki.osdev.org/Kernel_Debugging Good article https://interrupt.memfault.com/blog/advanced-gdb#source-files","title":"Reference"},{"location":"jtag/","text":"JTAG for Rpi3 Picture above: A JTAG debugger (blackbox), among other things, connected to an Rpi3 board. JTAG is a special hardware connection to a target board, allowing debugging of the target board in situ -- watching registers, setting breakpoints, dumping memory regions -- just as we debug kernel on QEMU. While sounding very useful, JTAG is not widely used even by kernel hackers as a debugging method. When building kernels on real hardware, programmers mostly debug by printing to UART, except for the very early stage of kernel boot, before the UART is up. Because of this reason, hardware/software for JTAG is lacking, even for popular boards like Rpi. Years ago, I have done JTAG debugging with a board of Texas Instruments (Pandaborad, Cortex-A9) with their $5,000 proprietary tool. I can attest it was very difficult to use. For education purpose though, it may be useful to watch registers & set breakpoints when we play with Rpi3. There are reports on how to do so (see references below). In general, the support for aarch64 seems spotty (as opposed to microcontroller boards). As of Jan 2021, the support was described as \"stalled\". I would expect caveats. That being said, it's gonna be fun to try! If you are interested, let us know by all means! We can provide JTAG hardware for you. References: https://metebalci.com/blog/bare-metal-raspberry-pi-3b-jtag/ https://www.suse.com/c/debugging-raspberry-pi-3-with-jtag/ https://www.linaro.org/blog/open-on-chip-debugger-ocd-at-linaro/ https://collaborate.linaro.org/display/TCWGPUB/OpenOCD+for+AArch64","title":"/jtag"},{"location":"jtag/#jtag-for-rpi3","text":"Picture above: A JTAG debugger (blackbox), among other things, connected to an Rpi3 board. JTAG is a special hardware connection to a target board, allowing debugging of the target board in situ -- watching registers, setting breakpoints, dumping memory regions -- just as we debug kernel on QEMU. While sounding very useful, JTAG is not widely used even by kernel hackers as a debugging method. When building kernels on real hardware, programmers mostly debug by printing to UART, except for the very early stage of kernel boot, before the UART is up. Because of this reason, hardware/software for JTAG is lacking, even for popular boards like Rpi. Years ago, I have done JTAG debugging with a board of Texas Instruments (Pandaborad, Cortex-A9) with their $5,000 proprietary tool. I can attest it was very difficult to use. For education purpose though, it may be useful to watch registers & set breakpoints when we play with Rpi3. There are reports on how to do so (see references below). In general, the support for aarch64 seems spotty (as opposed to microcontroller boards). As of Jan 2021, the support was described as \"stalled\". I would expect caveats. That being said, it's gonna be fun to try! If you are interested, let us know by all means! We can provide JTAG hardware for you. References: https://metebalci.com/blog/bare-metal-raspberry-pi-3b-jtag/ https://www.suse.com/c/debugging-raspberry-pi-3-with-jtag/ https://www.linaro.org/blog/open-on-chip-debugger-ocd-at-linaro/ https://collaborate.linaro.org/display/TCWGPUB/OpenOCD+for+AArch64","title":"JTAG for Rpi3"},{"location":"qemu/","text":"QEMU cheetsheet Add QEMU to PATH # assuming the qemu source tree has been built, and it is under ./qemu export PATH=\"$(pwd)/qemu/aarch64-softmmu:${PATH}\" # (optional: grab a sample kernel binary for testing) wget https://github.com/fxlin/p1-kernel/releases/download/exp1-qemu/kernel8.img Explanation: the export command adds the path to QEMU to the search paths, so that whenever you type qemu-system-aarch64 , the shell can find it. You may want to add the line to ~/.bashrc so it is executed whenever you log in to the server echo export PATH=\"$(pwd)/aarch64-softmmu:${PATH}\" >> ~/.bashrc To test if the QEMU path is added to PATH. $ whereis qemu-system-aarch64 qemu-system-aarch64: /home/xzl/qemu/aarch64-softmmu/qemu-system-aarch64 Note the output path is just an example from my machine. Launch the kernel, free run qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio # if you want to suppress graphics ... qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -nographic Explanation: * -M machine type * Two \"-serial\" options correspond to the two UARTs of Rpi3 as emulated by QEMU. Note: Our kernel writes message to the 2nd one. So we tell QEMU to redirect the 2nd UART to stdio. Launch the kernel, for GDB debugging # will wait for gdb to connect at local tcp 1234 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S # will wait for gdb to connect at local tcp 5678 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -gdb tcp::5678 -S Explanation: -S not starting the guest until you tell it to from gdb. -s listening for an incoming connection from gdb on TCP port 1234 The second form is useful in that if multiple students attempt to listen on tcp port 1234 on the same machine, all but one will fail. See for details. Launch the kernel with monitor qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -monitor stdio # multiplex both board serial and monitor output on stdio qemu-system-aarch64 -machine raspi3 -serial null -serial mon:stdio -kernel kernel8.img More on the monitor mode . Launch the kernel with tracing qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -d int -D qemu.log Explanation: -d int ---> enable interrupt dedug -D test.log ----> put debug msg to a file \"qemu.log\" Sample log from executing p1exp3: Exception return from AArch64 EL2 to AArch64 EL1 PC 0x80038 Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Explanation: ESR - exception syndrome register, encoding the cause of the exception. ELR - exception link register, containing the return address of the exception handler. PSTATE - CPU flags when the exception is taken Putting everything in one file (env-qemu.sh) # change the line as needed export PATH=\"$(pwd)/qemu/aarch64-softmmu:${PATH}\" run-uart0() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial stdio } run() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio } run-mon() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -monitor stdio } run-debug() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S } run-log() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -d int -D qemu.log } To use: every time when you log in to the server and wants to develop the kernel # switch to dir where the qemu source directory is qemu/ $ source env-qemu.sh # switch to dir where kernel8.img resides $ run VNC server running on 127.0.0.1:5900 kernel boots... interval is set to: 67108864 Reference https://wiki.osdev.org/QEMU All QEMU options: https://github.com/qemu/qemu/blob/master/qemu-options.hx","title":"/qemu"},{"location":"qemu/#qemu-cheetsheet","text":"","title":"QEMU cheetsheet"},{"location":"qemu/#add-qemu-to-path","text":"# assuming the qemu source tree has been built, and it is under ./qemu export PATH=\"$(pwd)/qemu/aarch64-softmmu:${PATH}\" # (optional: grab a sample kernel binary for testing) wget https://github.com/fxlin/p1-kernel/releases/download/exp1-qemu/kernel8.img Explanation: the export command adds the path to QEMU to the search paths, so that whenever you type qemu-system-aarch64 , the shell can find it. You may want to add the line to ~/.bashrc so it is executed whenever you log in to the server echo export PATH=\"$(pwd)/aarch64-softmmu:${PATH}\" >> ~/.bashrc To test if the QEMU path is added to PATH. $ whereis qemu-system-aarch64 qemu-system-aarch64: /home/xzl/qemu/aarch64-softmmu/qemu-system-aarch64 Note the output path is just an example from my machine.","title":"Add QEMU to PATH"},{"location":"qemu/#launch-the-kernel-free-run","text":"qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio # if you want to suppress graphics ... qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -nographic Explanation: * -M machine type * Two \"-serial\" options correspond to the two UARTs of Rpi3 as emulated by QEMU. Note: Our kernel writes message to the 2nd one. So we tell QEMU to redirect the 2nd UART to stdio.","title":"Launch the kernel, free run"},{"location":"qemu/#launch-the-kernel-for-gdb-debugging","text":"# will wait for gdb to connect at local tcp 1234 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S # will wait for gdb to connect at local tcp 5678 qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -gdb tcp::5678 -S Explanation: -S not starting the guest until you tell it to from gdb. -s listening for an incoming connection from gdb on TCP port 1234 The second form is useful in that if multiple students attempt to listen on tcp port 1234 on the same machine, all but one will fail. See for details.","title":"Launch the kernel, for GDB debugging"},{"location":"qemu/#launch-the-kernel-with-monitor","text":"qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -monitor stdio # multiplex both board serial and monitor output on stdio qemu-system-aarch64 -machine raspi3 -serial null -serial mon:stdio -kernel kernel8.img More on the monitor mode .","title":"Launch the kernel with monitor"},{"location":"qemu/#launch-the-kernel-with-tracing","text":"qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -d int -D qemu.log Explanation: -d int ---> enable interrupt dedug -D test.log ----> put debug msg to a file \"qemu.log\" Sample log from executing p1exp3: Exception return from AArch64 EL2 to AArch64 EL1 PC 0x80038 Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Taking exception 5 [IRQ] ...from EL1 to EL1 ...with ESR 0x0/0x0 ...with ELR 0x8095c ...to EL1 PC 0x81a80 PSTATE 0x3c5 Exception return from AArch64 EL1 to AArch64 EL1 PC 0x8095c Explanation: ESR - exception syndrome register, encoding the cause of the exception. ELR - exception link register, containing the return address of the exception handler. PSTATE - CPU flags when the exception is taken","title":"Launch the kernel with tracing"},{"location":"qemu/#putting-everything-in-one-file-env-qemush","text":"# change the line as needed export PATH=\"$(pwd)/qemu/aarch64-softmmu:${PATH}\" run-uart0() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial stdio } run() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio } run-mon() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -monitor stdio } run-debug() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S } run-log() { qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -d int -D qemu.log } To use: every time when you log in to the server and wants to develop the kernel # switch to dir where the qemu source directory is qemu/ $ source env-qemu.sh # switch to dir where kernel8.img resides $ run VNC server running on 127.0.0.1:5900 kernel boots... interval is set to: 67108864","title":"Putting everything in one file (env-qemu.sh)"},{"location":"qemu/#reference","text":"https://wiki.osdev.org/QEMU All QEMU options: https://github.com/qemu/qemu/blob/master/qemu-options.hx","title":"Reference"},{"location":"rationales/","text":"Raspberry Pi OS project introduction or how to efficiently learn operating system development? A few years ago, I opened the source code of the Linux kernel for the first time. At that time, I considered myself more or less a skillful software developer: I knew a little bit of assembler and C programming, and had a high-level understanding of major operating system concepts, such as process scheduling and virtual memory management. However, my first attempt was a complete failure - I understood almost nothing. For other software projects that I have to deal with, I have a simple approach that usually works very well: I find the entry point of the program and then start reading the source code, going as deep as necessary to understand all the details that I am interested in. This approach works well, but not for something as sophisticated as an operating system. It was not just that it took me more than a week just to find an entry point - the main problem was that I quickly found myself in a situation where I was looking at a few lines of code, and I had no idea how to find any clues about what those lines were doing. This was especially true for the low-level assembler source code, but it worked no better for any other part of the system that I tried to investigate. I don't like the idea of dismissing a problem just because it looks complex from the beginning. Furthermore, I believe that there are no complex problems. Instead, there are a lot of problems we simply don't know how to address efficiently, so I started to look for an effective way to learn OS development in general and Linux in particular. Challenges in learning OS development I know that there are tons of books and documentation written about Linux kernel development, but neither of them provides me with the learning experience that I want. Half of the material are so superficial that I already know it. With the other half I have a very similar problem that I have with exploring the kernel source code: as soon as a book goes deep enough, 90% of the details appear to be irrelevant to the core concepts, but related to some security, performance or legacy considerations as well as to millions of features that the Linux kernel supports. As a result, instead of learning core operating system concepts, you always end up digging into the implementation details of those features. You may be wondering why I need to learn operating system development in the first place. For me, the main reason is that I was always interested in how things work under the hood. It is not just curiosity: the more difficult the task you are working on, frequently things begin to trace down to the operating system level. You just can't make fully informed technical decisions if you don't understand how everything works at a lower level. Another thing is that if you really like a technical challenge, working with OS development can be an exciting task for you. The next question you may ask is, why Linux? Other operating systems would probably be easier to approach. The answer is that I want my knowledge to be, at least in some way, relevant to what I am currently doing and to something I expect to be doing in the future. Linux is perfect in this regard because nowadays everything from small IoT devices to large servers tend to run Linux. When I said that most of the books about Linux kernel development didn't work well for me - I wasn't being quite honest. There was one book that explained some essential concepts using the actual source code that I was capable of fully understanding even though I am a novice in OS development. This book is \"Linux Device Drivers\", and it's no wonder that it is one of the most famous technical books about the Linux kernel. It starts by introducing source code of a simple driver that you can compile and play around with. Then it begins to introduce new driver related concepts one by one and explains how to modify the source code of the driver to use these new concepts. That is exactly what I refer to as a \"good learning experience\". The only problem with this book is that it focuses explicitly on driver development and says very little about core kernel implementation details. But why has nobody created a similar book for kernel developers? I think this is because if you use the current Linux kernel source code as a base for your book, then it's just not possible. There is no function, structure, or module that can be used as a simple starting point because there is nothing simple about the Linux source. You also can't introduce new concepts one at a time because in the source code, everything is very closely related to one another. After I realized this, an idea came to me: if the Linux kernel is too vast and too complicated to be used as a starting point for learning OS development, why don't I implement my own OS that will be explicitly designed for learning purposes? In this way, I can make the OS simple enough to provide a good learning experience. Also, if this OS will be implemented mostly by copying and simplifying different parts of the Linux kernel source, it would be straightforward to use it as a starting point to learn the Linux kernel as well. In addition to the OS, I decided to write a series of lectures that teaches major OS development concepts and fully explains the OS source code. OS requirements I started working on the project, which later became the RPi OS . The first thing I had to do was to determine what parts of kernel development I considered to be \"basic\", and what components I considered to be not so essential and can be skipped (at least in the beginning). In my understanding, each operating system has 2 fundamental goals: Run user processes in isolation. Provide each user process with a unified view of the machine hardware. To satisfy the first requirement, the RPi OS needs to have its own scheduler. If I want to implement a scheduler, I also have to handle timer interrupts. { xzl: not necessarily if you consider cooperative scheduling } The second requirement implies that the OS should support some drivers and provide system calls to expose them to user applications. Since this is for beginners, I don't want to work with complicated hardware, so the only drivers I care about are drivers that can write something to screen and read user input from a keyboard. Also, the OS needs to be able to load and execute user programs, so naturally it needs to support some sort of file system and be capable of understanding some sort of executable file format. It would be nice if the OS can support basic networking, but I don't want to focus on that in a text for beginners. So those are basically the things that I can identify as \"core concepts of any operating system\". Now let's take a look at the things that I want to ignore: 1. Performance I don't want to use any sophisticated algorithms in the OS. I am also going to disable all caches and other performance optimization techniques for simplicity. 1. Security It is true that the RPi OS has at least one security feature: virtual memory. Everything else can be safely ignored. 1. Multiprocessing and synchronization I am quite happy with my OS being executed on a single processor core. In particular, this allows me to get rid of a vast source of complexity - synchronization. 1. Support for multiple architectures and different types of devices More on this in the next section. 1. Millions of other features that any production-ready operating system supports How Raspberry Pi comes into play I already mentioned that I don't want the RPi OS to support multiple computer architectures or a lot of different devices. I felt even stronger about this after I dug into the Linux kernel driver model. It appears that even devices with similar purposes can largely vary in implementation details. This makes it very difficult to come up with simple abstractions around different driver types, and to reuse driver source code. To me, this seems like one of the primary sources of complexity in the Linux kernel, and I definitely want to avoid it in the RPi OS. Ok, but what kind of computer should I use then? I clearly don't want to test my bare metal programs using my working laptop, because I'm honestly not sure that it is going to survive. More importantly, I don't want people to buy an expensive laptop just to follow my OS development exercises (I don't think anybody would do this anyway). Emulators look like more or less a good choice, but I want to work with a real device because it gives me the feeling that I am doing something real rather than playing with bare metal programming . {xzl: very true} I ended up using the Raspberry Pi, in particular, the Raspberry Pi 3 Model B . Using this device looks like the ideal choice for a number of reasons: It costs something around $35. I think that should be an affordable price. This device is specially designed for learning. Its inner architecture is as simple as possible, and that perfectly suits my needs. {xzl: not necessarily. Rpi3 has many hardware quirks. But it's probably one of the few viable choices. More on this later} This device uses ARM v8 architecture. This is a simple RISC architecture, is very well adapted to OS authors' needs, and doesn't have so many legacy requirements as, for example, the popular x86 architecture. If you don't believe me, you can compare the amount of source code in the /arch/arm64 and /arch/x86 folders in the Linux kernel. {xzl: I concur. I want you to learn something new enough and used in real-world. This also explains why I rule out RISC-V} The OS is not compatible with the older versions of the Raspberry Pi, because neither of them support 64 bit ARM v8 architecture, though I think that support for all future devices should be trivial. Working with community One major drawback of any technical book is that very soon after release each book becomes obsolete. Technology nowadays is evolving so fast that it is almost impossible for book writers to keep up with it. That's why I like the idea of an \"open source book\" - a book that is freely available on the internet and encourages its readers to participate in content creation and validation. If the book content is available on Github, it is very easy for any reader to fix and develop new code samples, update the book content, and participate in writing new chapters. I understand that right now the project is not perfect, and at the time of writing it is even not finished. But I still want to publish it now, because I hope that with the help of the community I will be able to not only complete the project faster but also to make it much better and much more useful than it was in the beginning.","title":"Rationales"},{"location":"rationales/#raspberry-pi-os-project-introduction-or-how-to-efficiently-learn-operating-system-development","text":"A few years ago, I opened the source code of the Linux kernel for the first time. At that time, I considered myself more or less a skillful software developer: I knew a little bit of assembler and C programming, and had a high-level understanding of major operating system concepts, such as process scheduling and virtual memory management. However, my first attempt was a complete failure - I understood almost nothing. For other software projects that I have to deal with, I have a simple approach that usually works very well: I find the entry point of the program and then start reading the source code, going as deep as necessary to understand all the details that I am interested in. This approach works well, but not for something as sophisticated as an operating system. It was not just that it took me more than a week just to find an entry point - the main problem was that I quickly found myself in a situation where I was looking at a few lines of code, and I had no idea how to find any clues about what those lines were doing. This was especially true for the low-level assembler source code, but it worked no better for any other part of the system that I tried to investigate. I don't like the idea of dismissing a problem just because it looks complex from the beginning. Furthermore, I believe that there are no complex problems. Instead, there are a lot of problems we simply don't know how to address efficiently, so I started to look for an effective way to learn OS development in general and Linux in particular.","title":"Raspberry Pi OS project introduction or how to efficiently learn operating system development?"},{"location":"rationales/#challenges-in-learning-os-development","text":"I know that there are tons of books and documentation written about Linux kernel development, but neither of them provides me with the learning experience that I want. Half of the material are so superficial that I already know it. With the other half I have a very similar problem that I have with exploring the kernel source code: as soon as a book goes deep enough, 90% of the details appear to be irrelevant to the core concepts, but related to some security, performance or legacy considerations as well as to millions of features that the Linux kernel supports. As a result, instead of learning core operating system concepts, you always end up digging into the implementation details of those features. You may be wondering why I need to learn operating system development in the first place. For me, the main reason is that I was always interested in how things work under the hood. It is not just curiosity: the more difficult the task you are working on, frequently things begin to trace down to the operating system level. You just can't make fully informed technical decisions if you don't understand how everything works at a lower level. Another thing is that if you really like a technical challenge, working with OS development can be an exciting task for you. The next question you may ask is, why Linux? Other operating systems would probably be easier to approach. The answer is that I want my knowledge to be, at least in some way, relevant to what I am currently doing and to something I expect to be doing in the future. Linux is perfect in this regard because nowadays everything from small IoT devices to large servers tend to run Linux. When I said that most of the books about Linux kernel development didn't work well for me - I wasn't being quite honest. There was one book that explained some essential concepts using the actual source code that I was capable of fully understanding even though I am a novice in OS development. This book is \"Linux Device Drivers\", and it's no wonder that it is one of the most famous technical books about the Linux kernel. It starts by introducing source code of a simple driver that you can compile and play around with. Then it begins to introduce new driver related concepts one by one and explains how to modify the source code of the driver to use these new concepts. That is exactly what I refer to as a \"good learning experience\". The only problem with this book is that it focuses explicitly on driver development and says very little about core kernel implementation details. But why has nobody created a similar book for kernel developers? I think this is because if you use the current Linux kernel source code as a base for your book, then it's just not possible. There is no function, structure, or module that can be used as a simple starting point because there is nothing simple about the Linux source. You also can't introduce new concepts one at a time because in the source code, everything is very closely related to one another. After I realized this, an idea came to me: if the Linux kernel is too vast and too complicated to be used as a starting point for learning OS development, why don't I implement my own OS that will be explicitly designed for learning purposes? In this way, I can make the OS simple enough to provide a good learning experience. Also, if this OS will be implemented mostly by copying and simplifying different parts of the Linux kernel source, it would be straightforward to use it as a starting point to learn the Linux kernel as well. In addition to the OS, I decided to write a series of lectures that teaches major OS development concepts and fully explains the OS source code.","title":"Challenges in learning OS development"},{"location":"rationales/#os-requirements","text":"I started working on the project, which later became the RPi OS . The first thing I had to do was to determine what parts of kernel development I considered to be \"basic\", and what components I considered to be not so essential and can be skipped (at least in the beginning). In my understanding, each operating system has 2 fundamental goals: Run user processes in isolation. Provide each user process with a unified view of the machine hardware. To satisfy the first requirement, the RPi OS needs to have its own scheduler. If I want to implement a scheduler, I also have to handle timer interrupts. { xzl: not necessarily if you consider cooperative scheduling } The second requirement implies that the OS should support some drivers and provide system calls to expose them to user applications. Since this is for beginners, I don't want to work with complicated hardware, so the only drivers I care about are drivers that can write something to screen and read user input from a keyboard. Also, the OS needs to be able to load and execute user programs, so naturally it needs to support some sort of file system and be capable of understanding some sort of executable file format. It would be nice if the OS can support basic networking, but I don't want to focus on that in a text for beginners. So those are basically the things that I can identify as \"core concepts of any operating system\". Now let's take a look at the things that I want to ignore: 1. Performance I don't want to use any sophisticated algorithms in the OS. I am also going to disable all caches and other performance optimization techniques for simplicity. 1. Security It is true that the RPi OS has at least one security feature: virtual memory. Everything else can be safely ignored. 1. Multiprocessing and synchronization I am quite happy with my OS being executed on a single processor core. In particular, this allows me to get rid of a vast source of complexity - synchronization. 1. Support for multiple architectures and different types of devices More on this in the next section. 1. Millions of other features that any production-ready operating system supports","title":"OS requirements"},{"location":"rationales/#how-raspberry-pi-comes-into-play","text":"I already mentioned that I don't want the RPi OS to support multiple computer architectures or a lot of different devices. I felt even stronger about this after I dug into the Linux kernel driver model. It appears that even devices with similar purposes can largely vary in implementation details. This makes it very difficult to come up with simple abstractions around different driver types, and to reuse driver source code. To me, this seems like one of the primary sources of complexity in the Linux kernel, and I definitely want to avoid it in the RPi OS. Ok, but what kind of computer should I use then? I clearly don't want to test my bare metal programs using my working laptop, because I'm honestly not sure that it is going to survive. More importantly, I don't want people to buy an expensive laptop just to follow my OS development exercises (I don't think anybody would do this anyway). Emulators look like more or less a good choice, but I want to work with a real device because it gives me the feeling that I am doing something real rather than playing with bare metal programming . {xzl: very true} I ended up using the Raspberry Pi, in particular, the Raspberry Pi 3 Model B . Using this device looks like the ideal choice for a number of reasons: It costs something around $35. I think that should be an affordable price. This device is specially designed for learning. Its inner architecture is as simple as possible, and that perfectly suits my needs. {xzl: not necessarily. Rpi3 has many hardware quirks. But it's probably one of the few viable choices. More on this later} This device uses ARM v8 architecture. This is a simple RISC architecture, is very well adapted to OS authors' needs, and doesn't have so many legacy requirements as, for example, the popular x86 architecture. If you don't believe me, you can compare the amount of source code in the /arch/arm64 and /arch/x86 folders in the Linux kernel. {xzl: I concur. I want you to learn something new enough and used in real-world. This also explains why I rule out RISC-V} The OS is not compatible with the older versions of the Raspberry Pi, because neither of them support 64 bit ARM v8 architecture, though I think that support for all future devices should be trivial.","title":"How Raspberry Pi comes into play"},{"location":"rationales/#working-with-community","text":"One major drawback of any technical book is that very soon after release each book becomes obsolete. Technology nowadays is evolving so fast that it is almost impossible for book writers to keep up with it. That's why I like the idea of an \"open source book\" - a book that is freely available on the internet and encourages its readers to participate in content creation and validation. If the book content is available on Github, it is very easy for any reader to fix and develop new code samples, update the book content, and participate in writing new chapters. I understand that right now the project is not perfect, and at the time of writing it is even not finished. But I still want to publish it now, because I hope that with the help of the community I will be able to not only complete the project faster but also to make it much better and much more useful than it was in the beginning.","title":"Working with community"},{"location":"rpi-os/","text":"3: Interrupts Objectives We will build a baremetal program that prints out messages, as driven by periodic interrupts from a hardware timer. You will learn and experience with: Exception/interrupt vectors Handling interrupts Program hardware timers Terms \"Interrupts\" or \"irq\"? We use these two terms interchangeably. Many kernel documents use the latter. Background: interrupts & exceptions in ARM64 Interrupts Interrupts are generated by IO devices, go through the irq controller, and eventually arrive the CPU. The CPU can program the irq controller to enable/disable specific interrupt sources. By disabling an irq source, the CPU will not lose any irq from that device, but just defer receiving irq until the CPU re-enables the irq source. The CPU can also read from the irq controller which IO devices have pending interrupts, meaning that the IO devices need attention. By their canonical definitions, interrupts are asynchronous while exceptions are synchronous. Interrupts & Exceptions on aarch64 However in ARM64 lingo, exception is broadly defined; interrupts are a special kind of exceptions. x86 has its own lingo, calling exceptions as \"traps\". In this article, we use ARM's broad definition of exceptions unless stated otherwise. ARM64 defines 4 types of exceptions. We will focus the former two . Synchronous exception s Exceptions of this type are always caused by the currently executed instruction. For example, you can use str instruction to store some data at a non-existing memory location. In this case, a synchronous exception is generated. Synchronous exceptions also can be used to generate a \"software interrupt\". Software interrupt is a synchronous exception that is generated on purpose by svc instruction. We will use this technique in lesson 5 to implement system calls. Asynchronous exceptions (IRQ) Those are normal interrupts. They are always asynchronous, which means that they have nothing to do with the currently executed instruction. In contrast to synchronous exceptions, they are always not generated by the processor itself, but by external hardware. FIQ (Fast Interrupt Request) This type of exception is called \"fast interrupts\" and exist solely for the purpose of prioritizing exceptions. It is possible to configure some interrupts as \"normal\" and other as \"fast\". Fast interrupts will be signaled first and will be handled by a separate exception handler. Linux doesn't use fast interrupts and we also are not going to do so. SError (System Error) Like IRQ and FIQ , SError exceptions are asynchronous and are generated by external hardware. Unlike IRQ and FIQ , SError always indicates some error condition. Here you can find an example explaining when SError can be generated. Exception vectors An exception vector is a piece of code the CPU will execute when a specific exception happens. \" These would normally be branch instructions that direct the core to the full exception handler. \" (the ARM64 manual). In some other architectures an exception vector could be an address to jump to. Note the subtle difference. Each exception level (EL) has its own vector table. Here we focus on EL1 where the kernel executes. The kernel must provide exception handlers to be executed at EL1 in order to handle exceptions from EL0 (user programs) or EL1 (the kernel's own execution). These should be handlers for each exception type above (SError, fiq, irq, and sync) and for each of the four execution states of the CPU: EL1t Exception happens when CPU is at EL1 while the stack pointer (SP) was set to be shared with EL0. This happens when SPSel register holds the value 0 . Recall that SPSel is part of the CPU's PSTATE. EL1h Exception happens at EL1 at the time when a dedicated SP was allocated for EL1. This happens when SPSel holds the value 1 . This is the mode that our kernel is are currently using. EL0_64 Exception is taken from EL0 executing in 64-bit mode. This experiment will not deal with EL0. Spoiler: EL0_64 corresponds to the exceptions that caused by 64-bit user programs. EL0_32 Exception is taken from EL0 executing in 32-bit mode. This experiment will not deal with EL0 or 32-bit mode. Spoiler: this corresponds to exceptions in 32-bit user programs. \"The t and h suffixes are based on the terminology of thread and handler , introduced in ARMv7-M.\" -- ARM In total, for EL1 the kernel needs to define 16 exception handlers (4 types X 4 execution states) ARM64 vector table Each exception vector (or handler) is a continuous sequence of instructions responsible for handling a particular exception. Each exception vector can occupy 0x80 bytes maximum (thus .align 7 in the asm code). This is not much, but nobody prevents us from jumping to some other memory location from an exception vector. The vector table is an array of exception vectors. Note each EL has its own table as described above. Here is a short, good reference from Arm. Code Walkthrough Exception vectors, tables, etc. (entry.S) The figure below shows how vector table is defined. The code mimics what the ARM64 Linux kernel does. Why named \"entry.S\"? Because in a full-fledged kernel, exception/irq handlers are where user programs enter the kernel for execution. Although this experiment is not building such a kernel, we follow the naming convention. The vector table consists of 16 ventry definitions: .align 11 .globl vectors vectors: ventry sync_invalid_el1t // Synchronous EL1t ventry irq_invalid_el1t // IRQ EL1t ventry fiq_invalid_el1t // FIQ EL1t ventry error_invalid_el1t // Error EL1t ... The macro ventry is used to create entries in the vector table. .macro ventry label .align 7 b \\label .endm As suggested above: for code clarity, we are not going to handle exceptions right inside the exception vector. Instead, we make each vector a branch instruction ( b \\label ) that jumps to a label provided for the macro as label argument. We need .align 7 because all exception vectors should be spaced at 0x80 bytes (2<<7) one from another. A useful assembly trick. Making CPU aware of the vector table (irq.S) Ok, now we have prepared the vector table, but the processor doesn't know where it is located and therefore can't use it. In order for the exception handling to work, we must set vbar_el1 (Vector Base Address Register) to the vector table address. .globl irq_vector_init irq_vector_init: adr x0, vectors msr vbar_el1, x0 ret A simple handler for unexpected exceptions In this experiment we are only interested in handling IRQ from EL1h . Yet, our kernel defines all 16 handlers for EL1. This is for debugging ease: we want to print out meaningful message in case our kernel triggers some other exceptions due to our programming mistakes. Note again: all these handlers are to be executed at EL1. The exceptions come from either EL0 or EL1. We name all the handlers that are NOT supposed to be trigged with a invalid postfix. We implement these handlers using a handle_invalid_entry macro: .macro handle_invalid_entry type kernel_entry mov x0, #\\type mrs x1, esr_el1 mrs x2, elr_el1 bl show_invalid_entry_message b err_hang .endm The first line invokes a macro kernel_entry which is the first few instructions the kernel should execute in handling an exception/interrupt (recall the term \"entry\"). We will discuss it below. Then we call show_invalid_entry_message() and prepare 3 arguments for it. The arguments are passed in 3 registers: x0, x1, and x2. x0: the exception type. The value comes from the argument to this macro. It can take one of these values defined by our kernel code. It tells us exactly which exception handler has been executed. x1: information about what causes the exception. The value comes from esr_el1 register. ESR stands for Exception Syndrome Register. EL1 implies \"when an exception is taken to EL1\", i.e. when the exception is handled at EL1. Note: in this experiment our kernel runs at EL1 and when an interrupt happens it is handled at EL1. Read the ref again. x2: the address of the instruction being executed when the exception happens. The value comes from the elr_el1 as described earlier. For synchronous exceptions, this is the instruction that causes the exception; for irqs (asynchronous), this is the instruction completed right before irq happens. Again, the postfix EL1 indicates that \" when taking an exception to EL1, (this reg) holds the address to return to. \" The code next invokes show_invalid_entry_message function, which prints textual information to UART. Returning from that function, the code executes in an infinite loop as we have nothing else to do. kernel_entry & exit To handle valid exceptions (timer interrupts in our case), the kernel needs to save & restore the context of the \"normal\" execution, i.e. switching from the normal execution to the exception handler, executing it, and resuming the execution being interrupted. In other words, after the exception handler, we want all general purpose registers to have the same values as they had before the exception was generated. Why does NOT the above handler handle_invalid_entry save registers? Because it ends with an infinite loop and never intends to resume the interrupted execution. el1_irq: kernel_entry bl handle_irq kernel_exit Back to kernel_entry . This is the first thing to do in handling an exception: saving the processor state, notably registers x0 - x30, to the stack. To do so, it first subtracts from sp the size of total stored registers (#S_FRAME_SIZE) and then fills the stack space. According to kernel_entry , there is kernel_exit to be called as the last thing of an exception handler. kernel_exit restores the CPU state by copying back the values of x0 - x30. The order exactly mirrors that of kernel_entry otherwise we will see wrong register values. Finally kernel_exit executes eret , which returns to the normal execution. The following figure shows how the kernel memory look like before & after handling an interrupt. Configuring interrupts Configuring the Interrupt controller Bcm2837, the SoC for Rpi3, has its own interrupt controller described on page 109 of BCM2837 ARM Peripherals manual . Because of the hardware quirks (e.g. many irqs are routed from GPU to CPU), the interrupt controller organizes irq sources into three groups and has registers for controlling/checking individual groups. Be aware of their weird naming: these irq groups are called \"Basic\" (irqs routed to the ARM CPU), \"1\", and \"2\" (irqs routed from GPU to CPU). For example, IRQ basic pending , IRQ pending 1 , IRQ pending 2 . The SoC manual has more dirty details. We are only interested in timer interrupts. The SoC manual, page 113 states that irq #1 and #3 are from the system timer. These irq sources belong to the irq group 1, which can be enabled using ENABLE_IRQS_1 . So enable_interrupt_controller() enables system timer IRQ at #1: void enable_interrupt_controller() { put32(ENABLE_IRQS_1, SYSTEM_TIMER_IRQ_1); } Masking/unmasking interrupts From time to time, the kernel must mask/unmask ALL interrupts, so that some critical code regions will never be interrupted. For example, what happens if an interrupt occurs right in the middle of kernel_entry macro? The CPU state would be corrupted. Upon entry to ANY exception/interrupt, the processor automatically masks all interrupts so that the kernel can save the CPU state atomically. The kernel then unmasks exceptions (often interrupts) it wants to handle during the execution of the interrupt handler. Right before exiting the exception handling ( eret ), the kernel masks all interrupts again for atomic CPU state restore. Note: it is perfectly legal to have nested interrupts, i.e. handling another interrupt in the middle of an interrupt handler. Nested interrupts are NOT common: for simple designs, many kernels intentionally keep interrupt handlers very short so they can mask interrupts throughout an interrupt handler without delaying future interrupts too much. However, handling interrupts during exception handlers is VERY common. Syscalls are executed as exception handlers, during which the kernel must be responsive to interrupts. The following two functions (irq.S) mask and unmask interrupts. .globl enable_irq enable_irq: msr daifclr, #2 ret .globl disable_irq disable_irq: msr daifset, #2 ret Explanation: ARM processor state (PSTATE) has 4 bits holding mask status for different types of interrupts. D Masks debug exceptions. These are a special type of synchronous exceptions. For obvious reasons, it is not possible to mask all synchronous exceptions, but it is convenient to have a separate flag that can mask debug exceptions. A Masks SErrors . It is called A because SErrors sometimes are called asynchronous aborts. I Masks IRQs F Masks FIQs Now you can probably guess why registers that are responsible for changing interrupt mask status are called daifclr and daifset . Those registers set and clear interrupt mask status bits in the processor state. Why do we use constant value 2 in both of the functions? This is because we only want to set and clear the second ( I ) bit. The IRQ handler We have a single, common exception handler for handling all IRQs . This handler is defined here . void handle_irq(void) { unsigned int irq = get32(IRQ_PENDING_1); switch (irq) { case (SYSTEM_TIMER_IRQ_1): handle_timer_irq(); break; default: printf(\"Unknown pending irq: %x\\r\\n\", irq); } } In the handler, we need a way to figure out what IO device generated the interrupt. Interrupt controller can help us with this job: it has IRQ_PENDING_1 register that holds interrupt status for interrupts 0 - 31 . Using this register we can check whether the current interrupt was generated by the timer or by some other device and call device specific interrupt handler. Note, multiple interrupts can be pending at the same time. That's why each device specific interrupt handler must acknowledge that it completed handling the interrupt and only after that interrupt pending bit in IRQ_PENDING_1 will be cleared. Because of the same reason, for a production kernel you would probably want to wrap switch construct in the interrupt handler in a loop: in this way, you will be able to handle multiple interrupts during a single handler execution. Arm's generic hardware timer We use the Arm generic timer, which is part of Arm64 core design (i.e. not defined by SoC). This is nice, as the generic timers exist for all Armv8 CPUs. Your experiences will apply to other Armv8 SoCs as well. Arm's official webpage (ARM062-1010708621-30) describes the use of generic timers. The following figure shows the generic timer hardware. In a nutshell, a global, chip-level hardware counter (i.e. \"System Counter\") drives per-core timer instances. As hardware boots, System Counter keeps incrementing, i.e. free running. Software can read the current System Counter. But System Counter alone does not generate interrupts. Software must program the timers so that they interrupt corresponding CPU cores at specific time intervals. Note: PE means CPU cores. As our kernel only deals with one core, we focus on one timer instance. How should the kernel program the timer? The timer provides two core registers (among others) as two alternative ways for programming the same timer. They are intuitive: CVAL, a 64-bit comparator. Roughly, this sets a \"threshold\" for System Counter: Example: The kernel writes a value X to CVAL. When System Counter exceeds X, the timer generates an interrupt. TVAL, a 32-bit timer value. Roughly, this sets a \"delta\" for System Counter: Example: The kernel writes a value X to TVAL. The hardware updates CVAL += the Current System Counter + TVAL. The timer generates an interrupt according to the new CVAL. The above brief description would suffice in our kernel experiment. Beyond them, TVAL has another less intuitive, \"countdown\" function (not used in this experiment but good to know). Since the last write by software, TVAL decrements as System Counter increments. The moment TVAL counts down to 0 is when an interrupt fires. After that, TVAL will keep counting down to a minus value. To summarize: If software needs a timer event in X ticks of the clock, the software can write X to TVAL periodically. Alternatively, if software wants an event when the system count reaches Y, software can write Y to CVAL. If software wants to know the remaining ticks until the next interrupt, the software reads from TVAL. Initialize timer (timer.S) By programming the timer device, We turn on the timer and allow it to generate interrupts. gen_timer_init: mov x0, #1 msr CNTP_CTL_EL0, x0 ret This writes 1 to the control register ( CNTP_CTL_EL0 ) of the EL1 physical timer . See here for the register definition. How to interpret the register name \"CNTP_CTL_EL0\": CTL indicates this is a control register; CNTP_XXX_EL0 indicates that this is for the EL1 physical timer. Why _EL0? I guess it means that the timer is accessible to both EL1 and EL0. See the table below. Register Purpose <timer>_CTL_EL<x> Control register <timer>_CVAL_EL<x> Comparator value <timer>_TVAL_EL<x> Timer value Timer Register prefix EL<x> EL1 physical timer CNTP EL0 EL1 virtual time CNTV EL0 Non-secure EL2 physical timer CNTHP EL2 Non-secure EL2 virtual timer CNTHV EL2 EL3 physical timer CNTPS EL1 Secure EL2 physical timer CNTHPS EL2 Secure EL2 virtual timer CNTHVS EL2 Turn on timer interrupt at the CPU core We have to deal with yet another Rpi3 quirk. The Arm generic timer IRQs are wired to a per-core interrupt controller/register. For core 0, this is TIMER_INT_CTRL_0 at 0x40000040; bit 1 is for physical timer at EL1 (CNTP). This register is documented in the manual of BCM2836 (search for \"Core timers interrupts\"). Note the manual is NOT for the BCM2837 SoC used by Rpi3. I have no idea how community figured this out. void enable_interrupt_controller() { // Enables Core 0 Timers interrupt control for the generic timer put32(TIMER_INT_CTRL_0, TIMER_INT_CTRL_0_VALUE); } To summarize : we have to program three places in order to receive the timer interrupts: the timer device, the per-core interrupt controller, and the core itself (DAIF). Handing timer interrupts The kernel gets an irq. The kernel check if it comes from the timer; if so, the kernel sets the timer for firing the next interrupt. void handle_irq(void) { // Each Core has its own pending local intrrupts register unsigned int irq = get32(INT_SOURCE_0); switch (irq) { case (GENERIC_TIMER_INTERRUPT): handle_generic_timer_irq(); break; ... The EL1h exception handler invokes the above function. The function reads INT_SOURCE_0 (0x4000:0060), search for \"Core interrupt sources\" in the BCM2836 manual ), where bit 1 is for our CNTP timer. Reset timer (timer.S) The kernel writes a delta value (1<<24) to TVAL, requesting an interrupt to fire after 1<<24 ticks. gen_timer_reset: mov x0, #1 lsl x0, x0, #24 msr CNTP_TVAL_EL0, x0 ret Timers on Rpi3 There are other timers on Rpi3 which you may see from various online blogs/tutorials/forums. The information can be very confusing. The naming of timers does NOT help. I list them below together with Arm generic timers described above. I suggest you stay away from other timers because the experience will not be as useful. Name Implemented by IRQ QEMU support? (v5.0 ) Phys Addr Document System Timer Broadcom (?) Global. In GPU irq space Implemented as bcm2835_systmr. However free running and cannot generate irq . 3f003000 BCM2837 ARM timer Arm ip (sp804) Global. In Arm core's private irq space (\"Basic irqs\") Unimplemented. See QEMU code bcm2835_peripherals.c 3f00b400 BCM2836 Local timer Broadcom (?) Per core Partially implemented . Can generate trigger irq but readback seems unsupported. 40000034 BCM2836 Arm generic timer Arm, as part of armv8 Per core Implemented 40000040 Armv8 doc + BCM2836 for IRQ routing FYI: Programming the Rpi3's system timer (not used in this experiment) Raspberry Pi system timer is a very simple device. It has a counter that increases its value by 1 after each clock tick. It also has 4 interrupt lines that connect to the interrupt controller (so it can generate 4 different interrupts) and 4 corresponding compare registers. When the value of the counter becomes equal to the value stored in one of the compare registers the corresponding interrupt is fired. That's why, before we will be able to use system timer interrupts, we need to initialize one of the compare registers with a non-zero value, the larger the value is - the later an interrupt will be generated. This is done in timer_init function. const unsigned int interval = 200000; unsigned int curVal = 0; void timer_init ( void ) { curVal = get32(TIMER_CLO); curVal += interval; put32(TIMER_C1, curVal); } The first line reads current counter value, the second line increases it and the third line sets the value of the compare register for the interrupt number 1. By manipulating interval value you can adjust how soon the first timer interrupt will be generated. Finally, we got to the timer interrupt handler. It is actually very simple. void handle_timer_irq( void ) { curVal += interval; put32(TIMER_C1, curVal); put32(TIMER_CS, TIMER_CS_M1); printf(\"Timer iterrupt received\\n\\r\"); } Here we first update compare register so that that next interrupt will be generated after the same time interval. Next, we acknowledge the interrupt by writing 1 to the TIMER_CS register. In the documentation TIMER_CS is called \"Timer Control/Status\" register. Bits [0:3] of this register can be used to acknowledge interrupts coming from one of the 4 available interrupt lines. Hacking tips -- tracing interrupts with QEMU qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img \\ -serial null -serial stdio \\ -d int -D test.log See the qmeu cheatsheet for more. Conclusion The last thing that you might want to take a look at is the kernel_main function where all previously discussed functionality is orchestrated. After you compile and run the sample it should print \"Timer interrupt received\" message after an interrupt is taken. Please, try to do it by yourself and don't forget to carefully examine the code and experiment with it.","title":"3: Interrupts"},{"location":"rpi-os/#3-interrupts","text":"","title":"3: Interrupts"},{"location":"rpi-os/#objectives","text":"We will build a baremetal program that prints out messages, as driven by periodic interrupts from a hardware timer. You will learn and experience with: Exception/interrupt vectors Handling interrupts Program hardware timers","title":"Objectives"},{"location":"rpi-os/#terms","text":"\"Interrupts\" or \"irq\"? We use these two terms interchangeably. Many kernel documents use the latter.","title":"Terms"},{"location":"rpi-os/#background-interrupts-exceptions-in-arm64","text":"","title":"Background: interrupts &amp; exceptions in ARM64"},{"location":"rpi-os/#interrupts","text":"Interrupts are generated by IO devices, go through the irq controller, and eventually arrive the CPU. The CPU can program the irq controller to enable/disable specific interrupt sources. By disabling an irq source, the CPU will not lose any irq from that device, but just defer receiving irq until the CPU re-enables the irq source. The CPU can also read from the irq controller which IO devices have pending interrupts, meaning that the IO devices need attention. By their canonical definitions, interrupts are asynchronous while exceptions are synchronous.","title":"Interrupts"},{"location":"rpi-os/#interrupts-exceptions-on-aarch64","text":"However in ARM64 lingo, exception is broadly defined; interrupts are a special kind of exceptions. x86 has its own lingo, calling exceptions as \"traps\". In this article, we use ARM's broad definition of exceptions unless stated otherwise. ARM64 defines 4 types of exceptions. We will focus the former two . Synchronous exception s Exceptions of this type are always caused by the currently executed instruction. For example, you can use str instruction to store some data at a non-existing memory location. In this case, a synchronous exception is generated. Synchronous exceptions also can be used to generate a \"software interrupt\". Software interrupt is a synchronous exception that is generated on purpose by svc instruction. We will use this technique in lesson 5 to implement system calls. Asynchronous exceptions (IRQ) Those are normal interrupts. They are always asynchronous, which means that they have nothing to do with the currently executed instruction. In contrast to synchronous exceptions, they are always not generated by the processor itself, but by external hardware. FIQ (Fast Interrupt Request) This type of exception is called \"fast interrupts\" and exist solely for the purpose of prioritizing exceptions. It is possible to configure some interrupts as \"normal\" and other as \"fast\". Fast interrupts will be signaled first and will be handled by a separate exception handler. Linux doesn't use fast interrupts and we also are not going to do so. SError (System Error) Like IRQ and FIQ , SError exceptions are asynchronous and are generated by external hardware. Unlike IRQ and FIQ , SError always indicates some error condition. Here you can find an example explaining when SError can be generated.","title":"Interrupts &amp; Exceptions on aarch64"},{"location":"rpi-os/#exception-vectors","text":"An exception vector is a piece of code the CPU will execute when a specific exception happens. \" These would normally be branch instructions that direct the core to the full exception handler. \" (the ARM64 manual). In some other architectures an exception vector could be an address to jump to. Note the subtle difference. Each exception level (EL) has its own vector table. Here we focus on EL1 where the kernel executes. The kernel must provide exception handlers to be executed at EL1 in order to handle exceptions from EL0 (user programs) or EL1 (the kernel's own execution). These should be handlers for each exception type above (SError, fiq, irq, and sync) and for each of the four execution states of the CPU: EL1t Exception happens when CPU is at EL1 while the stack pointer (SP) was set to be shared with EL0. This happens when SPSel register holds the value 0 . Recall that SPSel is part of the CPU's PSTATE. EL1h Exception happens at EL1 at the time when a dedicated SP was allocated for EL1. This happens when SPSel holds the value 1 . This is the mode that our kernel is are currently using. EL0_64 Exception is taken from EL0 executing in 64-bit mode. This experiment will not deal with EL0. Spoiler: EL0_64 corresponds to the exceptions that caused by 64-bit user programs. EL0_32 Exception is taken from EL0 executing in 32-bit mode. This experiment will not deal with EL0 or 32-bit mode. Spoiler: this corresponds to exceptions in 32-bit user programs. \"The t and h suffixes are based on the terminology of thread and handler , introduced in ARMv7-M.\" -- ARM In total, for EL1 the kernel needs to define 16 exception handlers (4 types X 4 execution states)","title":"Exception vectors"},{"location":"rpi-os/#arm64-vector-table","text":"Each exception vector (or handler) is a continuous sequence of instructions responsible for handling a particular exception. Each exception vector can occupy 0x80 bytes maximum (thus .align 7 in the asm code). This is not much, but nobody prevents us from jumping to some other memory location from an exception vector. The vector table is an array of exception vectors. Note each EL has its own table as described above. Here is a short, good reference from Arm.","title":"ARM64 vector table"},{"location":"rpi-os/#code-walkthrough","text":"","title":"Code Walkthrough"},{"location":"rpi-os/#exception-vectors-tables-etc-entrys","text":"The figure below shows how vector table is defined. The code mimics what the ARM64 Linux kernel does. Why named \"entry.S\"? Because in a full-fledged kernel, exception/irq handlers are where user programs enter the kernel for execution. Although this experiment is not building such a kernel, we follow the naming convention. The vector table consists of 16 ventry definitions: .align 11 .globl vectors vectors: ventry sync_invalid_el1t // Synchronous EL1t ventry irq_invalid_el1t // IRQ EL1t ventry fiq_invalid_el1t // FIQ EL1t ventry error_invalid_el1t // Error EL1t ... The macro ventry is used to create entries in the vector table. .macro ventry label .align 7 b \\label .endm As suggested above: for code clarity, we are not going to handle exceptions right inside the exception vector. Instead, we make each vector a branch instruction ( b \\label ) that jumps to a label provided for the macro as label argument. We need .align 7 because all exception vectors should be spaced at 0x80 bytes (2<<7) one from another. A useful assembly trick.","title":"Exception vectors, tables, etc. (entry.S)"},{"location":"rpi-os/#making-cpu-aware-of-the-vector-table-irqs","text":"Ok, now we have prepared the vector table, but the processor doesn't know where it is located and therefore can't use it. In order for the exception handling to work, we must set vbar_el1 (Vector Base Address Register) to the vector table address. .globl irq_vector_init irq_vector_init: adr x0, vectors msr vbar_el1, x0 ret","title":"Making CPU aware of the vector table (irq.S)"},{"location":"rpi-os/#a-simple-handler-for-unexpected-exceptions","text":"In this experiment we are only interested in handling IRQ from EL1h . Yet, our kernel defines all 16 handlers for EL1. This is for debugging ease: we want to print out meaningful message in case our kernel triggers some other exceptions due to our programming mistakes. Note again: all these handlers are to be executed at EL1. The exceptions come from either EL0 or EL1. We name all the handlers that are NOT supposed to be trigged with a invalid postfix. We implement these handlers using a handle_invalid_entry macro: .macro handle_invalid_entry type kernel_entry mov x0, #\\type mrs x1, esr_el1 mrs x2, elr_el1 bl show_invalid_entry_message b err_hang .endm The first line invokes a macro kernel_entry which is the first few instructions the kernel should execute in handling an exception/interrupt (recall the term \"entry\"). We will discuss it below. Then we call show_invalid_entry_message() and prepare 3 arguments for it. The arguments are passed in 3 registers: x0, x1, and x2. x0: the exception type. The value comes from the argument to this macro. It can take one of these values defined by our kernel code. It tells us exactly which exception handler has been executed. x1: information about what causes the exception. The value comes from esr_el1 register. ESR stands for Exception Syndrome Register. EL1 implies \"when an exception is taken to EL1\", i.e. when the exception is handled at EL1. Note: in this experiment our kernel runs at EL1 and when an interrupt happens it is handled at EL1. Read the ref again. x2: the address of the instruction being executed when the exception happens. The value comes from the elr_el1 as described earlier. For synchronous exceptions, this is the instruction that causes the exception; for irqs (asynchronous), this is the instruction completed right before irq happens. Again, the postfix EL1 indicates that \" when taking an exception to EL1, (this reg) holds the address to return to. \" The code next invokes show_invalid_entry_message function, which prints textual information to UART. Returning from that function, the code executes in an infinite loop as we have nothing else to do.","title":"A simple handler for unexpected exceptions"},{"location":"rpi-os/#kernel_entry-exit","text":"To handle valid exceptions (timer interrupts in our case), the kernel needs to save & restore the context of the \"normal\" execution, i.e. switching from the normal execution to the exception handler, executing it, and resuming the execution being interrupted. In other words, after the exception handler, we want all general purpose registers to have the same values as they had before the exception was generated. Why does NOT the above handler handle_invalid_entry save registers? Because it ends with an infinite loop and never intends to resume the interrupted execution. el1_irq: kernel_entry bl handle_irq kernel_exit Back to kernel_entry . This is the first thing to do in handling an exception: saving the processor state, notably registers x0 - x30, to the stack. To do so, it first subtracts from sp the size of total stored registers (#S_FRAME_SIZE) and then fills the stack space. According to kernel_entry , there is kernel_exit to be called as the last thing of an exception handler. kernel_exit restores the CPU state by copying back the values of x0 - x30. The order exactly mirrors that of kernel_entry otherwise we will see wrong register values. Finally kernel_exit executes eret , which returns to the normal execution. The following figure shows how the kernel memory look like before & after handling an interrupt.","title":"kernel_entry &amp; exit"},{"location":"rpi-os/#configuring-interrupts","text":"","title":"Configuring interrupts"},{"location":"rpi-os/#_1","text":"","title":""},{"location":"rpi-os/#configuring-the-interrupt-controller","text":"Bcm2837, the SoC for Rpi3, has its own interrupt controller described on page 109 of BCM2837 ARM Peripherals manual . Because of the hardware quirks (e.g. many irqs are routed from GPU to CPU), the interrupt controller organizes irq sources into three groups and has registers for controlling/checking individual groups. Be aware of their weird naming: these irq groups are called \"Basic\" (irqs routed to the ARM CPU), \"1\", and \"2\" (irqs routed from GPU to CPU). For example, IRQ basic pending , IRQ pending 1 , IRQ pending 2 . The SoC manual has more dirty details. We are only interested in timer interrupts. The SoC manual, page 113 states that irq #1 and #3 are from the system timer. These irq sources belong to the irq group 1, which can be enabled using ENABLE_IRQS_1 . So enable_interrupt_controller() enables system timer IRQ at #1: void enable_interrupt_controller() { put32(ENABLE_IRQS_1, SYSTEM_TIMER_IRQ_1); }","title":"Configuring the Interrupt controller"},{"location":"rpi-os/#maskingunmasking-interrupts","text":"From time to time, the kernel must mask/unmask ALL interrupts, so that some critical code regions will never be interrupted. For example, what happens if an interrupt occurs right in the middle of kernel_entry macro? The CPU state would be corrupted. Upon entry to ANY exception/interrupt, the processor automatically masks all interrupts so that the kernel can save the CPU state atomically. The kernel then unmasks exceptions (often interrupts) it wants to handle during the execution of the interrupt handler. Right before exiting the exception handling ( eret ), the kernel masks all interrupts again for atomic CPU state restore. Note: it is perfectly legal to have nested interrupts, i.e. handling another interrupt in the middle of an interrupt handler. Nested interrupts are NOT common: for simple designs, many kernels intentionally keep interrupt handlers very short so they can mask interrupts throughout an interrupt handler without delaying future interrupts too much. However, handling interrupts during exception handlers is VERY common. Syscalls are executed as exception handlers, during which the kernel must be responsive to interrupts. The following two functions (irq.S) mask and unmask interrupts. .globl enable_irq enable_irq: msr daifclr, #2 ret .globl disable_irq disable_irq: msr daifset, #2 ret Explanation: ARM processor state (PSTATE) has 4 bits holding mask status for different types of interrupts. D Masks debug exceptions. These are a special type of synchronous exceptions. For obvious reasons, it is not possible to mask all synchronous exceptions, but it is convenient to have a separate flag that can mask debug exceptions. A Masks SErrors . It is called A because SErrors sometimes are called asynchronous aborts. I Masks IRQs F Masks FIQs Now you can probably guess why registers that are responsible for changing interrupt mask status are called daifclr and daifset . Those registers set and clear interrupt mask status bits in the processor state. Why do we use constant value 2 in both of the functions? This is because we only want to set and clear the second ( I ) bit.","title":"Masking/unmasking interrupts"},{"location":"rpi-os/#the-irq-handler","text":"We have a single, common exception handler for handling all IRQs . This handler is defined here . void handle_irq(void) { unsigned int irq = get32(IRQ_PENDING_1); switch (irq) { case (SYSTEM_TIMER_IRQ_1): handle_timer_irq(); break; default: printf(\"Unknown pending irq: %x\\r\\n\", irq); } } In the handler, we need a way to figure out what IO device generated the interrupt. Interrupt controller can help us with this job: it has IRQ_PENDING_1 register that holds interrupt status for interrupts 0 - 31 . Using this register we can check whether the current interrupt was generated by the timer or by some other device and call device specific interrupt handler. Note, multiple interrupts can be pending at the same time. That's why each device specific interrupt handler must acknowledge that it completed handling the interrupt and only after that interrupt pending bit in IRQ_PENDING_1 will be cleared. Because of the same reason, for a production kernel you would probably want to wrap switch construct in the interrupt handler in a loop: in this way, you will be able to handle multiple interrupts during a single handler execution.","title":"The IRQ handler"},{"location":"rpi-os/#arms-generic-hardware-timer","text":"We use the Arm generic timer, which is part of Arm64 core design (i.e. not defined by SoC). This is nice, as the generic timers exist for all Armv8 CPUs. Your experiences will apply to other Armv8 SoCs as well. Arm's official webpage (ARM062-1010708621-30) describes the use of generic timers. The following figure shows the generic timer hardware. In a nutshell, a global, chip-level hardware counter (i.e. \"System Counter\") drives per-core timer instances. As hardware boots, System Counter keeps incrementing, i.e. free running. Software can read the current System Counter. But System Counter alone does not generate interrupts. Software must program the timers so that they interrupt corresponding CPU cores at specific time intervals. Note: PE means CPU cores. As our kernel only deals with one core, we focus on one timer instance. How should the kernel program the timer? The timer provides two core registers (among others) as two alternative ways for programming the same timer. They are intuitive: CVAL, a 64-bit comparator. Roughly, this sets a \"threshold\" for System Counter: Example: The kernel writes a value X to CVAL. When System Counter exceeds X, the timer generates an interrupt. TVAL, a 32-bit timer value. Roughly, this sets a \"delta\" for System Counter: Example: The kernel writes a value X to TVAL. The hardware updates CVAL += the Current System Counter + TVAL. The timer generates an interrupt according to the new CVAL. The above brief description would suffice in our kernel experiment. Beyond them, TVAL has another less intuitive, \"countdown\" function (not used in this experiment but good to know). Since the last write by software, TVAL decrements as System Counter increments. The moment TVAL counts down to 0 is when an interrupt fires. After that, TVAL will keep counting down to a minus value. To summarize: If software needs a timer event in X ticks of the clock, the software can write X to TVAL periodically. Alternatively, if software wants an event when the system count reaches Y, software can write Y to CVAL. If software wants to know the remaining ticks until the next interrupt, the software reads from TVAL.","title":"Arm's generic hardware timer"},{"location":"rpi-os/#initialize-timer-timers","text":"By programming the timer device, We turn on the timer and allow it to generate interrupts. gen_timer_init: mov x0, #1 msr CNTP_CTL_EL0, x0 ret This writes 1 to the control register ( CNTP_CTL_EL0 ) of the EL1 physical timer . See here for the register definition. How to interpret the register name \"CNTP_CTL_EL0\": CTL indicates this is a control register; CNTP_XXX_EL0 indicates that this is for the EL1 physical timer. Why _EL0? I guess it means that the timer is accessible to both EL1 and EL0. See the table below. Register Purpose <timer>_CTL_EL<x> Control register <timer>_CVAL_EL<x> Comparator value <timer>_TVAL_EL<x> Timer value Timer Register prefix EL<x> EL1 physical timer CNTP EL0 EL1 virtual time CNTV EL0 Non-secure EL2 physical timer CNTHP EL2 Non-secure EL2 virtual timer CNTHV EL2 EL3 physical timer CNTPS EL1 Secure EL2 physical timer CNTHPS EL2 Secure EL2 virtual timer CNTHVS EL2","title":"Initialize timer (timer.S)"},{"location":"rpi-os/#turn-on-timer-interrupt-at-the-cpu-core","text":"We have to deal with yet another Rpi3 quirk. The Arm generic timer IRQs are wired to a per-core interrupt controller/register. For core 0, this is TIMER_INT_CTRL_0 at 0x40000040; bit 1 is for physical timer at EL1 (CNTP). This register is documented in the manual of BCM2836 (search for \"Core timers interrupts\"). Note the manual is NOT for the BCM2837 SoC used by Rpi3. I have no idea how community figured this out. void enable_interrupt_controller() { // Enables Core 0 Timers interrupt control for the generic timer put32(TIMER_INT_CTRL_0, TIMER_INT_CTRL_0_VALUE); } To summarize : we have to program three places in order to receive the timer interrupts: the timer device, the per-core interrupt controller, and the core itself (DAIF).","title":"Turn on timer interrupt at the CPU core"},{"location":"rpi-os/#handing-timer-interrupts","text":"The kernel gets an irq. The kernel check if it comes from the timer; if so, the kernel sets the timer for firing the next interrupt. void handle_irq(void) { // Each Core has its own pending local intrrupts register unsigned int irq = get32(INT_SOURCE_0); switch (irq) { case (GENERIC_TIMER_INTERRUPT): handle_generic_timer_irq(); break; ... The EL1h exception handler invokes the above function. The function reads INT_SOURCE_0 (0x4000:0060), search for \"Core interrupt sources\" in the BCM2836 manual ), where bit 1 is for our CNTP timer.","title":"Handing timer interrupts"},{"location":"rpi-os/#reset-timer-timers","text":"The kernel writes a delta value (1<<24) to TVAL, requesting an interrupt to fire after 1<<24 ticks. gen_timer_reset: mov x0, #1 lsl x0, x0, #24 msr CNTP_TVAL_EL0, x0 ret","title":"Reset timer (timer.S)"},{"location":"rpi-os/#timers-on-rpi3","text":"There are other timers on Rpi3 which you may see from various online blogs/tutorials/forums. The information can be very confusing. The naming of timers does NOT help. I list them below together with Arm generic timers described above. I suggest you stay away from other timers because the experience will not be as useful. Name Implemented by IRQ QEMU support? (v5.0 ) Phys Addr Document System Timer Broadcom (?) Global. In GPU irq space Implemented as bcm2835_systmr. However free running and cannot generate irq . 3f003000 BCM2837 ARM timer Arm ip (sp804) Global. In Arm core's private irq space (\"Basic irqs\") Unimplemented. See QEMU code bcm2835_peripherals.c 3f00b400 BCM2836 Local timer Broadcom (?) Per core Partially implemented . Can generate trigger irq but readback seems unsupported. 40000034 BCM2836 Arm generic timer Arm, as part of armv8 Per core Implemented 40000040 Armv8 doc + BCM2836 for IRQ routing","title":"Timers on Rpi3"},{"location":"rpi-os/#fyi-programming-the-rpi3s-system-timer-not-used-in-this-experiment","text":"Raspberry Pi system timer is a very simple device. It has a counter that increases its value by 1 after each clock tick. It also has 4 interrupt lines that connect to the interrupt controller (so it can generate 4 different interrupts) and 4 corresponding compare registers. When the value of the counter becomes equal to the value stored in one of the compare registers the corresponding interrupt is fired. That's why, before we will be able to use system timer interrupts, we need to initialize one of the compare registers with a non-zero value, the larger the value is - the later an interrupt will be generated. This is done in timer_init function. const unsigned int interval = 200000; unsigned int curVal = 0; void timer_init ( void ) { curVal = get32(TIMER_CLO); curVal += interval; put32(TIMER_C1, curVal); } The first line reads current counter value, the second line increases it and the third line sets the value of the compare register for the interrupt number 1. By manipulating interval value you can adjust how soon the first timer interrupt will be generated. Finally, we got to the timer interrupt handler. It is actually very simple. void handle_timer_irq( void ) { curVal += interval; put32(TIMER_C1, curVal); put32(TIMER_CS, TIMER_CS_M1); printf(\"Timer iterrupt received\\n\\r\"); } Here we first update compare register so that that next interrupt will be generated after the same time interval. Next, we acknowledge the interrupt by writing 1 to the TIMER_CS register. In the documentation TIMER_CS is called \"Timer Control/Status\" register. Bits [0:3] of this register can be used to acknowledge interrupts coming from one of the 4 available interrupt lines.","title":"FYI: Programming the Rpi3's system timer (not used in this experiment)"},{"location":"rpi-os/#hacking-tips-tracing-interrupts-with-qemu","text":"qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img \\ -serial null -serial stdio \\ -d int -D test.log See the qmeu cheatsheet for more.","title":"Hacking tips -- tracing interrupts with QEMU"},{"location":"rpi-os/#conclusion","text":"The last thing that you might want to take a look at is the kernel_main function where all previously discussed functionality is orchestrated. After you compile and run the sample it should print \"Timer interrupt received\" message after an interrupt is taken. Please, try to do it by yourself and don't forget to carefully examine the code and experiment with it.","title":"Conclusion"},{"location":"ssh-proxy/","text":"Accessing the course server(s) This document describes server resources and how to connect for development. Projects hardware specs OS granger1.cs.virginia.edu p1-p4 Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS granger2.cs.virginia.edu p1-p4 Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS ~~labsrv06.cs.virginia.edu (out of service)~~ All but p2 Single Xeon Silver 4410 CPU (8c16t), 8 cores Ubuntu 20.04 LTS These servers are behind the campus firewall. You need to first SSH to portal.cs.virginia.edu , and from there SSH over to the course servers, e.g. labsrv06. This is described here . WARNING: portal is managed by the UVA IT. You use your existing computing ID & password. The course server is managed by cs4414 staff. Use the credentials that we share with you. Figure above: your local machine, the portal, and the server. Texts on the bottom: key files and their purpose. Terminal over SSH $ ssh xl6yq@portal.cs.virginia.edu (type in password...) Warning: No xauth data; using fake authentication data for X11 forwarding. Last login: Sun Jan 24 16:48:29 2021 from c-71-62-166-85.hsd1.va.comcast.net ********************************** ********************** Type \"module avail\" to see software available. See: www.cs.virginia.edu/computing for more information. $ ssh xl6yq@granger1.cs.virginia.edu (type in password...) Welcome to Ubuntu 20.04 LTS (GNU/Linux 5.4.0-45-generic x86_64) Connecting to the course servers can be automated. The picture shows the final results: From a local terminal (e.g. my minibox), connecting to a course server by simply typing ssh granger1 . Read on for how to configure. 1. Use key-based authentication in lieu of password Applicable local environment: Linux, MacOS, & Windows (WSL) The pub key on your local machine is at ~/.ssh/id_rsa.pub . Check out the file & its content. If it does not exist, generate a pub key by running ssh-keygen . # on the local console (Linux or WSL) $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/xzl/.ssh/id_rsa): Now, append your public key to both portal and granger1 ( ~/.ssh/authorized_keys ). Don't do this manually. Instead, do so by the command ssh-copy-id . For instance: # copy the pubkey from your local machine to portal $ ssh-copy-id xl6yq@portal.cs.virginia.edu (... type in password ...) # connect to \"portal\", it should no longer ask for password $ ssh xl6yq@portal.cs.virginia.edu # now we are on \"portal\". generate a new pair of public/private keys, which will be used between portal and granger1 $ ssh-keygen # copy the new public key from portal to granger1 $ ssh-copy-id xl6yq@granger1.cs.virginia.edu (... type in password ...) # it should no longer ask for password $ ssh xl6yq@granger1.cs.virginia.edu An alternative procedure (02/07/21) Credits Peiyi Yang, TA 2021. Started from scratch. First edited the ssh config file on the local computer saying to jump through portal when going to granger1. Then ran ssh-copy-id id@portal and entered the password to install the local's pubkey on portal. Then from local, ran ssh-copy-id id@granger1 and entered the password to install the local's pubkey on granger1. So there is only one key pair. The pubkey is copied to portal and then to granger1. Troubleshooting: the server still asks for password? Let's use granger1 as an example. On granger1, check the content of ~/.ssh/authorized_keys. You should see your public key saved there. For instance, mine is: $ cat ~/.ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCkkCZ2PO7GdX5CBL26zcIFz4XgMiHSQjaU32evuidvMXsC ZExT9QHl3Ou00QfuagmfebugxB0aruGAsKmBxEBmlj0r1uAVCekYaIn8IPA5jynQnDRDdIABaZBWlsPx9jKo KQqLlKgdG4JziQOAr0HaUgr+oIXgRUq7V/W1OhV9SQVF+vcIy8vVwNdLBNdbw/GtU0oKb76yxfXOC/VZM7eZ xhovb/J450U5Op8tL/+Lg5x2sJKqR2juCFAicGbVNuXXazEDrXHgDQp+WQS8rYK4Zs95KqAsMfxvsFSbs8lf h0pIs+sozBNUt+1noJkcyLfxhzu0yGEsxMULHE/KdAst xl6yq@portal03 \"xl6yq@portal03\" is the textual tag of the pubkey, indicating it is a pubkey generated on portal.cs On granger1, check the permission of ~/.ssh. It should be: $ ls -la ~ | grep .ssh drwx------ Check the permission of ~/.ssh/authorized_keys. It should be: $ ls -l ~/.ssh/authorized_keys -rw------- If none of the above works, you can put ssh in the verbose mode to see what's going on. From portal , type ssh -vv granger1.cs.virginia.edu Explanation: -vv tells ssh to dump its interactions with granger1 on negotiating keys. As a reference, my output is here . At the end of the output, you can see granger1 accepts my key offered from portal. Can do password-less authentication between local/portal and between portal/granger[12], but are still required to enter password between local/granger? From your local machine, type ssh -vv granger1.cs.virginia.edu And compare line-by-line with the output to the reference output here . Note to Windows Users : if you try to invoke ssh-copy-id that comes with Windows (the one you can invoke in PowerShell, not the one in WSL), there may be some caveats. See here . I would say just invoke ssh-copy-id in WSL. 2. Save connection info in SSH config Append the following to your ssh client configuration ( ~/.ssh/config ). Replace USERNAME with your actual username : Host granger1 User USERNAME HostName granger1.cs.virginia.edu ProxyJump USERNAME@portal.cs.virginia.edu:22 With the configuration, your local ssh client knows that when connecting to host granger1 , use portal as the jump proxy. So you can directly connect to granger1 from your local machine: $ ssh granger1 Aside: a one-liner for connecting to course servers $ ssh -l USERNAME granger1.cs.virginia.edu -J portal.cs.virginia.edu The -J option is available with your local ssh client OpenSSH >= 7.3p1. See here for more details. For instance, my version: $ ssh -V OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017 Remote development with VSCode Many students may prefer VSCode. Here is how to make it work for our kernel hacking. End results: being able to develop, compile, and do version control from VSCode. See an example screenshot below. So we will use VSCode's official Remote.SSH extension. I do not recommend 3rd party extensions, e.g. sftp. An official tutorial is here . tl;dr: VSCode will connect to the course server (Linux) using SSH under the hood. To do so you install the \"Remote development\" package which will install the \"Remote.SSH\" extension for VSCode. Screenshot from Peiyi Yang (py5yy@). Her VSCode color scheme is different from mine. Windows caveat 1: ssh keys The extension (Remote.SSH) will invoke Window's ssh client ( c:\\Windows\\System32\\OpenSSH\\ssh.exe ).The Window's ssh client expects its config file at C:\\Users\\%USERNAME%\\.ssh\\config . This is NOT the ssh client you run from WSL. If you haven't generated your SSH keys so far, you can do so by launching a PowerShell console and run ssh-keygen there. Launch PowerShell ssh-keygen in PowerShell Access WSL root Or, you can you copy existing ssh keys and config (e.g. from WSL ~/.ssh/ ) to the location mentioned above. Btw, the way to access WSL's root filesystem is to type \\\\wsl$ in the explorer address bar. See the figure above. Windows caveat 2: an outdated ssh client The current VSCode has a bug that breaks ssh with jumphost. You have to manually fix it by following this . In a nutshell, manual download a newer win32 ssh to overwrite the one shipping with Win 10 (it's a good idea to save a back up). Window's security mechanism is in your way. Work around it. Note : 1. Make sure to download the OpenSSH-Win64 version (not Win32). 2. Double check the SSH version. See the screenshot below. Turning off protection on ssh.exe (see link above) The newer ssh client manually installed Now, you should be good to go with VSCode. Make sure you have the Remote.SSH extension installed. Click \"Remote Explorer\" on the left bar. The extension will pick up your ssh config file (again that's C:/Users/%USERNAME%/.ssh/config ) and present a list of hosts recognized. Click one to connect to it. The extension will copy a bunch of stuffs to the host and launch some daemon on the host. Then you are connected. Password-less login used to work fine, but suddenly breaks? A common cause is that VSCode updates automatically, overwriting the ssh client you manually installed. Solution: check your ssh version and use the one we suggested. Launch a terminal After connection, click \"remote\" on the left bar to bring up a remote terminal, in which you can execute commands to build projects, etc. Make sure to click the \"+\" sign to create a new shell terminal. File browsing & editing Then you will specify a remote folder on the server to \"open\": To browse & edit files on the server, click \"explorer\" on the left bar Click \"source control\" on the left bar for a handy git interface. Troubleshooting Windows auto update may break VSCode's ssh configuration that worked previously. In this case, deleting (or moving to other places) the .vscode-server folder on granger and portal may solved the problem. If things break, report: the error message of VSCode the PowerShell output when you try to connect to granger1 from the PowerShell command line the PowerShell output when you try to connect to cs portal from the PowerShell command line any recent Windows/VSCode updates","title":"/ssh"},{"location":"ssh-proxy/#accessing-the-course-servers","text":"This document describes server resources and how to connect for development. Projects hardware specs OS granger1.cs.virginia.edu p1-p4 Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS granger2.cs.virginia.edu p1-p4 Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS ~~labsrv06.cs.virginia.edu (out of service)~~ All but p2 Single Xeon Silver 4410 CPU (8c16t), 8 cores Ubuntu 20.04 LTS These servers are behind the campus firewall. You need to first SSH to portal.cs.virginia.edu , and from there SSH over to the course servers, e.g. labsrv06. This is described here . WARNING: portal is managed by the UVA IT. You use your existing computing ID & password. The course server is managed by cs4414 staff. Use the credentials that we share with you. Figure above: your local machine, the portal, and the server. Texts on the bottom: key files and their purpose.","title":"Accessing the course server(s)"},{"location":"ssh-proxy/#terminal-over-ssh","text":"$ ssh xl6yq@portal.cs.virginia.edu (type in password...) Warning: No xauth data; using fake authentication data for X11 forwarding. Last login: Sun Jan 24 16:48:29 2021 from c-71-62-166-85.hsd1.va.comcast.net ********************************** ********************** Type \"module avail\" to see software available. See: www.cs.virginia.edu/computing for more information. $ ssh xl6yq@granger1.cs.virginia.edu (type in password...) Welcome to Ubuntu 20.04 LTS (GNU/Linux 5.4.0-45-generic x86_64) Connecting to the course servers can be automated. The picture shows the final results: From a local terminal (e.g. my minibox), connecting to a course server by simply typing ssh granger1 . Read on for how to configure.","title":"Terminal over SSH"},{"location":"ssh-proxy/#1-use-key-based-authentication-in-lieu-of-password","text":"Applicable local environment: Linux, MacOS, & Windows (WSL) The pub key on your local machine is at ~/.ssh/id_rsa.pub . Check out the file & its content. If it does not exist, generate a pub key by running ssh-keygen . # on the local console (Linux or WSL) $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/xzl/.ssh/id_rsa): Now, append your public key to both portal and granger1 ( ~/.ssh/authorized_keys ). Don't do this manually. Instead, do so by the command ssh-copy-id . For instance: # copy the pubkey from your local machine to portal $ ssh-copy-id xl6yq@portal.cs.virginia.edu (... type in password ...) # connect to \"portal\", it should no longer ask for password $ ssh xl6yq@portal.cs.virginia.edu # now we are on \"portal\". generate a new pair of public/private keys, which will be used between portal and granger1 $ ssh-keygen # copy the new public key from portal to granger1 $ ssh-copy-id xl6yq@granger1.cs.virginia.edu (... type in password ...) # it should no longer ask for password $ ssh xl6yq@granger1.cs.virginia.edu An alternative procedure (02/07/21) Credits Peiyi Yang, TA 2021. Started from scratch. First edited the ssh config file on the local computer saying to jump through portal when going to granger1. Then ran ssh-copy-id id@portal and entered the password to install the local's pubkey on portal. Then from local, ran ssh-copy-id id@granger1 and entered the password to install the local's pubkey on granger1. So there is only one key pair. The pubkey is copied to portal and then to granger1.","title":"1. Use key-based authentication in lieu of password"},{"location":"ssh-proxy/#troubleshooting-the-server-still-asks-for-password","text":"Let's use granger1 as an example. On granger1, check the content of ~/.ssh/authorized_keys. You should see your public key saved there. For instance, mine is: $ cat ~/.ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCkkCZ2PO7GdX5CBL26zcIFz4XgMiHSQjaU32evuidvMXsC ZExT9QHl3Ou00QfuagmfebugxB0aruGAsKmBxEBmlj0r1uAVCekYaIn8IPA5jynQnDRDdIABaZBWlsPx9jKo KQqLlKgdG4JziQOAr0HaUgr+oIXgRUq7V/W1OhV9SQVF+vcIy8vVwNdLBNdbw/GtU0oKb76yxfXOC/VZM7eZ xhovb/J450U5Op8tL/+Lg5x2sJKqR2juCFAicGbVNuXXazEDrXHgDQp+WQS8rYK4Zs95KqAsMfxvsFSbs8lf h0pIs+sozBNUt+1noJkcyLfxhzu0yGEsxMULHE/KdAst xl6yq@portal03 \"xl6yq@portal03\" is the textual tag of the pubkey, indicating it is a pubkey generated on portal.cs On granger1, check the permission of ~/.ssh. It should be: $ ls -la ~ | grep .ssh drwx------ Check the permission of ~/.ssh/authorized_keys. It should be: $ ls -l ~/.ssh/authorized_keys -rw------- If none of the above works, you can put ssh in the verbose mode to see what's going on. From portal , type ssh -vv granger1.cs.virginia.edu Explanation: -vv tells ssh to dump its interactions with granger1 on negotiating keys. As a reference, my output is here . At the end of the output, you can see granger1 accepts my key offered from portal. Can do password-less authentication between local/portal and between portal/granger[12], but are still required to enter password between local/granger? From your local machine, type ssh -vv granger1.cs.virginia.edu And compare line-by-line with the output to the reference output here . Note to Windows Users : if you try to invoke ssh-copy-id that comes with Windows (the one you can invoke in PowerShell, not the one in WSL), there may be some caveats. See here . I would say just invoke ssh-copy-id in WSL.","title":"Troubleshooting: the server still asks for password?"},{"location":"ssh-proxy/#2-save-connection-info-in-ssh-config","text":"Append the following to your ssh client configuration ( ~/.ssh/config ). Replace USERNAME with your actual username : Host granger1 User USERNAME HostName granger1.cs.virginia.edu ProxyJump USERNAME@portal.cs.virginia.edu:22 With the configuration, your local ssh client knows that when connecting to host granger1 , use portal as the jump proxy. So you can directly connect to granger1 from your local machine: $ ssh granger1","title":"2. Save connection info in SSH config"},{"location":"ssh-proxy/#aside-a-one-liner-for-connecting-to-course-servers","text":"$ ssh -l USERNAME granger1.cs.virginia.edu -J portal.cs.virginia.edu The -J option is available with your local ssh client OpenSSH >= 7.3p1. See here for more details. For instance, my version: $ ssh -V OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017","title":"Aside: a one-liner for connecting to course servers"},{"location":"ssh-proxy/#remote-development-with-vscode","text":"Many students may prefer VSCode. Here is how to make it work for our kernel hacking. End results: being able to develop, compile, and do version control from VSCode. See an example screenshot below. So we will use VSCode's official Remote.SSH extension. I do not recommend 3rd party extensions, e.g. sftp. An official tutorial is here . tl;dr: VSCode will connect to the course server (Linux) using SSH under the hood. To do so you install the \"Remote development\" package which will install the \"Remote.SSH\" extension for VSCode. Screenshot from Peiyi Yang (py5yy@). Her VSCode color scheme is different from mine.","title":"Remote development with VSCode"},{"location":"ssh-proxy/#windows-caveat-1-ssh-keys","text":"The extension (Remote.SSH) will invoke Window's ssh client ( c:\\Windows\\System32\\OpenSSH\\ssh.exe ).The Window's ssh client expects its config file at C:\\Users\\%USERNAME%\\.ssh\\config . This is NOT the ssh client you run from WSL. If you haven't generated your SSH keys so far, you can do so by launching a PowerShell console and run ssh-keygen there. Launch PowerShell ssh-keygen in PowerShell Access WSL root Or, you can you copy existing ssh keys and config (e.g. from WSL ~/.ssh/ ) to the location mentioned above. Btw, the way to access WSL's root filesystem is to type \\\\wsl$ in the explorer address bar. See the figure above.","title":"Windows caveat 1: ssh keys"},{"location":"ssh-proxy/#windows-caveat-2-an-outdated-ssh-client","text":"The current VSCode has a bug that breaks ssh with jumphost. You have to manually fix it by following this . In a nutshell, manual download a newer win32 ssh to overwrite the one shipping with Win 10 (it's a good idea to save a back up). Window's security mechanism is in your way. Work around it. Note : 1. Make sure to download the OpenSSH-Win64 version (not Win32). 2. Double check the SSH version. See the screenshot below. Turning off protection on ssh.exe (see link above) The newer ssh client manually installed Now, you should be good to go with VSCode. Make sure you have the Remote.SSH extension installed. Click \"Remote Explorer\" on the left bar. The extension will pick up your ssh config file (again that's C:/Users/%USERNAME%/.ssh/config ) and present a list of hosts recognized. Click one to connect to it. The extension will copy a bunch of stuffs to the host and launch some daemon on the host. Then you are connected. Password-less login used to work fine, but suddenly breaks? A common cause is that VSCode updates automatically, overwriting the ssh client you manually installed. Solution: check your ssh version and use the one we suggested.","title":"Windows caveat 2: an outdated ssh client"},{"location":"ssh-proxy/#launch-a-terminal","text":"After connection, click \"remote\" on the left bar to bring up a remote terminal, in which you can execute commands to build projects, etc. Make sure to click the \"+\" sign to create a new shell terminal.","title":"Launch a terminal"},{"location":"ssh-proxy/#file-browsing-editing","text":"Then you will specify a remote folder on the server to \"open\": To browse & edit files on the server, click \"explorer\" on the left bar Click \"source control\" on the left bar for a handy git interface.","title":"File browsing &amp; editing"},{"location":"ssh-proxy/#troubleshooting","text":"Windows auto update may break VSCode's ssh configuration that worked previously. In this case, deleting (or moving to other places) the .vscode-server folder on granger and portal may solved the problem. If things break, report: the error message of VSCode the PowerShell output when you try to connect to granger1 from the PowerShell command line the PowerShell output when you try to connect to cs portal from the PowerShell command line any recent Windows/VSCode updates","title":"Troubleshooting"},{"location":"workflow/","text":"Simplifying the dev workflow This is for developing for the actual Rpi3 hardware. Does not apply if you use QEMU. Motivation You may have found that building & testing the kernel requires tedious manual effort. Here are some steps to simplify the workflow, so that we can focus on kernel hacking. You should proceed only after having verified your hardware setup is correct. Is it safe to ...? Unplug the micro SD card (uSD) when Rpi3 is powered on? Safe . Doing so when Rpi3 runs a full-fledged OS, e.g. Raspbian OS, may corrupt data because the OS caches data in memory. Our tiny kernel does not attempt to write any data to the micro SD. Plug in a micro SD card when Rpi3 is powered on? Safe . Then you can power-cycle the Rpi3 so Disconnect the serial cable when Rpi3 is on? Safe . If your Rpi3 is powered over the serial cable -- no state to lose. If you Rpi3 is powered over micro USB: why disconnect the serial cable frequently? Unplug micro SD from PC without \"ejecting/unmounting\" from the PC OS? Safe . See here . The manual workflow (Once) Connect Rpi3 and PC via the serial cable. Repeat: Modify our kernel source if needed. Make kernel8.img Unplug uSD from Rpi3. Rpi3 does not have to be powered off. Plug in uSD to the card reader on PC. Copy kernel8.img to the uSD's boot partition. Overwrite the previous kernel8.img. Eject/umount uSD from PC. Plug in uSD to Rpi3. Power-cycle Rpi3. Wait for the kernel to execute. See output. Reason about it. The automated workflow Depending on your PC OS: Linux: there's a Python script which you can adapt. Windows (WSL): (contribute your experience) OSX: (contribute your experience)","title":"Simplifying the dev workflow"},{"location":"workflow/#simplifying-the-dev-workflow","text":"This is for developing for the actual Rpi3 hardware. Does not apply if you use QEMU.","title":"Simplifying the dev workflow"},{"location":"workflow/#motivation","text":"You may have found that building & testing the kernel requires tedious manual effort. Here are some steps to simplify the workflow, so that we can focus on kernel hacking. You should proceed only after having verified your hardware setup is correct.","title":"Motivation"},{"location":"workflow/#is-it-safe-to","text":"","title":"Is it safe to ...?"},{"location":"workflow/#unplug-the-micro-sd-card-usd-when-rpi3-is-powered-on","text":"Safe . Doing so when Rpi3 runs a full-fledged OS, e.g. Raspbian OS, may corrupt data because the OS caches data in memory. Our tiny kernel does not attempt to write any data to the micro SD.","title":"Unplug the micro SD card (uSD) when Rpi3 is powered on?"},{"location":"workflow/#plug-in-a-micro-sd-card-when-rpi3-is-powered-on","text":"Safe . Then you can power-cycle the Rpi3 so","title":"Plug in a micro SD card when Rpi3 is powered on?"},{"location":"workflow/#disconnect-the-serial-cable-when-rpi3-is-on","text":"Safe . If your Rpi3 is powered over the serial cable -- no state to lose. If you Rpi3 is powered over micro USB: why disconnect the serial cable frequently?","title":"Disconnect the serial cable when Rpi3 is on?"},{"location":"workflow/#unplug-micro-sd-from-pc-without-ejectingunmounting-from-the-pc-os","text":"Safe . See here .","title":"Unplug micro SD from PC without \"ejecting/unmounting\" from the PC OS?"},{"location":"workflow/#the-manual-workflow","text":"(Once) Connect Rpi3 and PC via the serial cable. Repeat: Modify our kernel source if needed. Make kernel8.img Unplug uSD from Rpi3. Rpi3 does not have to be powered off. Plug in uSD to the card reader on PC. Copy kernel8.img to the uSD's boot partition. Overwrite the previous kernel8.img. Eject/umount uSD from PC. Plug in uSD to Rpi3. Power-cycle Rpi3. Wait for the kernel to execute. See output. Reason about it.","title":"The manual workflow"},{"location":"workflow/#the-automated-workflow","text":"Depending on your PC OS: Linux: there's a Python script which you can adapt. Windows (WSL): (contribute your experience) OSX: (contribute your experience)","title":"The automated workflow"},{"location":"lesson00/rpi-os/","text":"0: Sharpen your tools Get the code : git clone https://github.com/fxlin/p1-kernel Terms baremetal; kernel; kernel binary; kernel image Dev environment This is where you develop kernel code. If you build kernel for Rpi3 ... Note: Recommended configurations are underscored . How to connect to CS server(s): see here . VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below. Your local machine runs: Develop remotely on CS servers Develop locally Windows WSL for SSH shell; then download (scp) kernel binary to local WSL for toolchain Linux SSH shell; then download (scp) kernel binary to local Native toolchain + console Mac Terminal for SSH shell HomeBrew (untested) If you build kernel for QEMU ... Note: Recommended configurations are underscored . How to connect to CS server(s): see here . VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below. Your local machine runs: If develop remotely on CS servers If develop on your local machine Windows WSL for SSH shell WSL for toolchain. gdbserver could be tricky. Linux SSH shell Native toolchain + console Mac Terminal for SSH shell HomeBrew (untested) Toolchain These are compiler, linker, etc. for us to generate the kernel code. Use the one provided by Ubuntu. # this is necessary only when you develop kernel code on your local machine # the server already has the toolchain installed $ sudo apt install gcc-aarch64-linux-gnu $ sudo apt install gdb-multiarch $ aarch64-linux-gnu-gcc --version aarch64-linux-gnu-gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0 Test Platform This is where you run the kernel code. Approach 1: the real hardware Check list Required: An Rpi3 board (Model B or B+) link Required: A USB-serial cable Amazon . Connection inside the dongle: black-GND; green-TXD; white-RXD; red-VCC. Required: A micro SD card. The capacity can be humble (e.g. 4GB). The speed does not matter much. The one I used was $6. Rpi's official page about uSD Required: SD card reader. To be plugged in your PC for loading kernel to the micro SD card. A cheap one can be $7 on Amazon Recommended: A micro USB cable for powering Rpi3. Prep Raspberry Pi 3 Model B Older versions of Raspberry Pi are not going to work with this tutorial because all lessons are designed to use a 64-bit processor that supports ARMv8 architecture, and such processor is only available in the Raspberry Pi 3. Newer versions, including Raspberry Pi 3 Model B+ should work fine. Load Raspbian OS to the SD card Raspbian is a Debian-based Linux distro. It's the official OS for Rpi3. Why we need Raspbian? 1. to test USB to TTL cable connectivity initially. 2. after installing Raspbian, the SD card is formatted in the right way. All the proprietary binary blobs needed to boot Rpi3 are also in place. Load the SD card with Raspbian OS. Follow the official instructions . Plug in the serial cable Rpi3 <-- a USB-serial cable ---> PC (running a temrinal emulator) After you get a serial cable, you need to test your connection. If you never did this before I recommend you to follow this guide It describes the process of connecting your Raspberry PI via a serial cable in great details. Basically, you run Raspberry's official OS to ensure the hardware setup is fine. Configure the serial emulator on your PC Linux users: minicom recommended. sudo minicom -b 115200 -o -D /dev/ttyUSB0 -C /tmp/minicom.log Note: your PC may give different names to the USB-serial dongle, e.g. /dev/ttyUSB1. Find it out by looking at dmesg output. Windows users (including WSL): PuTTY recommended. A sample configuration below. Note: your PC may give different names to the USB-serial dongle, e.g. COM4. Find it out by looking at Windows Device Manager. Powering up RPi3 We recommend you power Rpi3 through its micro USB port. Perhaps use a flip switch on the other side of the USB power for power cycling Rpi3. The guide above also describes how to power your Raspberry Pi using a serial cable. RPi OS works fine with such kind of setup, however, in this case, you need to run your terminal emulator right after you plug in the cable. Check this issue for details. Rpi3 <-- micro USB ---> PC Rpi3 <-- micro USB ---> Wall charger Power cycling Rpi3, you should see Linux kernel console output on PC terminal. An example setup This is my desktop when I hack with the Rpi3 kernel. Test your dev workflow Background: what's on SD card? On powering up, Rpi3 looks for the following files on boot partition of the SD card. bootcode.bin: the proprietary bootloader for enabling SDRAM. This comes with Raspbian. start.elf: the proprietary firmware loaded by the bootloader. Using the updated Raspbian OS. This comes with Raspbian. fixup.dat: needed to use 1GB of memory. This comes with Raspbian. config.txt: to be parsed by start.elf and decide boot behavior. It offers a great deal of options which is pretty cool. A default one comes with Raspbian. This file is to be customized by us kernel8.img: our kernel. Summary: we need to change config.txt (once) and kernel8.img (every time we re-compile kernel) on the SD card. Update config.txt Plug the SD card to PC via the card reader. Open config.txt which is on the boot partition. The following two lines are crucial. Add them to config.txt. arm_64bit=1 enable_uart=1 Note: multiple online tutorials advise options like kernel_old=1 or arm_control . You do NOT need those. With our options in config.txt above, Rpi3 will load the kernel named kernel8.img to 0x80000 . Check the official doc for config.txt above. Look for kernel_address . Ref: the official doc for config.txt. Build & load sample baremetal program ... to ensure our toolchain works fine. git clone git@github.com:fxlin/raspi3-tutorial.git cd raspi3-tutorial git checkout b026449 cd 05_uart0 make Note : the repo above (raspi3-tutorial.git) is NOT our project repo. It's someone's code for testing rpi3 hardware. We are just using for testing ONLY. Copy kernel8.img to the SD card. Eject the SD card from PC. Plug the SD to Rpi3. Make sure the serial connection is good and terminal emulator on your PC is ready. Power cycle Rpi3. You should see something like: (Your serial number may be different) Viola! You just built your first baremetal program for Rpi3! Approach 2: QEMU Compile QEMU from source This is required no matter you develop on local machines or on the server. Clean any pre-installed qemu and install necessary tools: # this is necessary only when you develop kernel code on your own machine (not recommended) # the server already has these software uninstalled/installed sudo apt remove qemu-system-arm sudo apt install gdb-multiarch build-essential pkg-config sudo apt install libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev Grab the QEMU source. Our QEMU is based on upstream v4.2 with custom aarch64 debugging support. git clone https://github.com/fxlin/qemu-cs4414.git qemu cd qemu ./configure --target-list=aarch64-softmmu make -j`nproc` export PATH=\"$(pwd)/aarch64-softmmu:${PATH}\" If successful, this will result in QEMU executables in ./aarch64-softmmu/. The last line above adds the path to our search path. If you encounter compilation errors (e.g. unmet dependencies), make sure you run all apt get commands above. Now try QEMU & check its version. The supported machines should include Rpi3 $ qemu-system-aarch64 --version QEMU emulator version 5.0.50 (v5.0.0-1247-gaf6f75d03f-dirty) Copyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers patched for cs4414/6456 aarch64 kernel hacking $ qemu-system-aarch64 -M help|grep rasp raspi2 Raspberry Pi 2B raspi3 Raspberry Pi 3B Test the compilation Test QEMU with Rpi3 baremetal code (NOTE: this repo is for validating your toolchain & QEMU build; it is NOT our course project) git clone https://github.com/fxlin/raspi3-tutorial.git cd raspi3-tutorial git checkout b026449 cd 05_uart0 make qemu-system-aarch64 -M raspi3 -kernel kernel8.img -serial stdio If everything works fine, you should see QMEU print out: My serial number is: 0000000000000000 Note: the test program runs an infinite loop which will cause high CPU usage on your host machine. Kill the test program timely. On Linux: On Windows (WSL) Move to the QEMU cheatsheet .","title":"exp0"},{"location":"lesson00/rpi-os/#0-sharpen-your-tools","text":"Get the code : git clone https://github.com/fxlin/p1-kernel","title":"0: Sharpen your tools"},{"location":"lesson00/rpi-os/#terms","text":"baremetal; kernel; kernel binary; kernel image","title":"Terms"},{"location":"lesson00/rpi-os/#dev-environment","text":"This is where you develop kernel code.","title":"Dev environment"},{"location":"lesson00/rpi-os/#if-you-build-kernel-for-rpi3","text":"Note: Recommended configurations are underscored . How to connect to CS server(s): see here . VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below. Your local machine runs: Develop remotely on CS servers Develop locally Windows WSL for SSH shell; then download (scp) kernel binary to local WSL for toolchain Linux SSH shell; then download (scp) kernel binary to local Native toolchain + console Mac Terminal for SSH shell HomeBrew (untested)","title":"If you build kernel for Rpi3 ..."},{"location":"lesson00/rpi-os/#if-you-build-kernel-for-qemu","text":"Note: Recommended configurations are underscored . How to connect to CS server(s): see here . VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below. Your local machine runs: If develop remotely on CS servers If develop on your local machine Windows WSL for SSH shell WSL for toolchain. gdbserver could be tricky. Linux SSH shell Native toolchain + console Mac Terminal for SSH shell HomeBrew (untested)","title":"If you build kernel for QEMU ..."},{"location":"lesson00/rpi-os/#toolchain","text":"These are compiler, linker, etc. for us to generate the kernel code. Use the one provided by Ubuntu. # this is necessary only when you develop kernel code on your local machine # the server already has the toolchain installed $ sudo apt install gcc-aarch64-linux-gnu $ sudo apt install gdb-multiarch $ aarch64-linux-gnu-gcc --version aarch64-linux-gnu-gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0","title":"Toolchain"},{"location":"lesson00/rpi-os/#test-platform","text":"This is where you run the kernel code.","title":"Test Platform"},{"location":"lesson00/rpi-os/#approach-1-the-real-hardware","text":"","title":"Approach 1: the real hardware"},{"location":"lesson00/rpi-os/#check-list","text":"Required: An Rpi3 board (Model B or B+) link Required: A USB-serial cable Amazon . Connection inside the dongle: black-GND; green-TXD; white-RXD; red-VCC. Required: A micro SD card. The capacity can be humble (e.g. 4GB). The speed does not matter much. The one I used was $6. Rpi's official page about uSD Required: SD card reader. To be plugged in your PC for loading kernel to the micro SD card. A cheap one can be $7 on Amazon Recommended: A micro USB cable for powering Rpi3.","title":"Check list"},{"location":"lesson00/rpi-os/#prep-raspberry-pi-3-model-b","text":"Older versions of Raspberry Pi are not going to work with this tutorial because all lessons are designed to use a 64-bit processor that supports ARMv8 architecture, and such processor is only available in the Raspberry Pi 3. Newer versions, including Raspberry Pi 3 Model B+ should work fine.","title":"Prep Raspberry Pi 3 Model B"},{"location":"lesson00/rpi-os/#load-raspbian-os-to-the-sd-card","text":"Raspbian is a Debian-based Linux distro. It's the official OS for Rpi3. Why we need Raspbian? 1. to test USB to TTL cable connectivity initially. 2. after installing Raspbian, the SD card is formatted in the right way. All the proprietary binary blobs needed to boot Rpi3 are also in place. Load the SD card with Raspbian OS. Follow the official instructions .","title":"Load Raspbian OS to the SD card"},{"location":"lesson00/rpi-os/#plug-in-the-serial-cable","text":"Rpi3 <-- a USB-serial cable ---> PC (running a temrinal emulator) After you get a serial cable, you need to test your connection. If you never did this before I recommend you to follow this guide It describes the process of connecting your Raspberry PI via a serial cable in great details. Basically, you run Raspberry's official OS to ensure the hardware setup is fine.","title":"Plug in the serial cable"},{"location":"lesson00/rpi-os/#configure-the-serial-emulator-on-your-pc","text":"Linux users: minicom recommended. sudo minicom -b 115200 -o -D /dev/ttyUSB0 -C /tmp/minicom.log Note: your PC may give different names to the USB-serial dongle, e.g. /dev/ttyUSB1. Find it out by looking at dmesg output. Windows users (including WSL): PuTTY recommended. A sample configuration below. Note: your PC may give different names to the USB-serial dongle, e.g. COM4. Find it out by looking at Windows Device Manager.","title":"Configure the serial emulator on your PC"},{"location":"lesson00/rpi-os/#powering-up-rpi3","text":"We recommend you power Rpi3 through its micro USB port. Perhaps use a flip switch on the other side of the USB power for power cycling Rpi3. The guide above also describes how to power your Raspberry Pi using a serial cable. RPi OS works fine with such kind of setup, however, in this case, you need to run your terminal emulator right after you plug in the cable. Check this issue for details. Rpi3 <-- micro USB ---> PC Rpi3 <-- micro USB ---> Wall charger Power cycling Rpi3, you should see Linux kernel console output on PC terminal.","title":"Powering up RPi3"},{"location":"lesson00/rpi-os/#an-example-setup","text":"This is my desktop when I hack with the Rpi3 kernel.","title":"An example setup"},{"location":"lesson00/rpi-os/#test-your-dev-workflow","text":"","title":"Test your dev workflow"},{"location":"lesson00/rpi-os/#background-whats-on-sd-card","text":"On powering up, Rpi3 looks for the following files on boot partition of the SD card. bootcode.bin: the proprietary bootloader for enabling SDRAM. This comes with Raspbian. start.elf: the proprietary firmware loaded by the bootloader. Using the updated Raspbian OS. This comes with Raspbian. fixup.dat: needed to use 1GB of memory. This comes with Raspbian. config.txt: to be parsed by start.elf and decide boot behavior. It offers a great deal of options which is pretty cool. A default one comes with Raspbian. This file is to be customized by us kernel8.img: our kernel. Summary: we need to change config.txt (once) and kernel8.img (every time we re-compile kernel) on the SD card.","title":"Background: what's on SD card?"},{"location":"lesson00/rpi-os/#update-configtxt","text":"Plug the SD card to PC via the card reader. Open config.txt which is on the boot partition. The following two lines are crucial. Add them to config.txt. arm_64bit=1 enable_uart=1 Note: multiple online tutorials advise options like kernel_old=1 or arm_control . You do NOT need those. With our options in config.txt above, Rpi3 will load the kernel named kernel8.img to 0x80000 . Check the official doc for config.txt above. Look for kernel_address . Ref: the official doc for config.txt.","title":"Update config.txt"},{"location":"lesson00/rpi-os/#build-load-sample-baremetal-program","text":"... to ensure our toolchain works fine. git clone git@github.com:fxlin/raspi3-tutorial.git cd raspi3-tutorial git checkout b026449 cd 05_uart0 make Note : the repo above (raspi3-tutorial.git) is NOT our project repo. It's someone's code for testing rpi3 hardware. We are just using for testing ONLY. Copy kernel8.img to the SD card. Eject the SD card from PC. Plug the SD to Rpi3. Make sure the serial connection is good and terminal emulator on your PC is ready. Power cycle Rpi3. You should see something like: (Your serial number may be different) Viola! You just built your first baremetal program for Rpi3!","title":"Build &amp; load sample baremetal program"},{"location":"lesson00/rpi-os/#approach-2-qemu","text":"","title":"Approach 2: QEMU"},{"location":"lesson00/rpi-os/#compile-qemu-from-source","text":"This is required no matter you develop on local machines or on the server. Clean any pre-installed qemu and install necessary tools: # this is necessary only when you develop kernel code on your own machine (not recommended) # the server already has these software uninstalled/installed sudo apt remove qemu-system-arm sudo apt install gdb-multiarch build-essential pkg-config sudo apt install libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev Grab the QEMU source. Our QEMU is based on upstream v4.2 with custom aarch64 debugging support. git clone https://github.com/fxlin/qemu-cs4414.git qemu cd qemu ./configure --target-list=aarch64-softmmu make -j`nproc` export PATH=\"$(pwd)/aarch64-softmmu:${PATH}\" If successful, this will result in QEMU executables in ./aarch64-softmmu/. The last line above adds the path to our search path. If you encounter compilation errors (e.g. unmet dependencies), make sure you run all apt get commands above. Now try QEMU & check its version. The supported machines should include Rpi3 $ qemu-system-aarch64 --version QEMU emulator version 5.0.50 (v5.0.0-1247-gaf6f75d03f-dirty) Copyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers patched for cs4414/6456 aarch64 kernel hacking $ qemu-system-aarch64 -M help|grep rasp raspi2 Raspberry Pi 2B raspi3 Raspberry Pi 3B","title":"Compile QEMU from source"},{"location":"lesson00/rpi-os/#test-the-compilation","text":"Test QEMU with Rpi3 baremetal code (NOTE: this repo is for validating your toolchain & QEMU build; it is NOT our course project) git clone https://github.com/fxlin/raspi3-tutorial.git cd raspi3-tutorial git checkout b026449 cd 05_uart0 make qemu-system-aarch64 -M raspi3 -kernel kernel8.img -serial stdio If everything works fine, you should see QMEU print out: My serial number is: 0000000000000000 Note: the test program runs an infinite loop which will cause high CPU usage on your host machine. Kill the test program timely. On Linux: On Windows (WSL) Move to the QEMU cheatsheet .","title":"Test the compilation"},{"location":"lesson01/rpi-os/","text":"1: Baremetal HelloWorld Objectives We will build: a minimal, baremetal program that can print \"Hello world\" via Rpi3's UART. Students will experience: The C project structure The use of cross-compilation toolchain arm64 assembly (lightly) Basic knowledge on Rpi3 and its UART hardware Source code location: p1-kernel/src/lesson01 Roadmap Create a Makefile project. Add minimum code to boot the platform. Initialize the UART hardware. Send characters to the UART registers. Terms Strictly speaking, this baremetal program is not a \"kernel\". We nevertheless call it so for ease of explanation. \"Raspberry Pi\" means the actual Rpi3 hardware. \"QEMU\" means the Rpi3 platform as emulated by QEMU. We will explain details where the real hardware behaves differently from QEMU. Project structure Makefile : We will use the GNU Makefile to build the kernel. src : This folder contains all of the source code. include : All of the header files are placed here. Note: Of all the subsequent experiments in p1, the source code has the same structure. Makefile walkthrough If you are not familiar with Makefiles, read this article. The complete Makefile: ARMGNU ?= aarch64-linux-gnu COPS = -Wall -nostdlib -nostartfiles -ffreestanding -Iinclude -mgeneral-regs-only -O0 -g ASMOPS = -Iinclude -g BUILD_DIR = build SRC_DIR = src all : kernel8.img clean : rm -rf $(BUILD_DIR) *.img $(BUILD_DIR)/%_c.o: $(SRC_DIR)/%.c mkdir -p $(@D) $(ARMGNU)-gcc $(COPS) -MMD -c $< -o $@ $(BUILD_DIR)/%_s.o: $(SRC_DIR)/%.S $(ARMGNU)-gcc $(ASMOPS) -MMD -c $< -o $@ C_FILES = $(wildcard $(SRC_DIR)/*.c) ASM_FILES = $(wildcard $(SRC_DIR)/*.S) OBJ_FILES = $(C_FILES:$(SRC_DIR)/%.c=$(BUILD_DIR)/%_c.o) OBJ_FILES += $(ASM_FILES:$(SRC_DIR)/%.S=$(BUILD_DIR)/%_s.o) DEP_FILES = $(OBJ_FILES:%.o=%.d) -include $(DEP_FILES) kernel8.img: $(SRC_DIR)/linker.ld $(OBJ_FILES) $(ARMGNU)-ld -T $(SRC_DIR)/linker.ld -o $(BUILD_DIR)/kernel8.elf $(OBJ_FILES) $(ARMGNU)-objcopy $(BUILD_DIR)/kernel8.elf -O binary kernel8.img Let's inspect this file in detail: ARMGNU ?= aarch64-linux-gnu The Makefile starts with a variable definition. ARMGNU is a cross-compiler prefix. We need to use a cross-compiler because we are compiling the source code for the arm64 architecture on an x86 machine. So instead of gcc , we will use aarch64-linux-gnu-gcc . COPS = -Wall -nostdlib -nostartfiles -ffreestanding -Iinclude -mgeneral-regs-only ASMOPS = -Iinclude COPS and ASMOPS are options that we pass to the compiler when compiling C and assembler code, respectively. These options require a short explanation: -Wall Show all warnings. A good practice. -nostdlib Don't use the C standard library. Most of the calls in the C standard library eventually interact with the operating system. We are writing a bare-metal program, and we don't have any underlying operating system, so the C standard library is not going to work for us anyway. -nostartfiles Don't use standard startup files. Startup files are responsible for setting an initial stack pointer, initializing static data, and jumping to the main entry point. We are going to do all of this by ourselves. -ffreestanding A freestanding environment is an environment in which the standard library may not exist, and program startup may not necessarily be at main. The option -ffreestanding directs the compiler to not assume that standard functions have their usual definition. -Iinclude Search for header files in the include folder. -mgeneral-regs-only . Use only general-purpose registers. ARM processors also have NEON registers. We don't want the compiler to use them because they add additional complexity (since, for example, we will need to store the registers during a context switch). -g Include debugging info in the resultant ELF binary. -O0 Turn off any compiler optimization. For ease of debugging. BUILD_DIR = build SRC_DIR = src SRC_DIR and BUILD_DIR are directories that contain source code and compiled object files, respectively. all : kernel8.img clean : rm -rf $(BUILD_DIR) *.img Build targets & rules The first two targets are pretty simple: the all target is the default one, and it is executed whenever you type make without any arguments ( make always uses the first target as the default). This target just redirects all work to a different target, kernel8.img . The name \"kernel8.img\" is mandated by the Rpi3 firmware. The trailing 8 denotes ARMv8 which is a 64-bit architecture. This filename tells the firmware to boot the processor into 64-bit mode. The clean target is responsible for deleting all compilation artifacts and the compiled kernel image. $(BUILD_DIR)/%_c.o: $(SRC_DIR)/%.c mkdir -p $(@D) $(ARMGNU)-gcc $(COPS) -MMD -c $< -o $@ $(BUILD_DIR)/%_s.o: $(SRC_DIR)/%.S $(ARMGNU)-gcc $(ASMOPS) -MMD -c $< -o $@ The next two targets are responsible for compiling C and assembler files. If, for example, in the src directory we have foo.c and foo.S files, they will be compiled into build/foo_c.o and build/foo_s.o , respectively. $< and $@ are substituted at runtime with the input and output filenames ( foo.c and foo_c.o ). Before compiling C files, we also create a build directory in case it doesn't exist yet. C_FILES = $(wildcard $(SRC_DIR)/*.c) ASM_FILES = $(wildcard $(SRC_DIR)/*.S) OBJ_FILES = $(C_FILES:$(SRC_DIR)/%.c=$(BUILD_DIR)/%_c.o) OBJ_FILES += $(ASM_FILES:$(SRC_DIR)/%.S=$(BUILD_DIR)/%_s.o) Here we are building an array of all object files ( OBJ_FILES ) created from the concatenation of both C and assembler source files. DEP_FILES = $(OBJ_FILES:%.o=%.d) -include $(DEP_FILES) The next two lines are a little bit tricky. If you take a look at how we defined our compilation targets for both C and assembler source files, you will notice that we used the -MMD parameter. This parameter instructs the gcc compiler to create a dependency file for each generated object file. A dependency file defines all of the dependencies for a particular source file. These dependencies usually contain a list of all included headers. We need to include all of the generated dependency files so that make knows what exactly to recompile in case a header changes. Bake the kernel binaries :cookie: $(ARMGNU)-ld -T $(SRC_DIR)/linker.ld -o kernel8.elf $(OBJ_FILES) We use the OBJ_FILES array to build the kernel8.elf file. We use the linker script src/linker.ld to define the basic layout of the resulting executable image (we will discuss the linker script in the next section). $(ARMGNU)-objcopy kernel8.elf -O binary kernel8.img kernel8.elf & kernel8.img build/kernel8.elf (\"kernel binary\"): Our build outcome as an ELF file. It contains all code, data, and debugging info. Often, to execute an ELF program in user space, there should be a loader to parse ELF, load code & data to designated memory locations, etc. For our kernel experiment, we do NOT have such a loader for the kernel itself. kernel8.img (\"kernel image\"): The raw instructions & data as extracted from kernel8.elf. The raw image is to be loaded to memory. Since it's a memory dump (see below), the load is as simple as byte-by-byte copy. The kernel image is produced by objcopy . Its manual says: \" objcopy can be used to generate a raw binary file by using an output target of \u2018binary\u2019 (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file.\" Q: can you use readelf to examine kernel8.elf, and explain your observation? The linker script A linker script describes how the sections in the input object files ( _c.o and _s.o ) should be mapped into the output file ( .elf ); it also controls the addresses of all program symbols (e.g. functions and variables). More information can be found here . Now let's take a look at the linker script: SECTIONS { .text.boot : { *(.text.boot) } .text : { *(.text) } .rodata : { *(.rodata) } .data : { *(.data) } . = ALIGN(0x8); bss_begin = .; .bss : { *(.bss*) } bss_end = .; } After startup, the Rpi3 GPU loads kernel8.img into memory 0x0 and starts execution from the beginning of the file. That's why the .text.boot section must come first; we are going to put the kernel startup code inside this section. QEMU behaves differently: it loads the kernel image at 0x80000. Q: How to tweak the linker script to update the start address? The .text , .rodata , and .data sections contain kernel instructions, read-only data, and global data with init values. The .bss section contains data that should be initialized to 0. By putting such data in a separate section, the compiler can save some space in the ELF binary\u2013\u2013only the section size is stored in the ELF header, but the section content is omitted. After booting up, our kernel initializes the .bss section to 0; that's why we need to record the start and end of the section (hence the bss_begin and bss_end symbols) and align the section so that it starts at an address that is a multiple of 8. This eases kernel programming because the str instruction can be used only with 8-byte-aligned addresses. Kernel startup Booting the kernel boot.S contains the kernel startup code (VSCode: Ctrl-p then type boot.S): #include \"mm.h\" .section \".text.boot\" .globl _start _start: mrs x0, mpidr_el1 and x0, x0,#0xFF // Check processor id cbz x0, master // Hang for all non-primary CPU b proc_hang proc_hang: b proc_hang master: adr x0, bss_begin adr x1, bss_end sub x1, x1, x0 bl memzero mov sp, #LOW_MEMORY bl kernel_main Let's review this file in detail: .section \".text.boot\" First, we specify that everything defined in boot.S should go in the .text.boot section. Previously, we saw that this section is placed at the beginning of the kernel image by the linker script. So when the kernel is started, execution begins at the start function: .globl _start _start: mrs x0, mpidr_el1 and x0, x0,#0xFF // Check processor id cbz x0, master // Hang for all non-primary CPU b proc_hang Rpi3 has 4 cores, and after the device is powered on, each core begins to execute the same code. Our kernel only works with the first one and put all of the other cores in an endless loop. This is exactly what the _start function is responsible for. It gets the processor ID from the mpidr_el1 system register. Q: It may make more sense to put core 1-3 in deep sleep using wfi . How? Kernel memory layout If the current processor ID is 0, then execution branches to the master function: master: adr x0, bss_begin adr x1, bss_end sub x1, x1, x0 bl memzero Here, we clean the .bss section by calling memzero . We will define this function later. In ARMv8 architecture, by convention, the first seven arguments are passed to the called function via registers x0\u2013x6 (cf: our cheat sheet). The memzero function accepts only two arguments: the start address ( bss_begin ) and the size of the section needed to be cleaned ( bss_end - bss_begin ). mov sp, #LOW_MEMORY bl kernel_main After cleaning the .bss section, the kernel initializes the stack pointer and passes execution to the kernel_main function. The Rpi3 loads the kernel at address 0 (QEMU loads at 0x80000); that's why the initial stack pointer can be set to any location high enough so that stack will not override the kernel image when it grows sufficiently large. LOW_MEMORY is defined in mm.h and is equal to 4MB. As our kernel's stack won't grow very large and the image itself is tiny, 4MB is more than enough for us. Aside: Some ARM64 instructions used For those of you who are not familiar with ARM assembler syntax, let me quickly summarize the instructions that we have used: mrs Load value from a system register to one of the general purpose registers (x0\u2013x30) and Perform the logical AND operation. We use this command to strip the last byte from the value we obtain from the mpidr_el1 register. cbz Compare the result of the previously executed operation to 0 and jump (or branch in ARM terminology) to the provided label if the comparison yields true. b Perform an unconditional branch to some label. adr Load a label's relative address into the target register. In this case, we want pointers to the start and end of the .bss region. sub Subtract values from two registers. bl \"Branch with a link\": perform an unconditional branch and store the return address in x30 (the link register). When the subroutine is finished, use the ret instruction to jump back to the return address. mov Move a value between registers or from a constant to a register. Our cheat sheet summarizes common ARM64 instructions. For official documentation, here is the ARMv8-A developer's guide. It's a good resource if the ARM ISA is unfamiliar to you. This page specifically outlines the register usage convention in the ABI. The kernel_main function We have seen that the boot code eventually passes control to the kernel_main function. (VSCode: Ctrl-t then type \"kernel_main\") #include \"mini_uart.h\" void kernel_main(void) { uart_init(); uart_send_string(\"Hello, world!\\r\\n\"); while (1) { uart_send(uart_recv()); } } This function is one of the simplest in the kernel. It works with the Mini UART device to print to screen and read user input. The kernel just prints Hello, world! and then enters an infinite loop that reads characters from the user and sends them back to the screen. A bit about the Rpi3 hardware The Rpi3 board is based on the BCM2837 SoC by Broadcom. The SoC manual is here . The SoC is not friendly for OS hackers: Broadcom poorly documents it and the hardware has many quirks. Despite so, the community figured out most of the SoC details over years because Rpi3's popularity. It's not our goal to dive in the SoC. Rather, our philosophy is to deal BCM2837-specific details as few as possible -- just enough to get our kernel working. We will spend more efforts on explaining generic hardware such as ARM64 cores, generic timers, irq controllers, etc. Rpi4 seems more friendly to kernel hackers. Memory-mapped IO On ARM-based SoCs, access to all devices is performed via memory-mapped registers. The Rpi3 SoC reserves physical memory address 0x3F000000 for IO devices. To configure a particular device, software reads/writes device registers. A device register is just a 32-bit region of memory. The meaning of each bit in each IO register is described in the SoC manual. The term \"device\" is heavily overloaded in many tech docs. Sometimes it means a board, e.g. \"an Rpi3 device\"; sometimes it means an IO peripheral, e.g. \"UART device\". We will be explicit. UART UART is a simple character device allowing software to send out text characters to a different machine. If you do not care about performance, UART requires very minimum software code. Therefore, it is often the first few IO devices to bring up when we build system software for a new machine. Only with UART meaning debugging is possible. (JTAG is another option which however requires more complex setup). In the simplest form, software writes ascii values to UART registers. The UART device converts written values to a sequence of high and low voltages on wire. This sequence is transmitted to your via the TTL-to-serial cable and is interpreted by your terminal emulator (e.g. PuTTY on Windows). Rpi3 has the two UART devices. Oddly enough, they are different. Name Type Comments UART0 PL011 Secondary, intended as Bluetooth connector UART1 mini UART Primary, intended as debug console UART1/Mini UART: easier to program; limited performance/functionalities. That's fine for our goal. For specification of the Mini UART registers: see page 8 of the SoC manual. UART0/PL011: richer functions; higher speed. Yet one needs to configure the board clock by talking to the GPU firmware. We won't do that. see Example code if you are interested. Both UARTs can be mapped to the same physical pins by setting the GPFSEL1 register. See the GPIO function diagram below. That's enough to know about Rpi UARTs. More: official web page . GPIO Another IO device is GPIO General-purpose input/output . GPIO provides a bunch of registers. Each bit in such a register corresponds to a pin on the Rpi3 board. By writing 1 or 0 to register bits, software can control the output voltage on the pins, e.g. for turning on/off LEDs connected to such pins. Reading is done in a similar fashion. The picture below shows GPIO pin headers populated on Rpi3. (Note: the picture shows Rpi2, which has the same pinout as Rpi3) An SoC often has limited number of pins. Software can control the use of these pins, e.g. for GPIO or for UART. Software does so by writing to specific memory-mapped registers. The GPIO can be used to configure the behavior of different GPIO pins. For example, to be able to use the Mini UART, we need to activate pins 14 and 15 and set them up to use this device. The image below illustrates how numbers are assigned to the GPIO pins: Walkthrough: the UART code The following init code configures pin 14 & 15 as UART in/out, sets up UART clock and its modes, etc. Much of the UART init code is irrelevant to QEMU. Since QEMU \"emulates\" the UARTs, it can dump whatever our kernel writes to the emulated UART registers to stdio. Example: qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio The first -serial means UART0 which we do not touch; the second -serial means we direct UART1 to stdio. void uart_init ( void ) { unsigned int selector; selector = get32(GPFSEL1); selector &= ~(7<<12); // clean gpio14 selector |= 2<<12; // set alt5 for gpio14 selector &= ~(7<<15); // clean gpio15 selector |= 2<<15; // set alt5 for gpio 15 put32(GPFSEL1,selector); put32(GPPUD,0); delay(150); put32(GPPUDCLK0,(1<<14)|(1<<15)); delay(150); put32(GPPUDCLK0,0); put32(AUX_ENABLES,1); //Enable mini uart (this also enables access to it registers) put32(AUX_MU_CNTL_REG,0); //Disable auto flow control and disable receiver and transmitter (for now) put32(AUX_MU_IER_REG,0); //Disable receive and transmit interrupts put32(AUX_MU_LCR_REG,3); //Enable 8 bit mode put32(AUX_MU_MCR_REG,0); //Set RTS line to be always high put32(AUX_MU_BAUD_REG,270); //Set baud rate to 115200 put32(AUX_MU_CNTL_REG,3); //Finally, enable transmitter and receiver } Here, we use the two functions put32 and get32 . Those functions are very simple -- read and write some data to and from a 32-bit register. You can take a look at how they are implemented in utils.S . uart_init is one of the most complex and important functions in this lesson, and we will continue to examine it in the next three sections. Init: GPIO alternative function selection First, we need to activate the GPIO pins. Most of the pins can be used with different IO devices. So before using a particular pin, we need to select the pin's alternative function, a number from 0 to 5 that can be set for each pin and configures which IO device is virtually \"connected\" to the pin. See the list of all available GPIO alternative functions in the image below (taken from page 102 of the SoC manual) Here you can see that pins 14 and 15 have the TXD1 and RXD1 alternative functions available. This means that if we select alternative function number 5 for pins 14 and 15, they will be used as a Mini UART Transmit Data pin and Mini UART Receive Data pin, respectively. The GPFSEL1 register is used to control alternative functions for pins 10-19. The meaning of all the bits in those registers is shown in the following table (page 92 of the SoC manual): So now you know everything you need to understand the following lines of code that are used to configure GPIO pins 14 and 15 to work with the Mini UART device: unsigned int selector; selector = get32(GPFSEL1); selector &= ~(7<<12); // clean gpio14 selector |= 2<<12; // set alt5 for gpio14 selector &= ~(7<<15); // clean gpio15 selector |= 2<<15; // set alt5 for gpio 15 put32(GPFSEL1,selector); Init: GPIO pull-up/down & how we disable it When working with GPIO pins, you will often encounter terms such as pull-up/pull-down. These concepts are explained in great detail in this article. For those who are too lazy to read the whole article, I will briefly explain the pull-up/pull-down concept. If you use a particular pin as input and don't connect anything to this pin, you will not be able to identify whether the value of the pin is 1 or 0. In fact, the device will report random values. The pull-up/pull-down mechanism allows you to overcome this issue. If you set the pin to the pull-up state and nothing is connected to it, it will report 1 all the time (for the pull-down state, the value will always be 0). In our case, we need neither the pull-up nor the pull-down state, because both the 14 and 15 pins are going to be connected all the time. The pin state is preserved even after a reboot, so before using any pin, we always have to initialize its state. There are three available states: pull-up, pull-down, and neither (to remove the current pull-up or pull-down state), and we need the third one. Switching between pin states is not a very simple procedure because it requires physically toggling a switch on the electric circuit. This process involves the GPPUD and GPPUDCLK registers and is described on page 101 of the SoC manual: The GPIO Pull-up/down Clock Registers control the actuation of internal pull-downs on the respective GPIO pins. These registers must be used in conjunction with the GPPUD register to effect GPIO Pull-up/down changes. The following sequence of events is required: 1. Write to GPPUD to set the required control signal (i.e. Pull-up or Pull-Down or neither to remove the current Pull-up/down) 2. Wait 150 cycles \u2013 this provides the required set-up time for the control signal 3. Write to GPPUDCLK0/1 to clock the control signal into the GPIO pads you wish to modify \u2013 NOTE only the pads which receive a clock will be modified, all others will retain their previous state. 4. Wait 150 cycles \u2013 this provides the required hold time for the control signal 5. Write to GPPUD to remove the control signal 6. Write to GPPUDCLK0/1 to remove the clock This procedure describes how we can remove both the pull-up and pull-down states from a pin , which is what we are doing for pins 14 and 15 in the following code: put32(GPPUD,0); delay(150); put32(GPPUDCLK0,(1<<14)|(1<<15)); delay(150); put32(GPPUDCLK0,0); Init: Mini UART Now our Mini UART is connected to the GPIO pins, and the pins are configured. The rest of the uart_init function is dedicated to Mini UART initialization. put32(AUX_ENABLES,1); //Enable mini uart (this also enables access to its registers) put32(AUX_MU_CNTL_REG,0); //Disable auto flow control and disable receiver and transmitter (for now) put32(AUX_MU_IER_REG,0); //Disable receive and transmit interrupts put32(AUX_MU_LCR_REG,3); //Enable 8 bit mode put32(AUX_MU_MCR_REG,0); //Set RTS line to be always high put32(AUX_MU_BAUD_REG,270); //Set baud rate to 115200 put32(AUX_MU_CNTL_REG,3); //Finally, enable transmitter and receiver Let's examine this code snippet line by line. put32(AUX_ENABLES,1); //Enable mini uart (this also enables access to its registers) This line enables the Mini UART. We must do this in the beginning, because this also enables access to all the other Mini UART registers. put32(AUX_MU_CNTL_REG,0); //Disable auto flow control and disable receiver and transmitter (for now) Here we disable the receiver and transmitter before the configuration is finished. We also permanently disable auto-flow control because it requires us to use additional GPIO pins, and the TTL-to-serial cable doesn't support it. For more information about auto-flow control, you can refer to this article. put32(AUX_MU_IER_REG,0); //Disable receive and transmit interrupts It is possible to configure the Mini UART to generate a processor interrupt each time new data is available. We want to be as simple as possible. So for now, we will just disable this feature. put32(AUX_MU_LCR_REG,3); //Enable 8 bit mode Mini UART can support either 7- or 8-bit operations. This is because an ASCII character is 7 bits for the standard set and 8 bits for the extended. We are going to use 8-bit mode. put32(AUX_MU_MCR_REG,0); //Set RTS line to be always high The RTS line is used in the flow control and we don't need it. Set it to be high all the time. put32(AUX_MU_BAUD_REG,270); //Set baud rate to 115200 The baud rate is the rate at which information is transferred in a communication channel. \u201c115200 baud\u201d means that the serial port is capable of transferring a maximum of 115200 bits per second. The baud rate of your Raspberry Pi mini UART device should be the same as the baud rate in your terminal emulator. The Mini UART calculates baud rate according to the following equation: baudrate = system_clock_freq / (8 * ( baudrate_reg + 1 )) The system_clock_freq is 250 MHz, so we can easily calculate the value of baudrate_reg as 270. put32(AUX_MU_CNTL_REG,3); //Finally, enable transmitter and receiver After this line is executed, the Mini UART is ready for work! Sending data over UART After the Mini UART is ready, we can try to use it to send and receive some data. To do this, we can use the following two functions: void uart_send ( char c ) { while(1) { if(get32(AUX_MU_LSR_REG)&0x20) break; } put32(AUX_MU_IO_REG,c); } char uart_recv ( void ) { while(1) { if(get32(AUX_MU_LSR_REG)&0x01) break; } return(get32(AUX_MU_IO_REG)&0xFF); } Both of the functions start with an infinite loop, the purpose of which is to verify whether the device is ready to transmit or receive data. We are using the AUX_MU_LSR_REG register to do this. Bit zero, if set to 1, indicates that the data is ready; this means that we can read from the UART. Bit five, if set to 1, tells us that the transmitter is empty, meaning that we can write to the UART. Next, we use AUX_MU_IO_REG to either store the value of the transmitted character or read the value of the received character. We also have a very simple function that is capable of sending strings instead of characters: void uart_send_string(char* str) { for (int i = 0; str[i] != '\\0'; i ++) { uart_send((char)str[i]); } } This function just iterates over all characters in a string and sends them one by one. Low efficiency? Apparently Tx/Rx with busy wait burn lots of CPU cycles for no good. It's fine for our baremetal program -- simple & less error-prone. Production software often do interrupt-driven Rx/Tx. Take the kernel for a spin Rpi3 Run make to build the kernel. The Raspberry Pi startup sequence is the following (simplified): The device is powered on. The GPU starts up and reads the config.txt file from the boot partition. This file contains some configuration parameters that the GPU uses to further adjust the startup sequence. kernel8.img is loaded into memory and executed. Setup To be able to run our simple OS, the config.txt file should be the following: enable_uart=1 arm_64bit=1 kernel_old=1 disable_commandline_tags=1 kernel_old=1 specifies that the kernel image should be loaded at address 0. disable_commandline_tags instructs the GPU to not pass any command line arguments to the booted image. Run Copy the generated kernel8.img file to the boot partition of your Raspberry Pi flash card and delete kernel7.img as well as any other kernel*.img files on your SD card. Make sure you left all other files in the boot partition untouched (see 43 and 158 issues for details). Update (2/10/21): students reported that UART1 stops to work with the newest Rpi3 firmware (either extracted from Raspbian OS or from the upstream github repo). The symptom: no \"helloworld\" is printed, while UART1 seems echoing fine. UART0 seems unaffected. My guess: it has something to do with the firmware's new device tree feature? Action: use older firmware provided by us: https://github.com/fxlin/p1-kernel/releases/tag/exp1-rpi3. Modify the config.txt file as described above. Connect the USB-to-TTL serial cable as described in the Prerequisites . Power on your Raspberry Pi. Open your terminal emulator. You should be able to see the Hello, world! message there. Aside (optional): prepare the SD card from scratch (w/o Raspbian) The steps above assume that you have Raspbian installed on your SD card. It is also possible to run the RPi OS using an empty SD card. Prepare your SD card: Use an MBR partition table Format the boot partition as FAT32 The card should be formatted exactly in the same way as it is required to install Raspbian. Check HOW TO FORMAT AN SD CARD AS FAT section in the official documenation for more information. Copy the following files to the card: bootcode.bin This is the GPU bootloader, it contains the GPU code to start the GPU and load the GPU firmware. start.elf This is the GPU firmware. It reads config.txt and enables the GPU to load and run ARM specific user code from kernel8.img Update (2/10/21): UART1 is broken by these upstream firmware for unknown reason. Use older firmware provided by us: https://github.com/fxlin/p1-kernel/releases/tag/exp1-rpi3. Copy kernel8.img and config.txt files. Connect the USB-to-TTL serial cable. Power on your Raspberry Pi. Use your terminal emulator to connect to the RPi OS. Unfortunately, all Raspberry Pi firmware files are closed-sourced and undocumented. For more information about the Raspberry Pi startup sequence, you can refer to some unofficial sources, like this StackExchange question or this Github repository. QEMU Setup Follow the instructions in Prerequisites . Type make -f Makefile.qemu . Run $ qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio VNC server running on 127.0.0.1:5900 Hello, world! <Ctrl-C>","title":"exp1"},{"location":"lesson01/rpi-os/#1-baremetal-helloworld","text":"","title":"1: Baremetal HelloWorld"},{"location":"lesson01/rpi-os/#objectives","text":"We will build: a minimal, baremetal program that can print \"Hello world\" via Rpi3's UART. Students will experience: The C project structure The use of cross-compilation toolchain arm64 assembly (lightly) Basic knowledge on Rpi3 and its UART hardware Source code location: p1-kernel/src/lesson01","title":"Objectives"},{"location":"lesson01/rpi-os/#roadmap","text":"Create a Makefile project. Add minimum code to boot the platform. Initialize the UART hardware. Send characters to the UART registers.","title":"Roadmap"},{"location":"lesson01/rpi-os/#terms","text":"Strictly speaking, this baremetal program is not a \"kernel\". We nevertheless call it so for ease of explanation. \"Raspberry Pi\" means the actual Rpi3 hardware. \"QEMU\" means the Rpi3 platform as emulated by QEMU. We will explain details where the real hardware behaves differently from QEMU.","title":"Terms"},{"location":"lesson01/rpi-os/#project-structure","text":"Makefile : We will use the GNU Makefile to build the kernel. src : This folder contains all of the source code. include : All of the header files are placed here. Note: Of all the subsequent experiments in p1, the source code has the same structure.","title":"Project structure"},{"location":"lesson01/rpi-os/#makefile-walkthrough","text":"If you are not familiar with Makefiles, read this article. The complete Makefile: ARMGNU ?= aarch64-linux-gnu COPS = -Wall -nostdlib -nostartfiles -ffreestanding -Iinclude -mgeneral-regs-only -O0 -g ASMOPS = -Iinclude -g BUILD_DIR = build SRC_DIR = src all : kernel8.img clean : rm -rf $(BUILD_DIR) *.img $(BUILD_DIR)/%_c.o: $(SRC_DIR)/%.c mkdir -p $(@D) $(ARMGNU)-gcc $(COPS) -MMD -c $< -o $@ $(BUILD_DIR)/%_s.o: $(SRC_DIR)/%.S $(ARMGNU)-gcc $(ASMOPS) -MMD -c $< -o $@ C_FILES = $(wildcard $(SRC_DIR)/*.c) ASM_FILES = $(wildcard $(SRC_DIR)/*.S) OBJ_FILES = $(C_FILES:$(SRC_DIR)/%.c=$(BUILD_DIR)/%_c.o) OBJ_FILES += $(ASM_FILES:$(SRC_DIR)/%.S=$(BUILD_DIR)/%_s.o) DEP_FILES = $(OBJ_FILES:%.o=%.d) -include $(DEP_FILES) kernel8.img: $(SRC_DIR)/linker.ld $(OBJ_FILES) $(ARMGNU)-ld -T $(SRC_DIR)/linker.ld -o $(BUILD_DIR)/kernel8.elf $(OBJ_FILES) $(ARMGNU)-objcopy $(BUILD_DIR)/kernel8.elf -O binary kernel8.img Let's inspect this file in detail: ARMGNU ?= aarch64-linux-gnu The Makefile starts with a variable definition. ARMGNU is a cross-compiler prefix. We need to use a cross-compiler because we are compiling the source code for the arm64 architecture on an x86 machine. So instead of gcc , we will use aarch64-linux-gnu-gcc . COPS = -Wall -nostdlib -nostartfiles -ffreestanding -Iinclude -mgeneral-regs-only ASMOPS = -Iinclude COPS and ASMOPS are options that we pass to the compiler when compiling C and assembler code, respectively. These options require a short explanation: -Wall Show all warnings. A good practice. -nostdlib Don't use the C standard library. Most of the calls in the C standard library eventually interact with the operating system. We are writing a bare-metal program, and we don't have any underlying operating system, so the C standard library is not going to work for us anyway. -nostartfiles Don't use standard startup files. Startup files are responsible for setting an initial stack pointer, initializing static data, and jumping to the main entry point. We are going to do all of this by ourselves. -ffreestanding A freestanding environment is an environment in which the standard library may not exist, and program startup may not necessarily be at main. The option -ffreestanding directs the compiler to not assume that standard functions have their usual definition. -Iinclude Search for header files in the include folder. -mgeneral-regs-only . Use only general-purpose registers. ARM processors also have NEON registers. We don't want the compiler to use them because they add additional complexity (since, for example, we will need to store the registers during a context switch). -g Include debugging info in the resultant ELF binary. -O0 Turn off any compiler optimization. For ease of debugging. BUILD_DIR = build SRC_DIR = src SRC_DIR and BUILD_DIR are directories that contain source code and compiled object files, respectively. all : kernel8.img clean : rm -rf $(BUILD_DIR) *.img","title":"Makefile walkthrough"},{"location":"lesson01/rpi-os/#build-targets-rules","text":"The first two targets are pretty simple: the all target is the default one, and it is executed whenever you type make without any arguments ( make always uses the first target as the default). This target just redirects all work to a different target, kernel8.img . The name \"kernel8.img\" is mandated by the Rpi3 firmware. The trailing 8 denotes ARMv8 which is a 64-bit architecture. This filename tells the firmware to boot the processor into 64-bit mode. The clean target is responsible for deleting all compilation artifacts and the compiled kernel image. $(BUILD_DIR)/%_c.o: $(SRC_DIR)/%.c mkdir -p $(@D) $(ARMGNU)-gcc $(COPS) -MMD -c $< -o $@ $(BUILD_DIR)/%_s.o: $(SRC_DIR)/%.S $(ARMGNU)-gcc $(ASMOPS) -MMD -c $< -o $@ The next two targets are responsible for compiling C and assembler files. If, for example, in the src directory we have foo.c and foo.S files, they will be compiled into build/foo_c.o and build/foo_s.o , respectively. $< and $@ are substituted at runtime with the input and output filenames ( foo.c and foo_c.o ). Before compiling C files, we also create a build directory in case it doesn't exist yet. C_FILES = $(wildcard $(SRC_DIR)/*.c) ASM_FILES = $(wildcard $(SRC_DIR)/*.S) OBJ_FILES = $(C_FILES:$(SRC_DIR)/%.c=$(BUILD_DIR)/%_c.o) OBJ_FILES += $(ASM_FILES:$(SRC_DIR)/%.S=$(BUILD_DIR)/%_s.o) Here we are building an array of all object files ( OBJ_FILES ) created from the concatenation of both C and assembler source files. DEP_FILES = $(OBJ_FILES:%.o=%.d) -include $(DEP_FILES) The next two lines are a little bit tricky. If you take a look at how we defined our compilation targets for both C and assembler source files, you will notice that we used the -MMD parameter. This parameter instructs the gcc compiler to create a dependency file for each generated object file. A dependency file defines all of the dependencies for a particular source file. These dependencies usually contain a list of all included headers. We need to include all of the generated dependency files so that make knows what exactly to recompile in case a header changes.","title":"Build targets &amp; rules"},{"location":"lesson01/rpi-os/#bake-the-kernel-binaries-cookie","text":"$(ARMGNU)-ld -T $(SRC_DIR)/linker.ld -o kernel8.elf $(OBJ_FILES) We use the OBJ_FILES array to build the kernel8.elf file. We use the linker script src/linker.ld to define the basic layout of the resulting executable image (we will discuss the linker script in the next section). $(ARMGNU)-objcopy kernel8.elf -O binary kernel8.img kernel8.elf & kernel8.img build/kernel8.elf (\"kernel binary\"): Our build outcome as an ELF file. It contains all code, data, and debugging info. Often, to execute an ELF program in user space, there should be a loader to parse ELF, load code & data to designated memory locations, etc. For our kernel experiment, we do NOT have such a loader for the kernel itself. kernel8.img (\"kernel image\"): The raw instructions & data as extracted from kernel8.elf. The raw image is to be loaded to memory. Since it's a memory dump (see below), the load is as simple as byte-by-byte copy. The kernel image is produced by objcopy . Its manual says: \" objcopy can be used to generate a raw binary file by using an output target of \u2018binary\u2019 (e.g., use -O binary). When objcopy generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file. All symbols and relocation information will be discarded. The memory dump will start at the load address of the lowest section copied into the output file.\" Q: can you use readelf to examine kernel8.elf, and explain your observation?","title":"Bake the kernel binaries :cookie:"},{"location":"lesson01/rpi-os/#the-linker-script","text":"A linker script describes how the sections in the input object files ( _c.o and _s.o ) should be mapped into the output file ( .elf ); it also controls the addresses of all program symbols (e.g. functions and variables). More information can be found here . Now let's take a look at the linker script: SECTIONS { .text.boot : { *(.text.boot) } .text : { *(.text) } .rodata : { *(.rodata) } .data : { *(.data) } . = ALIGN(0x8); bss_begin = .; .bss : { *(.bss*) } bss_end = .; } After startup, the Rpi3 GPU loads kernel8.img into memory 0x0 and starts execution from the beginning of the file. That's why the .text.boot section must come first; we are going to put the kernel startup code inside this section. QEMU behaves differently: it loads the kernel image at 0x80000. Q: How to tweak the linker script to update the start address? The .text , .rodata , and .data sections contain kernel instructions, read-only data, and global data with init values. The .bss section contains data that should be initialized to 0. By putting such data in a separate section, the compiler can save some space in the ELF binary\u2013\u2013only the section size is stored in the ELF header, but the section content is omitted. After booting up, our kernel initializes the .bss section to 0; that's why we need to record the start and end of the section (hence the bss_begin and bss_end symbols) and align the section so that it starts at an address that is a multiple of 8. This eases kernel programming because the str instruction can be used only with 8-byte-aligned addresses.","title":"The linker script"},{"location":"lesson01/rpi-os/#kernel-startup","text":"","title":"Kernel startup"},{"location":"lesson01/rpi-os/#booting-the-kernel","text":"boot.S contains the kernel startup code (VSCode: Ctrl-p then type boot.S): #include \"mm.h\" .section \".text.boot\" .globl _start _start: mrs x0, mpidr_el1 and x0, x0,#0xFF // Check processor id cbz x0, master // Hang for all non-primary CPU b proc_hang proc_hang: b proc_hang master: adr x0, bss_begin adr x1, bss_end sub x1, x1, x0 bl memzero mov sp, #LOW_MEMORY bl kernel_main Let's review this file in detail: .section \".text.boot\" First, we specify that everything defined in boot.S should go in the .text.boot section. Previously, we saw that this section is placed at the beginning of the kernel image by the linker script. So when the kernel is started, execution begins at the start function: .globl _start _start: mrs x0, mpidr_el1 and x0, x0,#0xFF // Check processor id cbz x0, master // Hang for all non-primary CPU b proc_hang Rpi3 has 4 cores, and after the device is powered on, each core begins to execute the same code. Our kernel only works with the first one and put all of the other cores in an endless loop. This is exactly what the _start function is responsible for. It gets the processor ID from the mpidr_el1 system register. Q: It may make more sense to put core 1-3 in deep sleep using wfi . How?","title":"Booting the kernel"},{"location":"lesson01/rpi-os/#kernel-memory-layout","text":"If the current processor ID is 0, then execution branches to the master function: master: adr x0, bss_begin adr x1, bss_end sub x1, x1, x0 bl memzero Here, we clean the .bss section by calling memzero . We will define this function later. In ARMv8 architecture, by convention, the first seven arguments are passed to the called function via registers x0\u2013x6 (cf: our cheat sheet). The memzero function accepts only two arguments: the start address ( bss_begin ) and the size of the section needed to be cleaned ( bss_end - bss_begin ). mov sp, #LOW_MEMORY bl kernel_main After cleaning the .bss section, the kernel initializes the stack pointer and passes execution to the kernel_main function. The Rpi3 loads the kernel at address 0 (QEMU loads at 0x80000); that's why the initial stack pointer can be set to any location high enough so that stack will not override the kernel image when it grows sufficiently large. LOW_MEMORY is defined in mm.h and is equal to 4MB. As our kernel's stack won't grow very large and the image itself is tiny, 4MB is more than enough for us. Aside: Some ARM64 instructions used For those of you who are not familiar with ARM assembler syntax, let me quickly summarize the instructions that we have used: mrs Load value from a system register to one of the general purpose registers (x0\u2013x30) and Perform the logical AND operation. We use this command to strip the last byte from the value we obtain from the mpidr_el1 register. cbz Compare the result of the previously executed operation to 0 and jump (or branch in ARM terminology) to the provided label if the comparison yields true. b Perform an unconditional branch to some label. adr Load a label's relative address into the target register. In this case, we want pointers to the start and end of the .bss region. sub Subtract values from two registers. bl \"Branch with a link\": perform an unconditional branch and store the return address in x30 (the link register). When the subroutine is finished, use the ret instruction to jump back to the return address. mov Move a value between registers or from a constant to a register. Our cheat sheet summarizes common ARM64 instructions. For official documentation, here is the ARMv8-A developer's guide. It's a good resource if the ARM ISA is unfamiliar to you. This page specifically outlines the register usage convention in the ABI.","title":"Kernel memory layout"},{"location":"lesson01/rpi-os/#the-kernel_main-function","text":"We have seen that the boot code eventually passes control to the kernel_main function. (VSCode: Ctrl-t then type \"kernel_main\") #include \"mini_uart.h\" void kernel_main(void) { uart_init(); uart_send_string(\"Hello, world!\\r\\n\"); while (1) { uart_send(uart_recv()); } } This function is one of the simplest in the kernel. It works with the Mini UART device to print to screen and read user input. The kernel just prints Hello, world! and then enters an infinite loop that reads characters from the user and sends them back to the screen.","title":"The kernel_main function"},{"location":"lesson01/rpi-os/#a-bit-about-the-rpi3-hardware","text":"The Rpi3 board is based on the BCM2837 SoC by Broadcom. The SoC manual is here . The SoC is not friendly for OS hackers: Broadcom poorly documents it and the hardware has many quirks. Despite so, the community figured out most of the SoC details over years because Rpi3's popularity. It's not our goal to dive in the SoC. Rather, our philosophy is to deal BCM2837-specific details as few as possible -- just enough to get our kernel working. We will spend more efforts on explaining generic hardware such as ARM64 cores, generic timers, irq controllers, etc. Rpi4 seems more friendly to kernel hackers.","title":"A bit about the Rpi3 hardware"},{"location":"lesson01/rpi-os/#memory-mapped-io","text":"On ARM-based SoCs, access to all devices is performed via memory-mapped registers. The Rpi3 SoC reserves physical memory address 0x3F000000 for IO devices. To configure a particular device, software reads/writes device registers. A device register is just a 32-bit region of memory. The meaning of each bit in each IO register is described in the SoC manual. The term \"device\" is heavily overloaded in many tech docs. Sometimes it means a board, e.g. \"an Rpi3 device\"; sometimes it means an IO peripheral, e.g. \"UART device\". We will be explicit.","title":"Memory-mapped IO"},{"location":"lesson01/rpi-os/#uart","text":"UART is a simple character device allowing software to send out text characters to a different machine. If you do not care about performance, UART requires very minimum software code. Therefore, it is often the first few IO devices to bring up when we build system software for a new machine. Only with UART meaning debugging is possible. (JTAG is another option which however requires more complex setup). In the simplest form, software writes ascii values to UART registers. The UART device converts written values to a sequence of high and low voltages on wire. This sequence is transmitted to your via the TTL-to-serial cable and is interpreted by your terminal emulator (e.g. PuTTY on Windows). Rpi3 has the two UART devices. Oddly enough, they are different. Name Type Comments UART0 PL011 Secondary, intended as Bluetooth connector UART1 mini UART Primary, intended as debug console UART1/Mini UART: easier to program; limited performance/functionalities. That's fine for our goal. For specification of the Mini UART registers: see page 8 of the SoC manual. UART0/PL011: richer functions; higher speed. Yet one needs to configure the board clock by talking to the GPU firmware. We won't do that. see Example code if you are interested. Both UARTs can be mapped to the same physical pins by setting the GPFSEL1 register. See the GPIO function diagram below. That's enough to know about Rpi UARTs. More: official web page .","title":"UART"},{"location":"lesson01/rpi-os/#gpio","text":"Another IO device is GPIO General-purpose input/output . GPIO provides a bunch of registers. Each bit in such a register corresponds to a pin on the Rpi3 board. By writing 1 or 0 to register bits, software can control the output voltage on the pins, e.g. for turning on/off LEDs connected to such pins. Reading is done in a similar fashion. The picture below shows GPIO pin headers populated on Rpi3. (Note: the picture shows Rpi2, which has the same pinout as Rpi3) An SoC often has limited number of pins. Software can control the use of these pins, e.g. for GPIO or for UART. Software does so by writing to specific memory-mapped registers. The GPIO can be used to configure the behavior of different GPIO pins. For example, to be able to use the Mini UART, we need to activate pins 14 and 15 and set them up to use this device. The image below illustrates how numbers are assigned to the GPIO pins:","title":"GPIO"},{"location":"lesson01/rpi-os/#walkthrough-the-uart-code","text":"The following init code configures pin 14 & 15 as UART in/out, sets up UART clock and its modes, etc. Much of the UART init code is irrelevant to QEMU. Since QEMU \"emulates\" the UARTs, it can dump whatever our kernel writes to the emulated UART registers to stdio. Example: qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio The first -serial means UART0 which we do not touch; the second -serial means we direct UART1 to stdio. void uart_init ( void ) { unsigned int selector; selector = get32(GPFSEL1); selector &= ~(7<<12); // clean gpio14 selector |= 2<<12; // set alt5 for gpio14 selector &= ~(7<<15); // clean gpio15 selector |= 2<<15; // set alt5 for gpio 15 put32(GPFSEL1,selector); put32(GPPUD,0); delay(150); put32(GPPUDCLK0,(1<<14)|(1<<15)); delay(150); put32(GPPUDCLK0,0); put32(AUX_ENABLES,1); //Enable mini uart (this also enables access to it registers) put32(AUX_MU_CNTL_REG,0); //Disable auto flow control and disable receiver and transmitter (for now) put32(AUX_MU_IER_REG,0); //Disable receive and transmit interrupts put32(AUX_MU_LCR_REG,3); //Enable 8 bit mode put32(AUX_MU_MCR_REG,0); //Set RTS line to be always high put32(AUX_MU_BAUD_REG,270); //Set baud rate to 115200 put32(AUX_MU_CNTL_REG,3); //Finally, enable transmitter and receiver } Here, we use the two functions put32 and get32 . Those functions are very simple -- read and write some data to and from a 32-bit register. You can take a look at how they are implemented in utils.S . uart_init is one of the most complex and important functions in this lesson, and we will continue to examine it in the next three sections.","title":"Walkthrough: the UART code"},{"location":"lesson01/rpi-os/#init-gpio-alternative-function-selection","text":"First, we need to activate the GPIO pins. Most of the pins can be used with different IO devices. So before using a particular pin, we need to select the pin's alternative function, a number from 0 to 5 that can be set for each pin and configures which IO device is virtually \"connected\" to the pin. See the list of all available GPIO alternative functions in the image below (taken from page 102 of the SoC manual) Here you can see that pins 14 and 15 have the TXD1 and RXD1 alternative functions available. This means that if we select alternative function number 5 for pins 14 and 15, they will be used as a Mini UART Transmit Data pin and Mini UART Receive Data pin, respectively. The GPFSEL1 register is used to control alternative functions for pins 10-19. The meaning of all the bits in those registers is shown in the following table (page 92 of the SoC manual): So now you know everything you need to understand the following lines of code that are used to configure GPIO pins 14 and 15 to work with the Mini UART device: unsigned int selector; selector = get32(GPFSEL1); selector &= ~(7<<12); // clean gpio14 selector |= 2<<12; // set alt5 for gpio14 selector &= ~(7<<15); // clean gpio15 selector |= 2<<15; // set alt5 for gpio 15 put32(GPFSEL1,selector); Init: GPIO pull-up/down & how we disable it When working with GPIO pins, you will often encounter terms such as pull-up/pull-down. These concepts are explained in great detail in this article. For those who are too lazy to read the whole article, I will briefly explain the pull-up/pull-down concept. If you use a particular pin as input and don't connect anything to this pin, you will not be able to identify whether the value of the pin is 1 or 0. In fact, the device will report random values. The pull-up/pull-down mechanism allows you to overcome this issue. If you set the pin to the pull-up state and nothing is connected to it, it will report 1 all the time (for the pull-down state, the value will always be 0). In our case, we need neither the pull-up nor the pull-down state, because both the 14 and 15 pins are going to be connected all the time. The pin state is preserved even after a reboot, so before using any pin, we always have to initialize its state. There are three available states: pull-up, pull-down, and neither (to remove the current pull-up or pull-down state), and we need the third one. Switching between pin states is not a very simple procedure because it requires physically toggling a switch on the electric circuit. This process involves the GPPUD and GPPUDCLK registers and is described on page 101 of the SoC manual: The GPIO Pull-up/down Clock Registers control the actuation of internal pull-downs on the respective GPIO pins. These registers must be used in conjunction with the GPPUD register to effect GPIO Pull-up/down changes. The following sequence of events is required: 1. Write to GPPUD to set the required control signal (i.e. Pull-up or Pull-Down or neither to remove the current Pull-up/down) 2. Wait 150 cycles \u2013 this provides the required set-up time for the control signal 3. Write to GPPUDCLK0/1 to clock the control signal into the GPIO pads you wish to modify \u2013 NOTE only the pads which receive a clock will be modified, all others will retain their previous state. 4. Wait 150 cycles \u2013 this provides the required hold time for the control signal 5. Write to GPPUD to remove the control signal 6. Write to GPPUDCLK0/1 to remove the clock This procedure describes how we can remove both the pull-up and pull-down states from a pin , which is what we are doing for pins 14 and 15 in the following code: put32(GPPUD,0); delay(150); put32(GPPUDCLK0,(1<<14)|(1<<15)); delay(150); put32(GPPUDCLK0,0);","title":"Init: GPIO alternative function selection"},{"location":"lesson01/rpi-os/#init-mini-uart","text":"Now our Mini UART is connected to the GPIO pins, and the pins are configured. The rest of the uart_init function is dedicated to Mini UART initialization. put32(AUX_ENABLES,1); //Enable mini uart (this also enables access to its registers) put32(AUX_MU_CNTL_REG,0); //Disable auto flow control and disable receiver and transmitter (for now) put32(AUX_MU_IER_REG,0); //Disable receive and transmit interrupts put32(AUX_MU_LCR_REG,3); //Enable 8 bit mode put32(AUX_MU_MCR_REG,0); //Set RTS line to be always high put32(AUX_MU_BAUD_REG,270); //Set baud rate to 115200 put32(AUX_MU_CNTL_REG,3); //Finally, enable transmitter and receiver Let's examine this code snippet line by line. put32(AUX_ENABLES,1); //Enable mini uart (this also enables access to its registers) This line enables the Mini UART. We must do this in the beginning, because this also enables access to all the other Mini UART registers. put32(AUX_MU_CNTL_REG,0); //Disable auto flow control and disable receiver and transmitter (for now) Here we disable the receiver and transmitter before the configuration is finished. We also permanently disable auto-flow control because it requires us to use additional GPIO pins, and the TTL-to-serial cable doesn't support it. For more information about auto-flow control, you can refer to this article. put32(AUX_MU_IER_REG,0); //Disable receive and transmit interrupts It is possible to configure the Mini UART to generate a processor interrupt each time new data is available. We want to be as simple as possible. So for now, we will just disable this feature. put32(AUX_MU_LCR_REG,3); //Enable 8 bit mode Mini UART can support either 7- or 8-bit operations. This is because an ASCII character is 7 bits for the standard set and 8 bits for the extended. We are going to use 8-bit mode. put32(AUX_MU_MCR_REG,0); //Set RTS line to be always high The RTS line is used in the flow control and we don't need it. Set it to be high all the time. put32(AUX_MU_BAUD_REG,270); //Set baud rate to 115200 The baud rate is the rate at which information is transferred in a communication channel. \u201c115200 baud\u201d means that the serial port is capable of transferring a maximum of 115200 bits per second. The baud rate of your Raspberry Pi mini UART device should be the same as the baud rate in your terminal emulator. The Mini UART calculates baud rate according to the following equation: baudrate = system_clock_freq / (8 * ( baudrate_reg + 1 )) The system_clock_freq is 250 MHz, so we can easily calculate the value of baudrate_reg as 270. put32(AUX_MU_CNTL_REG,3); //Finally, enable transmitter and receiver After this line is executed, the Mini UART is ready for work!","title":"Init: Mini UART"},{"location":"lesson01/rpi-os/#sending-data-over-uart","text":"After the Mini UART is ready, we can try to use it to send and receive some data. To do this, we can use the following two functions: void uart_send ( char c ) { while(1) { if(get32(AUX_MU_LSR_REG)&0x20) break; } put32(AUX_MU_IO_REG,c); } char uart_recv ( void ) { while(1) { if(get32(AUX_MU_LSR_REG)&0x01) break; } return(get32(AUX_MU_IO_REG)&0xFF); } Both of the functions start with an infinite loop, the purpose of which is to verify whether the device is ready to transmit or receive data. We are using the AUX_MU_LSR_REG register to do this. Bit zero, if set to 1, indicates that the data is ready; this means that we can read from the UART. Bit five, if set to 1, tells us that the transmitter is empty, meaning that we can write to the UART. Next, we use AUX_MU_IO_REG to either store the value of the transmitted character or read the value of the received character. We also have a very simple function that is capable of sending strings instead of characters: void uart_send_string(char* str) { for (int i = 0; str[i] != '\\0'; i ++) { uart_send((char)str[i]); } } This function just iterates over all characters in a string and sends them one by one. Low efficiency? Apparently Tx/Rx with busy wait burn lots of CPU cycles for no good. It's fine for our baremetal program -- simple & less error-prone. Production software often do interrupt-driven Rx/Tx.","title":"Sending data over UART"},{"location":"lesson01/rpi-os/#take-the-kernel-for-a-spin","text":"","title":"Take the kernel for a spin"},{"location":"lesson01/rpi-os/#rpi3","text":"Run make to build the kernel. The Raspberry Pi startup sequence is the following (simplified): The device is powered on. The GPU starts up and reads the config.txt file from the boot partition. This file contains some configuration parameters that the GPU uses to further adjust the startup sequence. kernel8.img is loaded into memory and executed. Setup To be able to run our simple OS, the config.txt file should be the following: enable_uart=1 arm_64bit=1 kernel_old=1 disable_commandline_tags=1 kernel_old=1 specifies that the kernel image should be loaded at address 0. disable_commandline_tags instructs the GPU to not pass any command line arguments to the booted image. Run Copy the generated kernel8.img file to the boot partition of your Raspberry Pi flash card and delete kernel7.img as well as any other kernel*.img files on your SD card. Make sure you left all other files in the boot partition untouched (see 43 and 158 issues for details). Update (2/10/21): students reported that UART1 stops to work with the newest Rpi3 firmware (either extracted from Raspbian OS or from the upstream github repo). The symptom: no \"helloworld\" is printed, while UART1 seems echoing fine. UART0 seems unaffected. My guess: it has something to do with the firmware's new device tree feature? Action: use older firmware provided by us: https://github.com/fxlin/p1-kernel/releases/tag/exp1-rpi3. Modify the config.txt file as described above. Connect the USB-to-TTL serial cable as described in the Prerequisites . Power on your Raspberry Pi. Open your terminal emulator. You should be able to see the Hello, world! message there. Aside (optional): prepare the SD card from scratch (w/o Raspbian) The steps above assume that you have Raspbian installed on your SD card. It is also possible to run the RPi OS using an empty SD card. Prepare your SD card: Use an MBR partition table Format the boot partition as FAT32 The card should be formatted exactly in the same way as it is required to install Raspbian. Check HOW TO FORMAT AN SD CARD AS FAT section in the official documenation for more information. Copy the following files to the card: bootcode.bin This is the GPU bootloader, it contains the GPU code to start the GPU and load the GPU firmware. start.elf This is the GPU firmware. It reads config.txt and enables the GPU to load and run ARM specific user code from kernel8.img Update (2/10/21): UART1 is broken by these upstream firmware for unknown reason. Use older firmware provided by us: https://github.com/fxlin/p1-kernel/releases/tag/exp1-rpi3. Copy kernel8.img and config.txt files. Connect the USB-to-TTL serial cable. Power on your Raspberry Pi. Use your terminal emulator to connect to the RPi OS. Unfortunately, all Raspberry Pi firmware files are closed-sourced and undocumented. For more information about the Raspberry Pi startup sequence, you can refer to some unofficial sources, like this StackExchange question or this Github repository.","title":"Rpi3"},{"location":"lesson01/rpi-os/#qemu","text":"Setup Follow the instructions in Prerequisites . Type make -f Makefile.qemu . Run $ qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio VNC server running on 127.0.0.1:5900 Hello, world! <Ctrl-C>","title":"QEMU"},{"location":"lesson02/rpi-os/","text":"2: Processor initialization Objectives Source code location: p1-kernel/src/lesson02 We are going to build: A baremetal program that can switch among CPU exception levels and print out the current level. Students will: Experiment with exception levels (ELs) Observe switches among ELs -- crucial for subsequent experiments! Tinker with the kernel, e.g. debugging Background: Exception levels (EL) ARMv8 defines 4 exception levels. An exception level is a processor execution mode in which only a subset of all operations and registers is available. The least privileged exception level, i.e. lowest level, is level 0. When processor operates at this level, it mostly uses only general purpose registers (X0 - X30) and stack pointer register (SP). EL0 also allows using STR and LDR instructions to load and store data to and from memory, among other instructions commonly used by a user program. Why exception levels? Because an OS needs to implement isolation . A user process should not be able to access other process's data. To achieve such behavior, a kernel always runs each user process at EL0. Operating at this exception level a process can only use it's own virtual memory and can't access any instructions that change ELs, MMUs, etc. The kernel itself usually works at EL1. While running at this exception level CPU gets access to the registers that allows configuring MMU as well as some system registers. About EL2/3 : we will not deal with EL 2 or EL 3 until project 3 (secure hardware enclaves). Let's briefly describe them. EL2 is for virtual machines. In this case the virtual machine hypervisor runs at EL2 and guest OSes run at EL1. This allows the hypervisor to isolate guest OSes in a similar way how OS isolates user processes. EL3 is for Arm TrustZone . It is used for transitions from ARM \"Secure World\" to \"Insecure world\". This abstraction exist to provide full hardware isolation between the software running in two different \"worlds\". Application from an \"Insecure world\" can in no way access or modify information (both instruction and data) that belongs to \"secure world\", and this restriction is enforced at the hardware level. Switching ELs In Arm architecture, there is no way a program can raise its own exception level without invoking code that is allowed to run on a higher level. This makes a perfect sense: otherwise, any program would be able to escape its assigned EL and makes unauthorized access to memory or registers. Current EL can be changed only if an exception is generated. Common causes of exceptions include: software executes some illegal instruction (for example, tries to access memory location at a nonexisting address; software tries to divide an integer by 0; software executes special instructions (e.g. svc ) to request exceptions. How about interrupts generated by IO? In Arm's lingo, interrupts are also handled as a special type of exceptions. Whenever an exception is generated the following sequence of steps takes place (In the description, the exception is handled at EL n , were n could be 1, 2 or 3). Address of the current instruction is saved in ELR_ELn (exception link register) Current processor state is stored in SPSR_ELn (Saved Program Status Register) NB: As some of you may know, other CPU hardware may automatically push registers on stack prior to exception handling. Armv8 does NOT do that. The CPU executes an exception handler at ELn. The exception handler calls eret instruction. This instruction restores processor state from SPSR_ELn and resumes execution starting from the address, stored in the ELR_ELn register. There are more details, e.g. the exception handler software also needs to store the state of all general purpose registers and restore it back afterwards, as we will discuss this process in details in the upcoming experiment. For now, we need just to understand the process in general and remember the meaning of the ELR_ELm and SPSR_ELn registers. An important thing to know is that exception handler is not obliged to return to the same instruction where the exception originates. Both ELR_ELm and SPSR_ELn are writable and the exception handler can modify them in order to specify the instructions to execute right after the EL switch. We are going to use this technique to our advantage when we try to switch from EL3 to EL1 in our code. Aside: enhanced debugging Bring up printf() Right now, the kernel can only print some constant string on a screen, but what I need is some analog of printf function. With printf I can easily display values of different registers and variables. Such functionality is essential for the kernel development because you don't have any other debugger support and printf becomes the only mean for figuring out what is going on inside Rpi3. Let's not reinvent the wheel and use one of existing printf implementations This function consists mostly from string manipulations and is not very interesting from a kernel developer point of view. The implementation that I used is very small and don't have external dependencies, that allows it to be easily integrated into the kernel. The only thing that I have to do is to define putc function that can send a single character to the screen. This function is defined here and it just uses already existing uart_send function. Also, we need to initialize the printf library and specify the location of the putc function. This is done in a single line of code . QEMU + GDB debugging Reminder: GDB allows you to do single step, etc. It may help understand/debug specific instructions. You can find extensive information online. Code Walkthrough Finding out the current EL As we are equipped with the printf function, we can proceed to figure out at which exception level the kernel is booted. A small function that can answer this question looks like this. .globl get_el get_el: mrs x0, CurrentEL lsr x0, x0, #2 ret Here we use mrs instruction to read the value from CurrentEL system register into x0 register. Then we shift this value 2 bits to the right (because the lowest 2 bits in the CurrentEL register are reserved and always have value 0). Finally the register x0 contains an integer number indicating current exception level. Now the only thing that is left is to display this value, like this . int el = get_el(); printf(\"Exception level: %d \\r\\n\", el); Rpi3: If you reproduce this experiment, you should see Exception level: 3 on the screen. This means the CPU executes as the security monitor when it boots up. QEMU: You will see Exception level: 2 because this is how QEMU emulates the CPU: setting the initial EL as 2. Why? Switching to EL1 EL1 is intended for OS kernels. Strictly speaking, our kernel is not obliged to switch to EL1 when it boots up, but EL1 is a natural choice for us because this level has just the right set of privileges to implement all common OS tasks. It also will be an interesting exercise to see how switching exceptions levels works in action. Let's take a look at the source code that does this (boot.S). master: ldr x0, =SCTLR_VALUE_MMU_DISABLED msr sctlr_el1, x0 ldr x0, =HCR_VALUE msr hcr_el2, x0 ldr x0, =SCR_VALUE msr scr_el3, x0 ldr x0, =SPSR_VALUE msr spsr_el3, x0 adr x0, el1_entry msr elr_el3, x0 eret The code configures a few system registers. Now we are going to examine those registers one by one. The register details are documented in the Armv8 architecture manual which we will refer to as needed. SCTLR_EL1, System Control Register (EL1) ldr x0, =SCTLR_VALUE_MMU_DISABLED msr sctlr_el1, x0 Here we set the value of the sctlr_el1 system register. sctlr_el1 is responsible for configuring different parameters of CPU when CPU operates at EL1. For example, it controls whether the cache is enabled and, what is most important for us, whether the MMU (Memory Management Unit) is turned on. sctlr_el1 is accessible from all exception levels higher or equal than EL1 (you can infer this from _el1 postfix) SCTLR_VALUE_MMU_DISABLED constant is defined here Individual bits of this value are defined like this: #define SCTLR_RESERVED (3 << 28) | (3 << 22) | (1 << 20) | (1 << 11) Some bits in the description of sctlr_el1 register are marked as RES1 . Those bits are reserved for future usage and should be initialized with 1 . #define SCTLR_EE_LITTLE_ENDIAN (0 << 25) Exception Endianness . This field controls endianess of explicit data access at EL1. We are going to configure the processor to work only with little-endian format. #define SCTLR_EOE_LITTLE_ENDIAN (0 << 24) Similar to previous field but this one controls endianess of explicit data access at EL0, instead of EL1. #define SCTLR_I_CACHE_DISABLED (0 << 12) Disable instruction cache. We are going to disable all caches for simplicity. You can find more information about data and instruction caches here . #define SCTLR_D_CACHE_DISABLED (0 << 2) Disable data cache. #define SCTLR_MMU_DISABLED (0 << 0) Disable MMU. MMU must be disabled until the lesson 6, where we are going to prepare page tables and start working with virtual memory. FYI - official doc HCR_EL2, Hypervisor Configuration (EL2) ldr x0, =HCR_VALUE msr hcr_el2, x0 We are NOT going to implement our own hypervisor . Still we need to use this register. Among other settings, bit 31 (RW) controls the execution state at EL1, being AArch64 (1) or AArch32 (0). This register also controls at which EL we will handle IRQ. In sysregs.h we set HCR_VALUE to be (1<<31). Official doc SCR_EL3, Secure Configuration (EL3) ldr x0, =SCR_VALUE msr scr_el3, x0 This register is responsible for configuring security settings. For example, it controls whether all lower levels are executed in \"secure\" or \"nonsecure\" world. It also controls execution state at EL2. Here we set that EL2 will execute at AArch64 state, and all lower exception levels will be \"non secure\". This register has no counterpart at EL2. Therefore, we don't have to set it on qemu emulation. Official doc SPSR_EL3, Saved Program Status (EL3) ldr x0, =SPSR_VALUE msr spsr_el3, x0 spsr_el3 contains CPU state, that will be restored after we execute eret instruction. What is CPU state? It consists of the following information: Condition Flags Those flags contains information about previously executed executions: whether the result was negative (N flag), zero (A flag), has unsigned overflow (C flag) or has signed overflow (V flag). Values of those flags can be used in conditional branch instructions. For example, b.eq instruction will jump to the provided label only if the result of the last comparison operation is equal to 0. The processor checks this by testing whether Z flag is set to 1. Interrupt disable bits Those bits allows to enable/disable different types of interrupts. EL & other information , required to fully restore the processor execution state after an exception is handled. Usually spsr_el3 is saved automatically by CPU hardware, when an exception is taken to EL3. Furthermore, this register is writable by our code, so we take advantage of this fact and manually prepare CPU state. SPSR_VALUE is prepared here and we initialize the following fields: #define SPSR_MASK_ALL (7 << 6) After we change EL to EL1 all types of interrupts will be masked (or disabled, which is the same). #define SPSR_EL1h (5 << 0) This indicates to which EL the eret instruction will take the CPU to. It's EL1. About EL1h: At EL1 we can either use our own dedicated stack pointer or use EL0 stack pointer. EL1h mode means that we are using EL1 dedicated stack pointer. Official doc ELR_EL3, Exception Link (EL3) adr x0, el1_entry msr elr_el3, x0 eret elr_el3 holds the address, to which we are going to return after eret instruction will be executed. Here we set this address to the location of el1_entry label. Official doc Conclusion That is pretty much it: when we enter el1_entry function the execution should be already at EL1 mode. Qemu.log: Exception return from AArch64 EL2 to AArch64 EL1 PC 0x80038 The address 0x80038 should point to el1_entry. Check it out using addr2line. Our subsequent experiments will switch between EL1 (kernel) and EL0 (user) frequently. Go ahead and try it out!","title":"exp2"},{"location":"lesson02/rpi-os/#2-processor-initialization","text":"","title":"2: Processor initialization"},{"location":"lesson02/rpi-os/#objectives","text":"Source code location: p1-kernel/src/lesson02 We are going to build: A baremetal program that can switch among CPU exception levels and print out the current level. Students will: Experiment with exception levels (ELs) Observe switches among ELs -- crucial for subsequent experiments! Tinker with the kernel, e.g. debugging","title":"Objectives"},{"location":"lesson02/rpi-os/#background-exception-levels-el","text":"ARMv8 defines 4 exception levels. An exception level is a processor execution mode in which only a subset of all operations and registers is available. The least privileged exception level, i.e. lowest level, is level 0. When processor operates at this level, it mostly uses only general purpose registers (X0 - X30) and stack pointer register (SP). EL0 also allows using STR and LDR instructions to load and store data to and from memory, among other instructions commonly used by a user program. Why exception levels? Because an OS needs to implement isolation . A user process should not be able to access other process's data. To achieve such behavior, a kernel always runs each user process at EL0. Operating at this exception level a process can only use it's own virtual memory and can't access any instructions that change ELs, MMUs, etc. The kernel itself usually works at EL1. While running at this exception level CPU gets access to the registers that allows configuring MMU as well as some system registers. About EL2/3 : we will not deal with EL 2 or EL 3 until project 3 (secure hardware enclaves). Let's briefly describe them. EL2 is for virtual machines. In this case the virtual machine hypervisor runs at EL2 and guest OSes run at EL1. This allows the hypervisor to isolate guest OSes in a similar way how OS isolates user processes. EL3 is for Arm TrustZone . It is used for transitions from ARM \"Secure World\" to \"Insecure world\". This abstraction exist to provide full hardware isolation between the software running in two different \"worlds\". Application from an \"Insecure world\" can in no way access or modify information (both instruction and data) that belongs to \"secure world\", and this restriction is enforced at the hardware level.","title":"Background: Exception levels (EL)"},{"location":"lesson02/rpi-os/#switching-els","text":"In Arm architecture, there is no way a program can raise its own exception level without invoking code that is allowed to run on a higher level. This makes a perfect sense: otherwise, any program would be able to escape its assigned EL and makes unauthorized access to memory or registers. Current EL can be changed only if an exception is generated. Common causes of exceptions include: software executes some illegal instruction (for example, tries to access memory location at a nonexisting address; software tries to divide an integer by 0; software executes special instructions (e.g. svc ) to request exceptions. How about interrupts generated by IO? In Arm's lingo, interrupts are also handled as a special type of exceptions. Whenever an exception is generated the following sequence of steps takes place (In the description, the exception is handled at EL n , were n could be 1, 2 or 3). Address of the current instruction is saved in ELR_ELn (exception link register) Current processor state is stored in SPSR_ELn (Saved Program Status Register) NB: As some of you may know, other CPU hardware may automatically push registers on stack prior to exception handling. Armv8 does NOT do that. The CPU executes an exception handler at ELn. The exception handler calls eret instruction. This instruction restores processor state from SPSR_ELn and resumes execution starting from the address, stored in the ELR_ELn register. There are more details, e.g. the exception handler software also needs to store the state of all general purpose registers and restore it back afterwards, as we will discuss this process in details in the upcoming experiment. For now, we need just to understand the process in general and remember the meaning of the ELR_ELm and SPSR_ELn registers. An important thing to know is that exception handler is not obliged to return to the same instruction where the exception originates. Both ELR_ELm and SPSR_ELn are writable and the exception handler can modify them in order to specify the instructions to execute right after the EL switch. We are going to use this technique to our advantage when we try to switch from EL3 to EL1 in our code.","title":"Switching ELs"},{"location":"lesson02/rpi-os/#aside-enhanced-debugging","text":"","title":"Aside: enhanced debugging"},{"location":"lesson02/rpi-os/#bring-up-printf","text":"Right now, the kernel can only print some constant string on a screen, but what I need is some analog of printf function. With printf I can easily display values of different registers and variables. Such functionality is essential for the kernel development because you don't have any other debugger support and printf becomes the only mean for figuring out what is going on inside Rpi3. Let's not reinvent the wheel and use one of existing printf implementations This function consists mostly from string manipulations and is not very interesting from a kernel developer point of view. The implementation that I used is very small and don't have external dependencies, that allows it to be easily integrated into the kernel. The only thing that I have to do is to define putc function that can send a single character to the screen. This function is defined here and it just uses already existing uart_send function. Also, we need to initialize the printf library and specify the location of the putc function. This is done in a single line of code .","title":"Bring up printf()"},{"location":"lesson02/rpi-os/#qemu-gdb-debugging","text":"Reminder: GDB allows you to do single step, etc. It may help understand/debug specific instructions. You can find extensive information online.","title":"QEMU + GDB debugging"},{"location":"lesson02/rpi-os/#code-walkthrough","text":"","title":"Code Walkthrough"},{"location":"lesson02/rpi-os/#finding-out-the-current-el","text":"As we are equipped with the printf function, we can proceed to figure out at which exception level the kernel is booted. A small function that can answer this question looks like this. .globl get_el get_el: mrs x0, CurrentEL lsr x0, x0, #2 ret Here we use mrs instruction to read the value from CurrentEL system register into x0 register. Then we shift this value 2 bits to the right (because the lowest 2 bits in the CurrentEL register are reserved and always have value 0). Finally the register x0 contains an integer number indicating current exception level. Now the only thing that is left is to display this value, like this . int el = get_el(); printf(\"Exception level: %d \\r\\n\", el); Rpi3: If you reproduce this experiment, you should see Exception level: 3 on the screen. This means the CPU executes as the security monitor when it boots up. QEMU: You will see Exception level: 2 because this is how QEMU emulates the CPU: setting the initial EL as 2. Why?","title":"Finding out the current EL"},{"location":"lesson02/rpi-os/#switching-to-el1","text":"EL1 is intended for OS kernels. Strictly speaking, our kernel is not obliged to switch to EL1 when it boots up, but EL1 is a natural choice for us because this level has just the right set of privileges to implement all common OS tasks. It also will be an interesting exercise to see how switching exceptions levels works in action. Let's take a look at the source code that does this (boot.S). master: ldr x0, =SCTLR_VALUE_MMU_DISABLED msr sctlr_el1, x0 ldr x0, =HCR_VALUE msr hcr_el2, x0 ldr x0, =SCR_VALUE msr scr_el3, x0 ldr x0, =SPSR_VALUE msr spsr_el3, x0 adr x0, el1_entry msr elr_el3, x0 eret The code configures a few system registers. Now we are going to examine those registers one by one. The register details are documented in the Armv8 architecture manual which we will refer to as needed.","title":"Switching to EL1"},{"location":"lesson02/rpi-os/#sctlr_el1-system-control-register-el1","text":"ldr x0, =SCTLR_VALUE_MMU_DISABLED msr sctlr_el1, x0 Here we set the value of the sctlr_el1 system register. sctlr_el1 is responsible for configuring different parameters of CPU when CPU operates at EL1. For example, it controls whether the cache is enabled and, what is most important for us, whether the MMU (Memory Management Unit) is turned on. sctlr_el1 is accessible from all exception levels higher or equal than EL1 (you can infer this from _el1 postfix) SCTLR_VALUE_MMU_DISABLED constant is defined here Individual bits of this value are defined like this: #define SCTLR_RESERVED (3 << 28) | (3 << 22) | (1 << 20) | (1 << 11) Some bits in the description of sctlr_el1 register are marked as RES1 . Those bits are reserved for future usage and should be initialized with 1 . #define SCTLR_EE_LITTLE_ENDIAN (0 << 25) Exception Endianness . This field controls endianess of explicit data access at EL1. We are going to configure the processor to work only with little-endian format. #define SCTLR_EOE_LITTLE_ENDIAN (0 << 24) Similar to previous field but this one controls endianess of explicit data access at EL0, instead of EL1. #define SCTLR_I_CACHE_DISABLED (0 << 12) Disable instruction cache. We are going to disable all caches for simplicity. You can find more information about data and instruction caches here . #define SCTLR_D_CACHE_DISABLED (0 << 2) Disable data cache. #define SCTLR_MMU_DISABLED (0 << 0) Disable MMU. MMU must be disabled until the lesson 6, where we are going to prepare page tables and start working with virtual memory. FYI - official doc","title":"SCTLR_EL1, System Control Register (EL1)"},{"location":"lesson02/rpi-os/#hcr_el2-hypervisor-configuration-el2","text":"ldr x0, =HCR_VALUE msr hcr_el2, x0 We are NOT going to implement our own hypervisor . Still we need to use this register. Among other settings, bit 31 (RW) controls the execution state at EL1, being AArch64 (1) or AArch32 (0). This register also controls at which EL we will handle IRQ. In sysregs.h we set HCR_VALUE to be (1<<31). Official doc","title":"HCR_EL2, Hypervisor Configuration (EL2)"},{"location":"lesson02/rpi-os/#scr_el3-secure-configuration-el3","text":"ldr x0, =SCR_VALUE msr scr_el3, x0 This register is responsible for configuring security settings. For example, it controls whether all lower levels are executed in \"secure\" or \"nonsecure\" world. It also controls execution state at EL2. Here we set that EL2 will execute at AArch64 state, and all lower exception levels will be \"non secure\". This register has no counterpart at EL2. Therefore, we don't have to set it on qemu emulation. Official doc","title":"SCR_EL3, Secure Configuration (EL3)"},{"location":"lesson02/rpi-os/#spsr_el3-saved-program-status-el3","text":"ldr x0, =SPSR_VALUE msr spsr_el3, x0 spsr_el3 contains CPU state, that will be restored after we execute eret instruction. What is CPU state? It consists of the following information: Condition Flags Those flags contains information about previously executed executions: whether the result was negative (N flag), zero (A flag), has unsigned overflow (C flag) or has signed overflow (V flag). Values of those flags can be used in conditional branch instructions. For example, b.eq instruction will jump to the provided label only if the result of the last comparison operation is equal to 0. The processor checks this by testing whether Z flag is set to 1. Interrupt disable bits Those bits allows to enable/disable different types of interrupts. EL & other information , required to fully restore the processor execution state after an exception is handled. Usually spsr_el3 is saved automatically by CPU hardware, when an exception is taken to EL3. Furthermore, this register is writable by our code, so we take advantage of this fact and manually prepare CPU state. SPSR_VALUE is prepared here and we initialize the following fields: #define SPSR_MASK_ALL (7 << 6) After we change EL to EL1 all types of interrupts will be masked (or disabled, which is the same). #define SPSR_EL1h (5 << 0) This indicates to which EL the eret instruction will take the CPU to. It's EL1. About EL1h: At EL1 we can either use our own dedicated stack pointer or use EL0 stack pointer. EL1h mode means that we are using EL1 dedicated stack pointer. Official doc","title":"SPSR_EL3, Saved Program Status (EL3)"},{"location":"lesson02/rpi-os/#elr_el3-exception-link-el3","text":"adr x0, el1_entry msr elr_el3, x0 eret elr_el3 holds the address, to which we are going to return after eret instruction will be executed. Here we set this address to the location of el1_entry label. Official doc","title":"ELR_EL3, Exception Link (EL3)"},{"location":"lesson02/rpi-os/#conclusion","text":"That is pretty much it: when we enter el1_entry function the execution should be already at EL1 mode. Qemu.log: Exception return from AArch64 EL2 to AArch64 EL1 PC 0x80038 The address 0x80038 should point to el1_entry. Check it out using addr2line. Our subsequent experiments will switch between EL1 (kernel) and EL0 (user) frequently. Go ahead and try it out!","title":"Conclusion"},{"location":"lesson03/fb/","text":"3 bonus: Interrupt-driven animation This is optional for the course purpose. Thus, this write up is not intended to be as thorough as others. Objectives See a use case of interrupts Learn about framebuffer Have some eye candy. Environment Rpi3 : need an HDMI cable connecting to a display. QEMU : run QEMU locally as we need an emulated display. Windows users : recommend to download prebuilt QEMU binaries. https://www.qemu.org/download/. You can build QEMU from source within WSL. I did that. Make sure to include graphics support. Likely slower than native binaries. To invoke prebuilt QEMU from PowerShell: Mac users : Ditto. See link above. Linux users : apt-get; if you build from source, make sure to include graphics support. Quick start cd lesson03-bonus make clean USE_QEMU=1 make # for QEMU USE_QEMU make # for rpi3 Pre-built binaries for Rpi3: https://github.com/fxlin/p1-kernel/releases/tag/p1exp3bonus Result (Rpi3) QEMU has caveats. See below. Background Framebuffer A memory region for pixel data. In the simplest form, CPU write RGB values there and pixels will show up on the display. Mailbox. On Rpi3, CPU talks to GPU through hardware mailbox. It's a small piece of memory shared between CPU/GPU. CPU puts commands in the shared memory (mbox) and kicks the GPU by writing to a GPU register; GPU executes the commands and responds by writing results to the shared memory. Code: mbox.c Rpi3 framebuffer properties On Rpi3, CPU talks to the GPU to set up the framebuffer. This function constructs a mbox message for GPU with a series of framebuffer properties. Virtual height/width define the framebuffer dimension. CPU is responsible for providing these pixels. Physical height/width define a rectangular region of pixels to be displayed. These pixels are derived by GPU from the framebuffer. See below. Virtual offsets define the top-left corner of the physical region within the virtual region. Pitch (bytes) is the actual memory size that each pixel raw takes in the framebuffer. Note: the following is based on (1) the Rpi foundation online documentation ; (2) QEMU source code for emulating Rpi3 GPU/display; (3) my experiments on Rpi3. (1) can be vague or erroneous and (2) is rudimentary. Case 1 : Virtual region > physical region (i.e. the viewport is a strict subpart of the framebuffer). This can be useful for screen panning and double buffering. This is how game consoles implement scrolling, e.g. over a large map pre-rendered in memory. Here's an excellent video on GameBoy: https://www.youtube.com/watch?v=FzPTK91EJY8&t=405s The Rpi3 mechanism is shown in the figure above. The hardware takes the pixels in from the viewport (defined by the phys region) in the framebuffer and sends to display. Scaling is applied before the final display. The viewport size does not necessarily correspond to the resolution on display. For instance, the viewport (phys height x width) can be 300x300; the final picture on the display could occupy the full screen (with x/y ratio preserved). This is also in the figure above. Case 2: Virtual region < physical region (i.e. the viewport is a strict superpart of the framebuffer) In this case, GPU scales the framebuffer pixels (virtual region) to the viewport (physical region). GPU seems to be doing interpolation to generate the additional pixels. Then GPU sends the physical region to display as above. The virtual region can be very small. \"On boot, the virtual size is set to 2x2. If a framebuffer is allocated without reconfiguring the virtual size, the screen will consist of four very large virtual pixels. Coloured red, green, yellow and blue, they produce the \"rainbow\" startup screen.\" [2]. See the picture below. This is the default display when Rpi3 boots without any additional changes to its default 2x2 (four pixel) framebuffer. Virtual offsets are ineffective. I confirmed that. QEMU code fb_use_offsets also suggests so. The picture below: the virtual region: 64x48 filled with a test image of 64x48; the physical region: 600x600. Case 3: otherwise? (untested. Per QEMU code virtual offsets will be ineffective). QEMU's emulation caveats (Observation based on QEMU's master branch as of Feb 2020.) QEMU's emulation of Rpi3 display only realizes the most common cases, e.g. virt = physical with offsets=0. Beyond that, it's quite problematic. For instance, here's how QEMU would display when virt 64x48 < physical 600x600, showing it does not implement scaling. QEMU display will also flicker when CPU is updating offsets periodically. Likely a bug in the code below. hw/misc/bcm2835_property.c implements the CPU/GPU mailbox interface. Can see what framebuffer properties are implemented. hw/display/bcm2835_fb.c has the actual emulation logic. See fb_use_offsets() which only applies virt offsets when virtual is smaller than physical. bcm2835_fb_validate_config() is how QEMU think the Rpi3 framebuffer should work, which can be problematic. Kernel code walkthrough Set up the framebuffer lfb.c is the framebuffer code. lfb_init sets up the framebuffer dimension. lfb_showicture() fills in the framebuffer with pixels from an image. We do not load from an image file (no filesystem yet!). Instead, we convert an image to a C header (e.g. tv-test-scree.h) using GIMP. Pretty cool! The header looks like this: static unsigned int tv_width = 1280; static unsigned int tv_height = 800; /* Call this macro repeatedly. After each use, the pixel data can be extracted */ #define HEADER_PIXEL(data,pixel) {\\ pixel[0] = (((data[0] - 33) << 2) | ((data[1] - 33) >> 4)); \\ pixel[1] = ((((data[1] - 33) & 0xF) << 4) | ((data[2] - 33) >> 2)); \\ pixel[2] = ((((data[2] - 33) & 0x3) << 6) | ((data[3] - 33))); \\ data += 4; \\ } static char *tv_data = \"````````````````````````````````````````````````````````````````\" \"````````````````````````````````````````````````````````````````\" \"`0T]I+#A!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\" \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\" \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\" \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!35F*Y_0D````````````````\" \"````````````````````````````````````````````````````````````````\" ... The header can be large, e.g. a few MBs. As a result, the raw RGB values will be compiled as an array in our kernel. Adjust the linker script Now build the kernel. You may see an error like this: aarch64-linux-gnu-ld -T build-qemu/linker.ld -o build-qemu/kernel8.elf build-qemu/mbox_c.o build-qemu/lfb_c.o build-qemu/kernel_c.o build-qemu/irq_c.o build-qemu/mini_uart_c.o build-qemu/printf_c.o build-qemu/timer_c.o build-qemu/timer_s.o build-qemu/utils_s.o build-qemu/irq_s.o build-qemu/entry_s.o build-qemu/mm_s.o build-qemu/boot_s.o build-qemu/boot_s.o: In function `el1_entry': /data/teaching/p1-kernel-workspace/p1-kernel/src/lesson03-bonus/src/boot.S:44:(.text.boot+0x38): relocation truncated to fit: R_AARCH64_ADR_PREL_LO21 against symbol `bss_begin' defined in .bss section in build-qemu/kernel8.elf /data/teaching/p1-kernel-workspace/p1-kernel/src/lesson03-bonus/src/boot.S:45:(.text.boot+0x3c): relocation truncated to fit: R_AARCH64_ADR_PREL_LO21 against symbol `bss_end' defined in .bss section in build-qemu/kernel8.elf Makefile:49: recipe for target 'kernel8.img' failed make: *** [kernel8.img] Error 1 Understand this is a linker error: because the message shows up when invoking ld . Per the error message, this error is about el1_entry . el1_entry: adr x0, bss_begin adr x1, bss_end It refers to two symbols bss_begin and bss_end using instructions ADR (\"R_AARCH64_ADR_PREL_LO21\"). The instructions encode the addresses of bss_begin/end as relative offsets to PC. The maximum offsets are 21 bits (\"LO21\"). Now we put lots of extra bytes in .data section, el1_entry is too far away from bss_begin/end. This can be seen from the existing linker script, where .data is sandwiched in between .text.boot and .bss. SECTIONS { . = START_ADDR; .text.boot : { *(.text.boot) } .text : { *(.text) } .rodata : { *(.rodata) } .data : { *(.data) } . = ALIGN(0x8); bss_begin = .; .bss : { *(.bss*) } bss_end = .; } Solution: move .bss to right after .text and we are good. Updating the framebuffer lfb_update simply increments virt offsets via mbox to the GPU. From the timer interrupt, we call lfb_update : void handle_generic_timer_irq( void ) { gen_timer_reset(interval); lfb_update(); // refresh fb } Known issues Reference https://github.com/bztsrc/raspi3-tutorial/tree/master/09_framebuffer https://github.com/brianwiddas/pi-baremetal As tribute to... KONAMI, Fighting Eleven World Soccer 2, Super Famicom, 1995.","title":"3 bonus: Interrupt-driven animation"},{"location":"lesson03/fb/#3-bonus-interrupt-driven-animation","text":"This is optional for the course purpose. Thus, this write up is not intended to be as thorough as others.","title":"3 bonus: Interrupt-driven animation"},{"location":"lesson03/fb/#objectives","text":"See a use case of interrupts Learn about framebuffer Have some eye candy.","title":"Objectives"},{"location":"lesson03/fb/#environment","text":"Rpi3 : need an HDMI cable connecting to a display. QEMU : run QEMU locally as we need an emulated display. Windows users : recommend to download prebuilt QEMU binaries. https://www.qemu.org/download/. You can build QEMU from source within WSL. I did that. Make sure to include graphics support. Likely slower than native binaries. To invoke prebuilt QEMU from PowerShell: Mac users : Ditto. See link above. Linux users : apt-get; if you build from source, make sure to include graphics support.","title":"Environment"},{"location":"lesson03/fb/#quick-start","text":"cd lesson03-bonus make clean USE_QEMU=1 make # for QEMU USE_QEMU make # for rpi3 Pre-built binaries for Rpi3: https://github.com/fxlin/p1-kernel/releases/tag/p1exp3bonus","title":"Quick start"},{"location":"lesson03/fb/#result-rpi3","text":"QEMU has caveats. See below.","title":"Result (Rpi3)"},{"location":"lesson03/fb/#background","text":"Framebuffer A memory region for pixel data. In the simplest form, CPU write RGB values there and pixels will show up on the display. Mailbox. On Rpi3, CPU talks to GPU through hardware mailbox. It's a small piece of memory shared between CPU/GPU. CPU puts commands in the shared memory (mbox) and kicks the GPU by writing to a GPU register; GPU executes the commands and responds by writing results to the shared memory. Code: mbox.c","title":"Background"},{"location":"lesson03/fb/#rpi3-framebuffer-properties","text":"On Rpi3, CPU talks to the GPU to set up the framebuffer. This function constructs a mbox message for GPU with a series of framebuffer properties. Virtual height/width define the framebuffer dimension. CPU is responsible for providing these pixels. Physical height/width define a rectangular region of pixels to be displayed. These pixels are derived by GPU from the framebuffer. See below. Virtual offsets define the top-left corner of the physical region within the virtual region. Pitch (bytes) is the actual memory size that each pixel raw takes in the framebuffer. Note: the following is based on (1) the Rpi foundation online documentation ; (2) QEMU source code for emulating Rpi3 GPU/display; (3) my experiments on Rpi3. (1) can be vague or erroneous and (2) is rudimentary. Case 1 : Virtual region > physical region (i.e. the viewport is a strict subpart of the framebuffer). This can be useful for screen panning and double buffering. This is how game consoles implement scrolling, e.g. over a large map pre-rendered in memory. Here's an excellent video on GameBoy: https://www.youtube.com/watch?v=FzPTK91EJY8&t=405s The Rpi3 mechanism is shown in the figure above. The hardware takes the pixels in from the viewport (defined by the phys region) in the framebuffer and sends to display. Scaling is applied before the final display. The viewport size does not necessarily correspond to the resolution on display. For instance, the viewport (phys height x width) can be 300x300; the final picture on the display could occupy the full screen (with x/y ratio preserved). This is also in the figure above. Case 2: Virtual region < physical region (i.e. the viewport is a strict superpart of the framebuffer) In this case, GPU scales the framebuffer pixels (virtual region) to the viewport (physical region). GPU seems to be doing interpolation to generate the additional pixels. Then GPU sends the physical region to display as above. The virtual region can be very small. \"On boot, the virtual size is set to 2x2. If a framebuffer is allocated without reconfiguring the virtual size, the screen will consist of four very large virtual pixels. Coloured red, green, yellow and blue, they produce the \"rainbow\" startup screen.\" [2]. See the picture below. This is the default display when Rpi3 boots without any additional changes to its default 2x2 (four pixel) framebuffer. Virtual offsets are ineffective. I confirmed that. QEMU code fb_use_offsets also suggests so. The picture below: the virtual region: 64x48 filled with a test image of 64x48; the physical region: 600x600. Case 3: otherwise? (untested. Per QEMU code virtual offsets will be ineffective).","title":"Rpi3 framebuffer properties"},{"location":"lesson03/fb/#qemus-emulation-caveats","text":"(Observation based on QEMU's master branch as of Feb 2020.) QEMU's emulation of Rpi3 display only realizes the most common cases, e.g. virt = physical with offsets=0. Beyond that, it's quite problematic. For instance, here's how QEMU would display when virt 64x48 < physical 600x600, showing it does not implement scaling. QEMU display will also flicker when CPU is updating offsets periodically. Likely a bug in the code below. hw/misc/bcm2835_property.c implements the CPU/GPU mailbox interface. Can see what framebuffer properties are implemented. hw/display/bcm2835_fb.c has the actual emulation logic. See fb_use_offsets() which only applies virt offsets when virtual is smaller than physical. bcm2835_fb_validate_config() is how QEMU think the Rpi3 framebuffer should work, which can be problematic.","title":"QEMU's emulation caveats"},{"location":"lesson03/fb/#kernel-code-walkthrough","text":"","title":"Kernel code walkthrough"},{"location":"lesson03/fb/#set-up-the-framebuffer","text":"lfb.c is the framebuffer code. lfb_init sets up the framebuffer dimension. lfb_showicture() fills in the framebuffer with pixels from an image. We do not load from an image file (no filesystem yet!). Instead, we convert an image to a C header (e.g. tv-test-scree.h) using GIMP. Pretty cool! The header looks like this: static unsigned int tv_width = 1280; static unsigned int tv_height = 800; /* Call this macro repeatedly. After each use, the pixel data can be extracted */ #define HEADER_PIXEL(data,pixel) {\\ pixel[0] = (((data[0] - 33) << 2) | ((data[1] - 33) >> 4)); \\ pixel[1] = ((((data[1] - 33) & 0xF) << 4) | ((data[2] - 33) >> 2)); \\ pixel[2] = ((((data[2] - 33) & 0x3) << 6) | ((data[3] - 33))); \\ data += 4; \\ } static char *tv_data = \"````````````````````````````````````````````````````````````````\" \"````````````````````````````````````````````````````````````````\" \"`0T]I+#A!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\" \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\" \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\" \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!35F*Y_0D````````````````\" \"````````````````````````````````````````````````````````````````\" ... The header can be large, e.g. a few MBs. As a result, the raw RGB values will be compiled as an array in our kernel.","title":"Set up the framebuffer"},{"location":"lesson03/fb/#adjust-the-linker-script","text":"Now build the kernel. You may see an error like this: aarch64-linux-gnu-ld -T build-qemu/linker.ld -o build-qemu/kernel8.elf build-qemu/mbox_c.o build-qemu/lfb_c.o build-qemu/kernel_c.o build-qemu/irq_c.o build-qemu/mini_uart_c.o build-qemu/printf_c.o build-qemu/timer_c.o build-qemu/timer_s.o build-qemu/utils_s.o build-qemu/irq_s.o build-qemu/entry_s.o build-qemu/mm_s.o build-qemu/boot_s.o build-qemu/boot_s.o: In function `el1_entry': /data/teaching/p1-kernel-workspace/p1-kernel/src/lesson03-bonus/src/boot.S:44:(.text.boot+0x38): relocation truncated to fit: R_AARCH64_ADR_PREL_LO21 against symbol `bss_begin' defined in .bss section in build-qemu/kernel8.elf /data/teaching/p1-kernel-workspace/p1-kernel/src/lesson03-bonus/src/boot.S:45:(.text.boot+0x3c): relocation truncated to fit: R_AARCH64_ADR_PREL_LO21 against symbol `bss_end' defined in .bss section in build-qemu/kernel8.elf Makefile:49: recipe for target 'kernel8.img' failed make: *** [kernel8.img] Error 1 Understand this is a linker error: because the message shows up when invoking ld . Per the error message, this error is about el1_entry . el1_entry: adr x0, bss_begin adr x1, bss_end It refers to two symbols bss_begin and bss_end using instructions ADR (\"R_AARCH64_ADR_PREL_LO21\"). The instructions encode the addresses of bss_begin/end as relative offsets to PC. The maximum offsets are 21 bits (\"LO21\"). Now we put lots of extra bytes in .data section, el1_entry is too far away from bss_begin/end. This can be seen from the existing linker script, where .data is sandwiched in between .text.boot and .bss. SECTIONS { . = START_ADDR; .text.boot : { *(.text.boot) } .text : { *(.text) } .rodata : { *(.rodata) } .data : { *(.data) } . = ALIGN(0x8); bss_begin = .; .bss : { *(.bss*) } bss_end = .; } Solution: move .bss to right after .text and we are good.","title":"Adjust the linker script"},{"location":"lesson03/fb/#updating-the-framebuffer","text":"lfb_update simply increments virt offsets via mbox to the GPU. From the timer interrupt, we call lfb_update : void handle_generic_timer_irq( void ) { gen_timer_reset(interval); lfb_update(); // refresh fb }","title":"Updating the framebuffer"},{"location":"lesson03/fb/#known-issues","text":"","title":"Known issues"},{"location":"lesson03/fb/#reference","text":"https://github.com/bztsrc/raspi3-tutorial/tree/master/09_framebuffer https://github.com/brianwiddas/pi-baremetal","title":"Reference"},{"location":"lesson03/fb/#as-tribute-to","text":"KONAMI, Fighting Eleven World Soccer 2, Super Famicom, 1995.","title":"As tribute to..."},{"location":"lesson03/rpi-os/","text":"3: Interrupts Objectives Source code location: p1-kernel/src/lesson03 We will build a baremetal program that prints out messages, as driven by periodic interrupts from a hardware timer. You will learn and experience with: Exception/interrupt vectors Handling interrupts Program hardware timers Terms \"Interrupts\" or \"irq\"? We use these two terms interchangeably. Many kernel documents use the latter. Background: interrupts & exceptions in ARM64 Interrupts Interrupts are generated by IO devices, go through the irq controller, and eventually arrive the CPU. The CPU can program the irq controller to enable/disable specific interrupt sources. By disabling an irq source, the CPU will not lose any irq from that device, but just defer receiving irq until the CPU re-enables the irq source. The CPU can also read from the irq controller which IO devices have pending interrupts, meaning that the IO devices need attention. By their canonical definitions, interrupts are asynchronous while exceptions are synchronous. Interrupts & Exceptions on aarch64 However in ARM64 lingo, exception is broadly defined; interrupts are a special kind of exceptions. x86 has its own lingo, calling exceptions as \"traps\". In this article, we use ARM's broad definition of exceptions unless stated otherwise. Exception vectors Figure above: the EL1 vector table as in memory. Note that EL2 and EL3 each has a vector table like this An exception vector (or handler) is a piece of code the CPU will execute when a specific exception happens. \" These would normally be branch instructions that direct the core to the full exception handler. \" (the ARM64 manual). The ARM64 hardware mandates: each exception vector can occupy 0x80 bytes maximum (thus .align 7 in the asm code). In some other architectures an exception vector could be an address to jump to. Note the subtle difference. A vector table is an array of exception vectors. Each exception level (EL) has its own vector table. The vector table for EL1 . Provided by our kernel. Purpose: to handle exceptions taken from EL0 (user programs) or EL1 (the kernel's own execution) to EL1. Format: the kernel define 16 exception handlers : 4 types [SError, fiq, irq, sync] X CPU 4 execution states [EL1t, EL1h, EL0_64, EL0_32]. Four exception types (focus the former two) Synchronous exception s Exceptions of this type are always caused by the currently executed instruction. For example, you can use str instruction to store some data at a non-existing memory location. In this case, a synchronous exception is generated. Synchronous exceptions also can be used to generate a \"software interrupt\". Software interrupt is a synchronous exception that is generated on purpose by svc instruction. We will use this technique in lesson 5 to implement system calls. Asynchronous exceptions (IRQ) Those are normal interrupts. They are always asynchronous, which means that they have nothing to do with the currently executed instruction. In contrast to synchronous exceptions, they are always not generated by the processor itself, but by external hardware. FIQ (Fast Interrupt Request) This type of exception is called \"fast interrupts\" and exist solely for the purpose of prioritizing exceptions. It is possible to configure some interrupts as \"normal\" and other as \"fast\". Fast interrupts will be signaled first and will be handled by a separate exception handler. Linux doesn't use fast interrupts and we also are not going to do so. SError (System Error) Like IRQ and FIQ , SError exceptions are asynchronous and are generated by external hardware. Unlike IRQ and FIQ , SError always indicates some error condition. Here you can find an example explaining when SError can be generated. Four CPU execution states EL1t Exception happens when CPU is at EL1 while the stack pointer (SP) was set to be shared with EL0. This happens when SPSel register holds the value 0 . Recall that SPSel is part of the CPU's PSTATE. EL1h Exception happens at EL1 at the time when a dedicated SP was allocated for EL1. This happens when SPSel holds the value 1 . This is the mode that our kernel is are currently using. EL0_64 Exception is taken from EL0 executing in 64-bit mode. This experiment will not deal with EL0. Spoiler: EL0_64 corresponds to the exceptions that caused by 64-bit user programs. (Note: in the vector table for EL1, this entry is for EL0_64; in the vector table for EL2, this is for EL1_64) EL0_32 Exception is taken from EL0 executing in 32-bit mode. This experiment will not deal with EL0 or 32-bit mode. Spoiler: this corresponds to exceptions in 32-bit user programs. (Note: in the vector table for EL1, this entry is for EL0_32; in the vector table for EL2, this is for EL1_32) \"The t and h suffixes are based on the terminology of thread and handler , introduced in ARMv7-M.\" -- ARM The vector tables for EL2 or EL3? The format is the same as EL1, e.g. 16 (=4x4) exception handlers. See the short official document \" AArch64 exception vector table \". Code Walkthrough Exception vectors, tables, etc. (entry.S) The figure below shows how vector table is defined. The code mimics what the ARM64 Linux kernel does. Why named \"entry.S\"? Because in a full-fledged kernel, exception/irq handlers are where user programs enter the kernel for execution. Although this experiment is not building such a kernel, we follow the naming convention. The vector table consists of 16 ventry definitions: .align 11 .globl vectors vectors: ventry sync_invalid_el1t // Synchronous EL1t ventry irq_invalid_el1t // IRQ EL1t ventry fiq_invalid_el1t // FIQ EL1t ventry error_invalid_el1t // Error EL1t ... The macro ventry is used to create entries in the vector table. .macro ventry label .align 7 b \\label .endm As suggested above: for code clarity, we are not going to handle exceptions right inside the exception vector. Instead, we make each vector a branch instruction ( b \\label ) that jumps to a label provided for the macro as label argument. We need .align 7 because all exception vectors should be spaced at 0x80 bytes (2<<7) one from another. A useful assembly trick. Making CPU aware of the vector table (irq.S) Ok, now we have prepared the vector table, but the processor doesn't know where it is located and therefore can't use it. In order for the exception handling to work, we must set vbar_el1 (Vector Base Address Register) to the vector table address. .globl irq_vector_init irq_vector_init: adr x0, vectors msr vbar_el1, x0 ret A simple handler for unexpected exceptions In this experiment we are only interested in handling IRQ from EL1h . Yet, our kernel defines all 16 handlers for EL1. This is for debugging ease: we want to print out meaningful message in case our kernel triggers some other exceptions due to our programming mistakes. Note again: all these handlers are to be executed at EL1. The exceptions come from either EL0 or EL1. We name all the handlers that are NOT supposed to be trigged with a invalid postfix. We implement these handlers using a handle_invalid_entry macro: .macro handle_invalid_entry type kernel_entry mov x0, #\\type mrs x1, esr_el1 mrs x2, elr_el1 bl show_invalid_entry_message b err_hang .endm The first line invokes a macro kernel_entry which is the first few instructions the kernel should execute in handling an exception/interrupt (recall the term \"entry\"). We will discuss it below. Then we call show_invalid_entry_message() and prepare 3 arguments for it. The arguments are passed in 3 registers: x0, x1, and x2. x0: the exception type. The value comes from the argument to this macro. It can take one of these values defined by our kernel code. It tells us exactly which exception handler has been executed. x1: information about what causes the exception. The value comes from esr_el1 register. ESR stands for Exception Syndrome Register. EL1 implies \"when an exception is taken to EL1\", i.e. when the exception is handled at EL1. Note: in this experiment our kernel runs at EL1 and when an interrupt happens it is handled at EL1. Read the ref again. x2: the address of the instruction being executed when the exception happens. The value comes from the elr_el1 as described earlier. For synchronous exceptions, this is the instruction that causes the exception; for irqs (asynchronous), this is the instruction completed right before irq happens. Again, the postfix EL1 indicates that \" when taking an exception to EL1, (this reg) holds the address to return to. \" The code next invokes show_invalid_entry_message function, which prints textual information to UART. Returning from that function, the code executes in an infinite loop as we have nothing else to do. kernel_entry & exit To handle valid exceptions (timer interrupts in our case), the kernel needs to save & restore the context of the \"normal\" execution, i.e. switching from the normal execution to the exception handler, executing it, and resuming the execution being interrupted. In other words, after the exception handler, we want all general purpose registers to have the same values as they had before the exception was generated. Why does NOT the above handler handle_invalid_entry save registers? Because it ends with an infinite loop and never intends to resume the interrupted execution. el1_irq: kernel_entry bl handle_irq kernel_exit Back to kernel_entry . This is the first thing to do in handling an exception: saving the processor state, notably registers x0 - x30, to the stack. To do so, it first subtracts from sp the size of total stored registers (#S_FRAME_SIZE) and then fills the stack space. According to kernel_entry , there is kernel_exit to be called as the last thing of an exception handler. kernel_exit restores the CPU state by copying back the values of x0 - x30. The order exactly mirrors that of kernel_entry otherwise we will see wrong register values. Finally kernel_exit executes eret , which returns to the normal execution. The following figure shows how the kernel memory look like before & after handling an interrupt. interrupt enable/disable? When an exception happens, the CPU will turn off interrupts automatically. When we return from an interrupt, ERET will restore PSTATE from SPSR_EL1, which contains the DAIF flags that control the interrupt state (i.e. enabled or disabled). Configuring interrupts Configuring the Interrupt controller Bcm2837, the SoC for Rpi3, has its own interrupt controller described on page 109 of BCM2837 ARM Peripherals manual . Because of the hardware quirks (e.g. many irqs are routed from GPU to CPU), the interrupt controller organizes irq sources into three groups and has registers for controlling/checking individual groups. Be aware of their weird naming: these irq groups are called \"Basic\" (irqs routed to the ARM CPU), \"1\", and \"2\" (irqs routed from GPU to CPU). For example, IRQ basic pending , IRQ pending 1 , IRQ pending 2 . The SoC manual has more dirty details. We are only interested in timer interrupts. The SoC manual, page 113 states that irq #1 and #3 are from the system timer. These irq sources belong to the irq group 1, which can be enabled using ENABLE_IRQS_1 . So enable_interrupt_controller() enables system timer IRQ at #1: void enable_interrupt_controller() { put32(ENABLE_IRQS_1, SYSTEM_TIMER_IRQ_1); } Masking/unmasking interrupts From time to time, the kernel must mask/unmask ALL interrupts, so that some critical code regions will never be interrupted. For example, what happens if an interrupt occurs right in the middle of kernel_entry macro? The CPU state would be corrupted. Upon entry to ANY exception/interrupt, the processor automatically masks all interrupts so that the kernel can save the CPU state atomically. The kernel then unmasks exceptions (often interrupts) it wants to handle during the execution of the interrupt handler. Right before exiting the exception handling ( eret ), the kernel masks all interrupts again for atomic CPU state restore. Note: it is perfectly legal to have nested interrupts, i.e. handling another interrupt in the middle of an interrupt handler. Nested interrupts are NOT common: for simple designs, many kernels intentionally keep interrupt handlers very short so they can mask interrupts throughout an interrupt handler without delaying future interrupts too much. However, handling interrupts during exception handlers is VERY common. Syscalls are executed as exception handlers, during which the kernel must be responsive to interrupts. The following two functions (irq.S) mask and unmask interrupts. .globl enable_irq enable_irq: msr daifclr, #2 ret .globl disable_irq disable_irq: msr daifset, #2 ret Explanation: ARM processor state (PSTATE) has 4 bits holding mask status for different types of interrupts. D Masks debug exceptions. These are a special type of synchronous exceptions. For obvious reasons, it is not possible to mask all synchronous exceptions, but it is convenient to have a separate flag that can mask debug exceptions. A Masks SErrors . It is called A because SErrors sometimes are called asynchronous aborts. I Masks IRQs F Masks FIQs Now you can probably guess why registers that are responsible for changing interrupt mask status are called daifclr and daifset . Those registers set and clear interrupt mask status bits in the processor state. Why do we use constant value 2 in both of the functions? This is because we only want to set and clear the second ( I ) bit. The IRQ handler We have a single, common exception handler for handling all IRQs . This handler is defined here . void handle_irq(void) { unsigned int irq = get32(IRQ_PENDING_1); switch (irq) { case (SYSTEM_TIMER_IRQ_1): handle_timer_irq(); break; default: printf(\"Unknown pending irq: %x\\r\\n\", irq); } } In the handler, we need a way to figure out what IO device generated the interrupt. Interrupt controller can help us with this job: it has IRQ_PENDING_1 register that holds interrupt status for interrupts 0 - 31 . Using this register we can check whether the current interrupt was generated by the timer or by some other device and call device specific interrupt handler. Note, multiple interrupts can be pending at the same time. That's why each device specific interrupt handler must acknowledge that it completed handling the interrupt and only after that interrupt pending bit in IRQ_PENDING_1 will be cleared. Because of the same reason, for a production kernel you would probably want to wrap switch construct in the interrupt handler in a loop: in this way, you will be able to handle multiple interrupts during a single handler execution. Arm's generic hardware timer We use the Arm generic timer, which is part of Arm64 core design (i.e. not defined by SoC). This is nice, as the generic timers exist for all Armv8 CPUs. Your experiences will apply to other Armv8 SoCs as well. Arm's official webpage (ARM062-1010708621-30) describes the use of generic timers. The following figure shows the generic timer hardware. In a nutshell, a global, chip-level hardware counter (i.e. \"System Counter\") drives per-core timer instances. As hardware boots, System Counter keeps incrementing, i.e. free running. Software can read the current System Counter. But System Counter alone does not generate interrupts. Software must program the timers so that they interrupt corresponding CPU cores at specific time intervals. Note: PE means CPU cores. As our kernel only deals with one core, we focus on one timer instance. How should the kernel program the timer? The hardware provides two core registers (among others) as two alternative ways for programming the same timer. CVAL, a 64-bit comparator. Roughly, this sets a \"threshold\" for System Counter: Example: The kernel writes a value X to CVAL. When System Counter exceeds X, the timer generates an interrupt. TVAL, a 32-bit signed timer value. Roughly, this sets a \"delta\" for System Counter: Example: The kernel writes a value X to TVAL. The hardware updates CVAL += the Current System Counter + TVAL. The timer generates an interrupt according to the new CVAL. The above brief description would suffice in our kernel experiment. Beyond them, TVAL has another less intuitive, \"countdown\" function (not used in this experiment but useful for timekeeping). Since the last write by software, TVAL decrements as System Counter increments. The moment TVAL counts down to 0 is when an interrupt fires. After that, TVAL will keep counting down to a minus value. To summarize : If software needs a timer event in X ticks of the clock, the software can write X to TVAL periodically. Alternatively, if software wants an event when the system count reaches Y, software can write Y to CVAL. If software wants to know the remaining ticks until the next interrupt, the software reads from TVAL. Initialize timer (timer.S) By programming the timer device, We turn on the timer and allow it to generate interrupts. gen_timer_init: mov x0, #1 msr CNTP_CTL_EL0, x0 ret This writes 1 to the control register ( CNTP_CTL_EL0 ) of the EL1 physical timer . See here for the register definition. How to interpret the register name \"CNTP_CTL_EL0\": CTL indicates this is a control register; CNTP_XXX_EL0 indicates that this is for the EL1 physical timer. Why _EL0? I guess it means that the timer is accessible to both EL1 and EL0. See the table below. Register Purpose <timer>_CTL_EL<x> Control register <timer>_CVAL_EL<x> Comparator value <timer>_TVAL_EL<x> Timer value Timer name Register prefix EL<x> EL1 physical timer CNTP EL0 EL1 virtual time CNTV EL0 Non-secure EL2 physical timer CNTHP EL2 Non-secure EL2 virtual timer CNTHV EL2 EL3 physical timer CNTPS EL1 Secure EL2 physical timer CNTHPS EL2 Secure EL2 virtual timer CNTHVS EL2 (From Arm's generic timer document:) The CNTPCT_EL0 system register reports the current system count value. CNTFRQ_EL0reports the frequency of the system count. However, this register is not populated by hardware. The register is write-able at the highest implemented Exception level and readable at all Exception levels. Firmware, typically running at EL3, populates this register as part of early system initialization. Higher-level software, like an operating system, can then use the register to get the frequency. Turn on timer interrupt at the CPU core We have to deal with yet another Rpi3 quirk. The Arm generic timer IRQs are wired to a per-core interrupt controller/register. For core 0, this is TIMER_INT_CTRL_0 at 0x40000040; bit 1 is for physical timer at EL1 (CNTP). This register is documented in the manual of BCM2836 (search for \"Core timers interrupts\"). Note the manual is NOT for the BCM2837 SoC used by Rpi3. I have no idea how community figured this out. void enable_interrupt_controller() { // Enables Core 0 Timers interrupt control for the generic timer put32(TIMER_INT_CTRL_0, TIMER_INT_CTRL_0_VALUE); } To summarize : we have to program three places in order to receive the timer interrupts: the timer device, the per-core interrupt controller, and the core itself (DAIF). Handing timer interrupts The kernel gets an irq. The kernel check if it comes from the timer; if so, the kernel sets the timer for firing the next interrupt. void handle_irq(void) { // Each Core has its own pending local intrrupts register unsigned int irq = get32(INT_SOURCE_0); switch (irq) { case (GENERIC_TIMER_INTERRUPT): handle_generic_timer_irq(); break; ... The EL1h exception handler invokes the above function. The function reads INT_SOURCE_0 (0x4000:0060), search for \"Core interrupt sources\" in the BCM2836 manual ), where bit 1 is for our CNTP timer. Reset timer (timer.S) The kernel writes a delta value (1<<24) to TVAL, requesting an interrupt to fire after 1<<24 ticks. gen_timer_reset: mov x0, #1 lsl x0, x0, #24 msr CNTP_TVAL_EL0, x0 ret FYI: other timers on Rpi3 There are other timers on Rpi3 which you may see from various online blogs/tutorials/forums. The information can be very confusing. The naming of timers does NOT help. I list them below together with Arm generic timers described above. I suggest you stay away from other timers because the experience will not be as useful. Name Implemented by IRQ QEMU support? (v5.0 ) Phys Addr Document System Timer Broadcom (?) Global. In GPU irq space Implemented as bcm2835_systmr. However free running and cannot generate irq . 3f003000 BCM2837 ARM timer Arm ip (sp804) Global. In Arm core's private irq space (\"Basic irqs\") Unimplemented. See QEMU code bcm2835_peripherals.c 3f00b400 BCM2836 Local timer Broadcom (?) Per core Partially implemented . Can generate trigger irq but readback seems unsupported. 40000034 BCM2836 Arm generic timer Arm, as part of armv8 Per core Implemented 40000040 Armv8 doc + BCM2836 for IRQ routing FYI: Programming the Rpi3's system timer (not used in this experiment) Raspberry Pi system timer is a very simple device. It has a counter that increases its value by 1 after each clock tick. It also has 4 interrupt lines that connect to the interrupt controller (so it can generate 4 different interrupts) and 4 corresponding compare registers. When the value of the counter becomes equal to the value stored in one of the compare registers the corresponding interrupt is fired. That's why, before we will be able to use system timer interrupts, we need to initialize one of the compare registers with a non-zero value, the larger the value is - the later an interrupt will be generated. This is done in timer_init function. const unsigned int interval = 200000; unsigned int curVal = 0; void timer_init ( void ) { curVal = get32(TIMER_CLO); curVal += interval; put32(TIMER_C1, curVal); } The first line reads current counter value, the second line increases it and the third line sets the value of the compare register for the interrupt number 1. By manipulating interval value you can adjust how soon the first timer interrupt will be generated. Finally, we got to the timer interrupt handler. It is actually very simple. void handle_timer_irq( void ) { curVal += interval; put32(TIMER_C1, curVal); put32(TIMER_CS, TIMER_CS_M1); printf(\"Timer iterrupt received\\n\\r\"); } Here we first update compare register so that that next interrupt will be generated after the same time interval. Next, we acknowledge the interrupt by writing 1 to the TIMER_CS register. In the documentation TIMER_CS is called \"Timer Control/Status\" register. Bits [0:3] of this register can be used to acknowledge interrupts coming from one of the 4 available interrupt lines. Hacking tips -- tracing interrupts with QEMU qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img \\ -serial null -serial stdio \\ -d int -D test.log See the qmeu cheatsheet for more. Conclusion The last thing that you might want to take a look at is the kernel_main function where all previously discussed functionality is orchestrated. After you compile and run the sample it should print \"Timer interrupt received\" message after an interrupt is taken. Please, try to do it by yourself and don't forget to carefully examine the code and experiment with it.","title":"exp3"},{"location":"lesson03/rpi-os/#3-interrupts","text":"","title":"3: Interrupts"},{"location":"lesson03/rpi-os/#objectives","text":"Source code location: p1-kernel/src/lesson03 We will build a baremetal program that prints out messages, as driven by periodic interrupts from a hardware timer. You will learn and experience with: Exception/interrupt vectors Handling interrupts Program hardware timers","title":"Objectives"},{"location":"lesson03/rpi-os/#terms","text":"\"Interrupts\" or \"irq\"? We use these two terms interchangeably. Many kernel documents use the latter.","title":"Terms"},{"location":"lesson03/rpi-os/#background-interrupts-exceptions-in-arm64","text":"","title":"Background: interrupts &amp; exceptions in ARM64"},{"location":"lesson03/rpi-os/#interrupts","text":"Interrupts are generated by IO devices, go through the irq controller, and eventually arrive the CPU. The CPU can program the irq controller to enable/disable specific interrupt sources. By disabling an irq source, the CPU will not lose any irq from that device, but just defer receiving irq until the CPU re-enables the irq source. The CPU can also read from the irq controller which IO devices have pending interrupts, meaning that the IO devices need attention. By their canonical definitions, interrupts are asynchronous while exceptions are synchronous.","title":"Interrupts"},{"location":"lesson03/rpi-os/#interrupts-exceptions-on-aarch64","text":"However in ARM64 lingo, exception is broadly defined; interrupts are a special kind of exceptions. x86 has its own lingo, calling exceptions as \"traps\". In this article, we use ARM's broad definition of exceptions unless stated otherwise.","title":"Interrupts &amp; Exceptions on aarch64"},{"location":"lesson03/rpi-os/#exception-vectors","text":"Figure above: the EL1 vector table as in memory. Note that EL2 and EL3 each has a vector table like this An exception vector (or handler) is a piece of code the CPU will execute when a specific exception happens. \" These would normally be branch instructions that direct the core to the full exception handler. \" (the ARM64 manual). The ARM64 hardware mandates: each exception vector can occupy 0x80 bytes maximum (thus .align 7 in the asm code). In some other architectures an exception vector could be an address to jump to. Note the subtle difference. A vector table is an array of exception vectors. Each exception level (EL) has its own vector table. The vector table for EL1 . Provided by our kernel. Purpose: to handle exceptions taken from EL0 (user programs) or EL1 (the kernel's own execution) to EL1. Format: the kernel define 16 exception handlers : 4 types [SError, fiq, irq, sync] X CPU 4 execution states [EL1t, EL1h, EL0_64, EL0_32]. Four exception types (focus the former two) Synchronous exception s Exceptions of this type are always caused by the currently executed instruction. For example, you can use str instruction to store some data at a non-existing memory location. In this case, a synchronous exception is generated. Synchronous exceptions also can be used to generate a \"software interrupt\". Software interrupt is a synchronous exception that is generated on purpose by svc instruction. We will use this technique in lesson 5 to implement system calls. Asynchronous exceptions (IRQ) Those are normal interrupts. They are always asynchronous, which means that they have nothing to do with the currently executed instruction. In contrast to synchronous exceptions, they are always not generated by the processor itself, but by external hardware. FIQ (Fast Interrupt Request) This type of exception is called \"fast interrupts\" and exist solely for the purpose of prioritizing exceptions. It is possible to configure some interrupts as \"normal\" and other as \"fast\". Fast interrupts will be signaled first and will be handled by a separate exception handler. Linux doesn't use fast interrupts and we also are not going to do so. SError (System Error) Like IRQ and FIQ , SError exceptions are asynchronous and are generated by external hardware. Unlike IRQ and FIQ , SError always indicates some error condition. Here you can find an example explaining when SError can be generated. Four CPU execution states EL1t Exception happens when CPU is at EL1 while the stack pointer (SP) was set to be shared with EL0. This happens when SPSel register holds the value 0 . Recall that SPSel is part of the CPU's PSTATE. EL1h Exception happens at EL1 at the time when a dedicated SP was allocated for EL1. This happens when SPSel holds the value 1 . This is the mode that our kernel is are currently using. EL0_64 Exception is taken from EL0 executing in 64-bit mode. This experiment will not deal with EL0. Spoiler: EL0_64 corresponds to the exceptions that caused by 64-bit user programs. (Note: in the vector table for EL1, this entry is for EL0_64; in the vector table for EL2, this is for EL1_64) EL0_32 Exception is taken from EL0 executing in 32-bit mode. This experiment will not deal with EL0 or 32-bit mode. Spoiler: this corresponds to exceptions in 32-bit user programs. (Note: in the vector table for EL1, this entry is for EL0_32; in the vector table for EL2, this is for EL1_32) \"The t and h suffixes are based on the terminology of thread and handler , introduced in ARMv7-M.\" -- ARM The vector tables for EL2 or EL3? The format is the same as EL1, e.g. 16 (=4x4) exception handlers. See the short official document \" AArch64 exception vector table \".","title":"Exception vectors"},{"location":"lesson03/rpi-os/#code-walkthrough","text":"","title":"Code Walkthrough"},{"location":"lesson03/rpi-os/#exception-vectors-tables-etc-entrys","text":"The figure below shows how vector table is defined. The code mimics what the ARM64 Linux kernel does. Why named \"entry.S\"? Because in a full-fledged kernel, exception/irq handlers are where user programs enter the kernel for execution. Although this experiment is not building such a kernel, we follow the naming convention. The vector table consists of 16 ventry definitions: .align 11 .globl vectors vectors: ventry sync_invalid_el1t // Synchronous EL1t ventry irq_invalid_el1t // IRQ EL1t ventry fiq_invalid_el1t // FIQ EL1t ventry error_invalid_el1t // Error EL1t ... The macro ventry is used to create entries in the vector table. .macro ventry label .align 7 b \\label .endm As suggested above: for code clarity, we are not going to handle exceptions right inside the exception vector. Instead, we make each vector a branch instruction ( b \\label ) that jumps to a label provided for the macro as label argument. We need .align 7 because all exception vectors should be spaced at 0x80 bytes (2<<7) one from another. A useful assembly trick.","title":"Exception vectors, tables, etc. (entry.S)"},{"location":"lesson03/rpi-os/#making-cpu-aware-of-the-vector-table-irqs","text":"Ok, now we have prepared the vector table, but the processor doesn't know where it is located and therefore can't use it. In order for the exception handling to work, we must set vbar_el1 (Vector Base Address Register) to the vector table address. .globl irq_vector_init irq_vector_init: adr x0, vectors msr vbar_el1, x0 ret","title":"Making CPU aware of the vector table (irq.S)"},{"location":"lesson03/rpi-os/#a-simple-handler-for-unexpected-exceptions","text":"In this experiment we are only interested in handling IRQ from EL1h . Yet, our kernel defines all 16 handlers for EL1. This is for debugging ease: we want to print out meaningful message in case our kernel triggers some other exceptions due to our programming mistakes. Note again: all these handlers are to be executed at EL1. The exceptions come from either EL0 or EL1. We name all the handlers that are NOT supposed to be trigged with a invalid postfix. We implement these handlers using a handle_invalid_entry macro: .macro handle_invalid_entry type kernel_entry mov x0, #\\type mrs x1, esr_el1 mrs x2, elr_el1 bl show_invalid_entry_message b err_hang .endm The first line invokes a macro kernel_entry which is the first few instructions the kernel should execute in handling an exception/interrupt (recall the term \"entry\"). We will discuss it below. Then we call show_invalid_entry_message() and prepare 3 arguments for it. The arguments are passed in 3 registers: x0, x1, and x2. x0: the exception type. The value comes from the argument to this macro. It can take one of these values defined by our kernel code. It tells us exactly which exception handler has been executed. x1: information about what causes the exception. The value comes from esr_el1 register. ESR stands for Exception Syndrome Register. EL1 implies \"when an exception is taken to EL1\", i.e. when the exception is handled at EL1. Note: in this experiment our kernel runs at EL1 and when an interrupt happens it is handled at EL1. Read the ref again. x2: the address of the instruction being executed when the exception happens. The value comes from the elr_el1 as described earlier. For synchronous exceptions, this is the instruction that causes the exception; for irqs (asynchronous), this is the instruction completed right before irq happens. Again, the postfix EL1 indicates that \" when taking an exception to EL1, (this reg) holds the address to return to. \" The code next invokes show_invalid_entry_message function, which prints textual information to UART. Returning from that function, the code executes in an infinite loop as we have nothing else to do.","title":"A simple handler for unexpected exceptions"},{"location":"lesson03/rpi-os/#kernel_entry-exit","text":"To handle valid exceptions (timer interrupts in our case), the kernel needs to save & restore the context of the \"normal\" execution, i.e. switching from the normal execution to the exception handler, executing it, and resuming the execution being interrupted. In other words, after the exception handler, we want all general purpose registers to have the same values as they had before the exception was generated. Why does NOT the above handler handle_invalid_entry save registers? Because it ends with an infinite loop and never intends to resume the interrupted execution. el1_irq: kernel_entry bl handle_irq kernel_exit Back to kernel_entry . This is the first thing to do in handling an exception: saving the processor state, notably registers x0 - x30, to the stack. To do so, it first subtracts from sp the size of total stored registers (#S_FRAME_SIZE) and then fills the stack space. According to kernel_entry , there is kernel_exit to be called as the last thing of an exception handler. kernel_exit restores the CPU state by copying back the values of x0 - x30. The order exactly mirrors that of kernel_entry otherwise we will see wrong register values. Finally kernel_exit executes eret , which returns to the normal execution. The following figure shows how the kernel memory look like before & after handling an interrupt.","title":"kernel_entry &amp; exit"},{"location":"lesson03/rpi-os/#interrupt-enabledisable","text":"When an exception happens, the CPU will turn off interrupts automatically. When we return from an interrupt, ERET will restore PSTATE from SPSR_EL1, which contains the DAIF flags that control the interrupt state (i.e. enabled or disabled).","title":"interrupt enable/disable?"},{"location":"lesson03/rpi-os/#configuring-interrupts","text":"","title":"Configuring interrupts"},{"location":"lesson03/rpi-os/#_1","text":"","title":""},{"location":"lesson03/rpi-os/#configuring-the-interrupt-controller","text":"Bcm2837, the SoC for Rpi3, has its own interrupt controller described on page 109 of BCM2837 ARM Peripherals manual . Because of the hardware quirks (e.g. many irqs are routed from GPU to CPU), the interrupt controller organizes irq sources into three groups and has registers for controlling/checking individual groups. Be aware of their weird naming: these irq groups are called \"Basic\" (irqs routed to the ARM CPU), \"1\", and \"2\" (irqs routed from GPU to CPU). For example, IRQ basic pending , IRQ pending 1 , IRQ pending 2 . The SoC manual has more dirty details. We are only interested in timer interrupts. The SoC manual, page 113 states that irq #1 and #3 are from the system timer. These irq sources belong to the irq group 1, which can be enabled using ENABLE_IRQS_1 . So enable_interrupt_controller() enables system timer IRQ at #1: void enable_interrupt_controller() { put32(ENABLE_IRQS_1, SYSTEM_TIMER_IRQ_1); }","title":"Configuring the Interrupt controller"},{"location":"lesson03/rpi-os/#maskingunmasking-interrupts","text":"From time to time, the kernel must mask/unmask ALL interrupts, so that some critical code regions will never be interrupted. For example, what happens if an interrupt occurs right in the middle of kernel_entry macro? The CPU state would be corrupted. Upon entry to ANY exception/interrupt, the processor automatically masks all interrupts so that the kernel can save the CPU state atomically. The kernel then unmasks exceptions (often interrupts) it wants to handle during the execution of the interrupt handler. Right before exiting the exception handling ( eret ), the kernel masks all interrupts again for atomic CPU state restore. Note: it is perfectly legal to have nested interrupts, i.e. handling another interrupt in the middle of an interrupt handler. Nested interrupts are NOT common: for simple designs, many kernels intentionally keep interrupt handlers very short so they can mask interrupts throughout an interrupt handler without delaying future interrupts too much. However, handling interrupts during exception handlers is VERY common. Syscalls are executed as exception handlers, during which the kernel must be responsive to interrupts. The following two functions (irq.S) mask and unmask interrupts. .globl enable_irq enable_irq: msr daifclr, #2 ret .globl disable_irq disable_irq: msr daifset, #2 ret Explanation: ARM processor state (PSTATE) has 4 bits holding mask status for different types of interrupts. D Masks debug exceptions. These are a special type of synchronous exceptions. For obvious reasons, it is not possible to mask all synchronous exceptions, but it is convenient to have a separate flag that can mask debug exceptions. A Masks SErrors . It is called A because SErrors sometimes are called asynchronous aborts. I Masks IRQs F Masks FIQs Now you can probably guess why registers that are responsible for changing interrupt mask status are called daifclr and daifset . Those registers set and clear interrupt mask status bits in the processor state. Why do we use constant value 2 in both of the functions? This is because we only want to set and clear the second ( I ) bit.","title":"Masking/unmasking interrupts"},{"location":"lesson03/rpi-os/#the-irq-handler","text":"We have a single, common exception handler for handling all IRQs . This handler is defined here . void handle_irq(void) { unsigned int irq = get32(IRQ_PENDING_1); switch (irq) { case (SYSTEM_TIMER_IRQ_1): handle_timer_irq(); break; default: printf(\"Unknown pending irq: %x\\r\\n\", irq); } } In the handler, we need a way to figure out what IO device generated the interrupt. Interrupt controller can help us with this job: it has IRQ_PENDING_1 register that holds interrupt status for interrupts 0 - 31 . Using this register we can check whether the current interrupt was generated by the timer or by some other device and call device specific interrupt handler. Note, multiple interrupts can be pending at the same time. That's why each device specific interrupt handler must acknowledge that it completed handling the interrupt and only after that interrupt pending bit in IRQ_PENDING_1 will be cleared. Because of the same reason, for a production kernel you would probably want to wrap switch construct in the interrupt handler in a loop: in this way, you will be able to handle multiple interrupts during a single handler execution.","title":"The IRQ handler"},{"location":"lesson03/rpi-os/#arms-generic-hardware-timer","text":"We use the Arm generic timer, which is part of Arm64 core design (i.e. not defined by SoC). This is nice, as the generic timers exist for all Armv8 CPUs. Your experiences will apply to other Armv8 SoCs as well. Arm's official webpage (ARM062-1010708621-30) describes the use of generic timers. The following figure shows the generic timer hardware. In a nutshell, a global, chip-level hardware counter (i.e. \"System Counter\") drives per-core timer instances. As hardware boots, System Counter keeps incrementing, i.e. free running. Software can read the current System Counter. But System Counter alone does not generate interrupts. Software must program the timers so that they interrupt corresponding CPU cores at specific time intervals. Note: PE means CPU cores. As our kernel only deals with one core, we focus on one timer instance. How should the kernel program the timer? The hardware provides two core registers (among others) as two alternative ways for programming the same timer. CVAL, a 64-bit comparator. Roughly, this sets a \"threshold\" for System Counter: Example: The kernel writes a value X to CVAL. When System Counter exceeds X, the timer generates an interrupt. TVAL, a 32-bit signed timer value. Roughly, this sets a \"delta\" for System Counter: Example: The kernel writes a value X to TVAL. The hardware updates CVAL += the Current System Counter + TVAL. The timer generates an interrupt according to the new CVAL. The above brief description would suffice in our kernel experiment. Beyond them, TVAL has another less intuitive, \"countdown\" function (not used in this experiment but useful for timekeeping). Since the last write by software, TVAL decrements as System Counter increments. The moment TVAL counts down to 0 is when an interrupt fires. After that, TVAL will keep counting down to a minus value. To summarize : If software needs a timer event in X ticks of the clock, the software can write X to TVAL periodically. Alternatively, if software wants an event when the system count reaches Y, software can write Y to CVAL. If software wants to know the remaining ticks until the next interrupt, the software reads from TVAL.","title":"Arm's generic hardware timer"},{"location":"lesson03/rpi-os/#initialize-timer-timers","text":"By programming the timer device, We turn on the timer and allow it to generate interrupts. gen_timer_init: mov x0, #1 msr CNTP_CTL_EL0, x0 ret This writes 1 to the control register ( CNTP_CTL_EL0 ) of the EL1 physical timer . See here for the register definition. How to interpret the register name \"CNTP_CTL_EL0\": CTL indicates this is a control register; CNTP_XXX_EL0 indicates that this is for the EL1 physical timer. Why _EL0? I guess it means that the timer is accessible to both EL1 and EL0. See the table below. Register Purpose <timer>_CTL_EL<x> Control register <timer>_CVAL_EL<x> Comparator value <timer>_TVAL_EL<x> Timer value Timer name Register prefix EL<x> EL1 physical timer CNTP EL0 EL1 virtual time CNTV EL0 Non-secure EL2 physical timer CNTHP EL2 Non-secure EL2 virtual timer CNTHV EL2 EL3 physical timer CNTPS EL1 Secure EL2 physical timer CNTHPS EL2 Secure EL2 virtual timer CNTHVS EL2 (From Arm's generic timer document:) The CNTPCT_EL0 system register reports the current system count value. CNTFRQ_EL0reports the frequency of the system count. However, this register is not populated by hardware. The register is write-able at the highest implemented Exception level and readable at all Exception levels. Firmware, typically running at EL3, populates this register as part of early system initialization. Higher-level software, like an operating system, can then use the register to get the frequency.","title":"Initialize timer (timer.S)"},{"location":"lesson03/rpi-os/#turn-on-timer-interrupt-at-the-cpu-core","text":"We have to deal with yet another Rpi3 quirk. The Arm generic timer IRQs are wired to a per-core interrupt controller/register. For core 0, this is TIMER_INT_CTRL_0 at 0x40000040; bit 1 is for physical timer at EL1 (CNTP). This register is documented in the manual of BCM2836 (search for \"Core timers interrupts\"). Note the manual is NOT for the BCM2837 SoC used by Rpi3. I have no idea how community figured this out. void enable_interrupt_controller() { // Enables Core 0 Timers interrupt control for the generic timer put32(TIMER_INT_CTRL_0, TIMER_INT_CTRL_0_VALUE); } To summarize : we have to program three places in order to receive the timer interrupts: the timer device, the per-core interrupt controller, and the core itself (DAIF).","title":"Turn on timer interrupt at the CPU core"},{"location":"lesson03/rpi-os/#handing-timer-interrupts","text":"The kernel gets an irq. The kernel check if it comes from the timer; if so, the kernel sets the timer for firing the next interrupt. void handle_irq(void) { // Each Core has its own pending local intrrupts register unsigned int irq = get32(INT_SOURCE_0); switch (irq) { case (GENERIC_TIMER_INTERRUPT): handle_generic_timer_irq(); break; ... The EL1h exception handler invokes the above function. The function reads INT_SOURCE_0 (0x4000:0060), search for \"Core interrupt sources\" in the BCM2836 manual ), where bit 1 is for our CNTP timer.","title":"Handing timer interrupts"},{"location":"lesson03/rpi-os/#reset-timer-timers","text":"The kernel writes a delta value (1<<24) to TVAL, requesting an interrupt to fire after 1<<24 ticks. gen_timer_reset: mov x0, #1 lsl x0, x0, #24 msr CNTP_TVAL_EL0, x0 ret","title":"Reset timer (timer.S)"},{"location":"lesson03/rpi-os/#fyi-other-timers-on-rpi3","text":"There are other timers on Rpi3 which you may see from various online blogs/tutorials/forums. The information can be very confusing. The naming of timers does NOT help. I list them below together with Arm generic timers described above. I suggest you stay away from other timers because the experience will not be as useful. Name Implemented by IRQ QEMU support? (v5.0 ) Phys Addr Document System Timer Broadcom (?) Global. In GPU irq space Implemented as bcm2835_systmr. However free running and cannot generate irq . 3f003000 BCM2837 ARM timer Arm ip (sp804) Global. In Arm core's private irq space (\"Basic irqs\") Unimplemented. See QEMU code bcm2835_peripherals.c 3f00b400 BCM2836 Local timer Broadcom (?) Per core Partially implemented . Can generate trigger irq but readback seems unsupported. 40000034 BCM2836 Arm generic timer Arm, as part of armv8 Per core Implemented 40000040 Armv8 doc + BCM2836 for IRQ routing","title":"FYI: other timers on Rpi3"},{"location":"lesson03/rpi-os/#fyi-programming-the-rpi3s-system-timer-not-used-in-this-experiment","text":"Raspberry Pi system timer is a very simple device. It has a counter that increases its value by 1 after each clock tick. It also has 4 interrupt lines that connect to the interrupt controller (so it can generate 4 different interrupts) and 4 corresponding compare registers. When the value of the counter becomes equal to the value stored in one of the compare registers the corresponding interrupt is fired. That's why, before we will be able to use system timer interrupts, we need to initialize one of the compare registers with a non-zero value, the larger the value is - the later an interrupt will be generated. This is done in timer_init function. const unsigned int interval = 200000; unsigned int curVal = 0; void timer_init ( void ) { curVal = get32(TIMER_CLO); curVal += interval; put32(TIMER_C1, curVal); } The first line reads current counter value, the second line increases it and the third line sets the value of the compare register for the interrupt number 1. By manipulating interval value you can adjust how soon the first timer interrupt will be generated. Finally, we got to the timer interrupt handler. It is actually very simple. void handle_timer_irq( void ) { curVal += interval; put32(TIMER_C1, curVal); put32(TIMER_CS, TIMER_CS_M1); printf(\"Timer iterrupt received\\n\\r\"); } Here we first update compare register so that that next interrupt will be generated after the same time interval. Next, we acknowledge the interrupt by writing 1 to the TIMER_CS register. In the documentation TIMER_CS is called \"Timer Control/Status\" register. Bits [0:3] of this register can be used to acknowledge interrupts coming from one of the 4 available interrupt lines.","title":"FYI: Programming the Rpi3's system timer (not used in this experiment)"},{"location":"lesson03/rpi-os/#hacking-tips-tracing-interrupts-with-qemu","text":"qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img \\ -serial null -serial stdio \\ -d int -D test.log See the qmeu cheatsheet for more.","title":"Hacking tips -- tracing interrupts with QEMU"},{"location":"lesson03/rpi-os/#conclusion","text":"The last thing that you might want to take a look at is the kernel_main function where all previously discussed functionality is orchestrated. After you compile and run the sample it should print \"Timer interrupt received\" message after an interrupt is taken. Please, try to do it by yourself and don't forget to carefully examine the code and experiment with it.","title":"Conclusion"},{"location":"lesson04a/rpi-os/","text":"4a: Cooperative Multitasking Results with UART output: Source code location: p1-kernel/src/lesson04a Overview From this experiment onward, our kernel starts to schedule multiple tasks. This makes it a true \"kernel\" instead of a baremetal program. This experiment focuses on scheduling and task switch. Tasks must voluntarily yield to each other. We defer interrupt handling to upcoming experiment. We will intentionally leave out interrupts, i.e. timer interrupts are left OFF . Roadmap. We will implement: The task_struct data structure Task creation by manipulating task_struct , registers, and stack Minimalist memory allocation Minimalist task scheduling Processes or tasks? . As we do not have virtual memory yet, we use the term \"tasks\" instead of \"processes\". Note: in Linux both thread and processes are just different types of tasks; the difference is in how they share address spaces. Key data structures Figure above: an array of pointers to task_structs of tasks task_struct A struct describing a task. Its name comes from the Linux kernel (again). The code is as follows ( sched.h ). struct cpu_context { unsigned long x19; unsigned long x20; unsigned long x21; unsigned long x22; unsigned long x23; unsigned long x24; unsigned long x25; unsigned long x26; unsigned long x27; unsigned long x28; unsigned long fp; unsigned long sp; unsigned long pc; }; struct task_struct { struct cpu_context cpu_context; long state; long counter; long priority; long preempt_count; }; This struct has the following members: cpu_context This is a struct that contains values of all registers that might be different between the tasks. Why don't we save all registers, but only x19 - x30 and sp ? ( fp is x29 and pc is x30 ). A short answer: to cater to the Armv8 calling convention. Because task switch happens only when a task calls cpu_switch_to function. From the point of view of the task that is being scheduled out (i.e. the \"switched-from\" task), it just calls cpu_switch_to function and it returns after some (potentially long) time. The \"switched from\" task is unaware of that another task (i.e. the \"switched-to\" task) happens to runs during this period. Accordingly to ARM calling conventions registers x0 - x18 can be overwritten by the callee (i.e. cpu_switch_to() in our case). Hence, the kernel doesn't have to save the contents of x0 - x18 for the caller (the \"switched-from\" task). state The state of the currently running task (NOT PSTATE -- an orthogonal concept). For a task just doing CPU work but not IO, the task state will always be TASK_RUNNING . For now, this is the only state supported by our kernel. Later we add a few additional states. For example, a task waiting for an interrupt should be in a different state, because it doesn't make sense to schedule the task when it is not ready to run yet. counter is used to determine how long the current task has been running. counter decreases by 1 each timer tick. When it reaches 0, the kernel will attempt to schedule another task. This supports our simple scheduling algorithm. priority When the kernel schedules a new task, the kernel copies the task's priority value counter . In this way, the kernel can regulate the amount of processor time the task gets relative to other tasks. preempt_count A flag. A non-zero value means that the current task is executing in a critical code region that cannot be interrupted, e.g. by switching to another task. Any timer tick should be ignored and not triggering rescheduling. After the kernel startup, there is only one task running: the one that runs kernel_main(). It is called \"init task\". Before the scheduler is enabled, we must fill task_struct of the init task. This is done in INIT_TASK . All task_struct s are stored in task (sched.c) array. This array has only 64 slots - that is the maximum number of simultaneous tasks the kernel can have. It won't suit a production OS, but it is ok for our goals. An important global variable is current (sched.c) that always points to task_struct of currently executing task. Both current and task array are initially set to hold a pointer to the init task. There is also a global variable nr_task - it contains the number of currently running tasks in the system. Task switch Preparing task_structs (kernel.c) void kernel_main(void) { uart_init(); init_printf(0, putc); irq_vector_init(); int res = copy_process((unsigned long)&process, (unsigned long)\"12345\"); if (res != 0) { printf(\"error while starting process 1\"); return; } res = copy_process((unsigned long)&process, (unsigned long)\"abcde\"); if (res != 0) { printf(\"error while starting process 2\"); return; } while (1){ schedule(); } } A new function copy_process is introduced. copy_process takes 2 arguments: a function to execute in a new thread and an argument passed to this function. copy_process allocates a new task_struct and makes it available for the scheduler. Another new function schedule . This is the core scheduler function: it checks whether there is a new task that needs to preempt the current one. In cooperative scheduling, a task voluntarily calls schedule if it doesn't have any work to do at the moment. For preemptive multitasking, schedule is also called from the timer interrupt handler. Try your self with QEMU: set a breakpoint at copy_process & launch the kernel. Examine task_struct with print *p . Examine the value of cpu_context.[pc|sp|fn|arg]. We are calling copy_process 2 times, each time passing a pointer to the process function as the first argument. process function is very simple. void process(char *array) { while (1){ for (int i = 0; i < 5; i++){ uart_send(array[i]); delay(100000); schedule(); } } } It just keeps printing characters from the array, which is passed as an argument. Task 1 is created with the argument \"12345\" and task 2 is with the argument \"abcde\". After printing out a string, a task yields to others by calling schedule() . If our scheduler implementation is correct, both threads will take turns to print strings. Switching tasks (sched.c & sched.S) This is where the magic happens. The code looks like this. void switch_to(struct task_struct * next) { if (current == next) return; struct task_struct * prev = current; current = next; cpu_switch_to(prev, next); } If the \"next\" process is not the same as the \"current\", the kernel updates current . The cpu_switch_to function is where the real context switch happens. To manipulates registers, it is in assembly. .globl cpu_switch_to cpu_switch_to: mov x10, #THREAD_CPU_CONTEXT add x8, x0, x10 mov x9, sp stp x19, x20, [x8], #16 // store callee-saved registers stp x21, x22, [x8], #16 stp x23, x24, [x8], #16 stp x25, x26, [x8], #16 stp x27, x28, [x8], #16 stp x29, x9, [x8], #16 str x30, [x8] add x8, x1, x10 ldp x19, x20, [x8], #16 // restore callee-saved registers ldp x21, x22, [x8], #16 ldp x23, x24, [x8], #16 ldp x25, x26, [x8], #16 ldp x27, x28, [x8], #16 ldp x29, x9, [x8], #16 ldr x30, [x8] mov sp, x9 ret Let's examine it line by line. mov x10, #THREAD_CPU_CONTEXT add x8, x0, x10 THREAD_CPU_CONTEXT constant contains offset of the cpu_context structure in the task_struct (the offset is 0 in the current implementation). x0 contains a pointer to the first argument, which is the current task_struct (i.e. the \"switch-from\" task). After the copied 2 lines are executed, x8 will contain a pointer to the current cpu_context . mov x9, sp stp x19, x20, [x8], #16 // store callee-saved registers stp x21, x22, [x8], #16 stp x23, x24, [x8], #16 stp x25, x26, [x8], #16 stp x27, x28, [x8], #16 stp x29, x9, [x8], #16 str x30, [x8] The figure above: During context switch, registers are being saved to task_struct.context Next all callee-saved registers are stored in the order, in which they are defined in cpu_context structure. The current stack pointer is saved as cpu_context.sp and x29 is saved as cpu_context.fp (frame pointer). Note: x30 , the link register containing function return address, is stored as cpu_context.pc . Why? Now we calculate the address of the next task's cpu_context : add x8, x1, x10 This a cute hack. x10 contains THREAD_CPU_CONTEXT , the offset of the cpu_context structure inside task_struct . x1 is a pointer to the next task_struct , so x8 will contain a pointer to the next cpu_context . Now, restore the CPU context of \"switch_to\" task from memory to CPU regs. A mirror procedure. ldp x19, x20, [x8], #16 // restore callee-saved registers ldp x21, x22, [x8], #16 ldp x23, x24, [x8], #16 ldp x25, x26, [x8], #16 ldp x27, x28, [x8], #16 ldp x29, x9, [x8], #16 ldr x30, [x8] mov sp, x9 ret The ret instruction will jump to the location pointed to by the link register ( x30 ). If we are switching to a task for the first time, this will be the beginning of the ret_from_fork function. More on that below. In all other cases this will be the location previously saved in the cpu_context.pc by the cpu_switch_to function. Think: which instruction does it point to? Launching a new task New task creation is implemented in the copy_process function. Keep in mind: after copy_process finishes execution, no context switch happens yet. The function only prepares new task_struct and adds it to the task array \u2014 this task will be executed only after schedule function is called. int copy_process(unsigned long fn, unsigned long arg) { struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) return 1; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)p + THREAD_SIZE; int pid = nr_tasks++; task[pid] = p; return 0; } We examine it in details. struct task_struct *p; The function starts with allocating a pointer for the new task. As interrupts are off, the kernel will not be interrupted in the middle of the copy_process function. p = (struct task_struct *) get_free_page(); if (!p) return 1; Next, a new page is allocated. At the bottom of this page, we are putting the task_struct for the newly created task. The rest of this page will be used as the task stack. A few lines below, context.sp is set as p + THREAD_SIZE . THREAD_SIZE is defined as 4KB. It is the total amount of kernel memory for a task. The name, again, is following the Linux kernel convention. Figure above: a task's task_struct in relative to its stack space p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; After the task_struct is allocated, we can initialize its properties. Priority and initial counters are set based on the current task priority. p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)p + THREAD_SIZE; This is the most important part of the function. Here cpu_context is initialized. The stack pointer is set to the top of the newly allocated memory page (see the figure above). pc is set to the ret_from_fork function. Details below. ret_from_fork (entry.S) This is the first piece of code executed by a newly created process. A new process P executes ret_from_fork after it is switched to for the first time. That is right after the scheduler picks P for the first time and restores P's CPU context from task_struct to CPU registers. Throughout its lifetime, P only executes ret_from_fork once. About naming: despite the name \"fork\", we are not doing fork() as in Linux/Unix. We are simply copying a task_struct while fork() does far more things like duplicating process address spaces. The naming follows the Linux kernel convention; and we will evolve our ret_from_fork in subsequent experiments. .globl ret_from_fork ret_from_fork: bl schedule_tail // will talk about this later mov x0, x20 blr x19 //should never return What are the initial values of x19 and x20 ? See code copy_process above, which saves fn (the process's main function) and arg (the argument passed to the process) to task_struct.x19 and x20 . When switching to P, the kernel restores fn and arg from task_struct to x19 and x20 . And here we are: ret_from_fork calls the function stored in x19 register with the argument stored in x20 . :wrench:Try your self with QEMU+GDB: set a breakpoint at ret_from_fork, launch the kernel, and single step into the new process function. Memory allocation Each task in the system should have its dedicated stack. That's why when creating a new task we must have a way to allocate memory. For now, our memory allocator is extremely primitive. (The implementation can be found in mm.c file) static unsigned short mem_map [ PAGING_PAGES ] = {0,}; unsigned long get_free_page() { for (int i = 0; i < PAGING_PAGES; i++){ if (mem_map[i] == 0){ mem_map[i] = 1; return LOW_MEMORY + i*PAGE_SIZE; } } return 0; } void free_page(unsigned long p){ mem_map[(p - LOW_MEMORY) / PAGE_SIZE] = 0; } :wrench: Try it yourself with QEMU: ptype mem_map then print (short[10])*mem_map . The allocator can work only with memory pages (each page is 4 KB in size). There is an array called mem_map that for each page in the system holds its status: whether it is allocated or free. Whenever we need to allocate a new page, we just loop through this array and return the first free page. This implementation is based on 2 assumptions: We know the total amount of memory in the system. It is 1 GB - 1 MB (the last megabyte of memory is reserved for device registers.). This value is stored in the HIGH_MEMORY constant. First 4 MB of memory are reserved for the kernel image and init task stack. This value is stored in the LOW_MEMORY constant. All memory allocations start right after this point. Note: even with QEMU our kernel must start from 0x80000 (512KB), the above assumptions are good as there's still plenty room in 512KB -- LOW_MEMORY for our tiny kernel. The scheduler Finally, we are ready to look at the scheduler algorithm. We almost precisely copied this algorithm from the first release of the Linux kernel. void _schedule(void) { int next,c; struct task_struct * p; while (1) { c = -1; next = 0; // try to pick a task for (int i = 0; i < NR_TASKS; i++){ p = task[i]; if (p && p->state == TASK_RUNNING && p->counter > c) { c = p->counter; next = i; } } if (c) { break; } // update counters for (int i = 0; i < NR_TASKS; i++) { p = task[i]; if (p) { p->counter = (p->counter >> 1) + p->priority; } } } switch_to(task[next]); } The simple algorithm works like the following: The first for loop iterates over all tasks and tries to find a task in TASK_RUNNING state with the maximum counter. If such a task is found, we immediately break from the while loop and switch to this task. If no such task is found, this is either because i) no task is in TASK_RUNNING state or ii) all such tasks have 0 counters. In a real OS, i) might happen, for example, when all tasks are waiting for an interrupt. In our current tiny kernel, all tasks are always in TASK_RUNNING (Why?) The scheduler moves to the 2nd for loop to \"recharge\" counters. It bumps counters for all tasks once. The increment depends on a task's priority. Note: a task counter can never get larger than 2 * priority . With updated counters, the scheduler goes back to the 1st for loop to pick a task. We will augment the scheduling algorithm for preemptive multitasking later. Conclusion We have seen important nuts & bolts of multitasking. The subsequent experiment will enable task preemption. We will show a detailed workflow of context switch there. One more thing ... There's support for a graphical console. Works for both QEMU and Rpi3. Display required. See instructions .","title":"exp4a"},{"location":"lesson04a/rpi-os/#4a-cooperative-multitasking","text":"Results with UART output: Source code location: p1-kernel/src/lesson04a","title":"4a: Cooperative Multitasking"},{"location":"lesson04a/rpi-os/#overview","text":"From this experiment onward, our kernel starts to schedule multiple tasks. This makes it a true \"kernel\" instead of a baremetal program. This experiment focuses on scheduling and task switch. Tasks must voluntarily yield to each other. We defer interrupt handling to upcoming experiment. We will intentionally leave out interrupts, i.e. timer interrupts are left OFF . Roadmap. We will implement: The task_struct data structure Task creation by manipulating task_struct , registers, and stack Minimalist memory allocation Minimalist task scheduling Processes or tasks? . As we do not have virtual memory yet, we use the term \"tasks\" instead of \"processes\". Note: in Linux both thread and processes are just different types of tasks; the difference is in how they share address spaces.","title":"Overview"},{"location":"lesson04a/rpi-os/#key-data-structures","text":"Figure above: an array of pointers to task_structs of tasks","title":"Key data structures"},{"location":"lesson04a/rpi-os/#task_struct","text":"A struct describing a task. Its name comes from the Linux kernel (again). The code is as follows ( sched.h ). struct cpu_context { unsigned long x19; unsigned long x20; unsigned long x21; unsigned long x22; unsigned long x23; unsigned long x24; unsigned long x25; unsigned long x26; unsigned long x27; unsigned long x28; unsigned long fp; unsigned long sp; unsigned long pc; }; struct task_struct { struct cpu_context cpu_context; long state; long counter; long priority; long preempt_count; }; This struct has the following members: cpu_context This is a struct that contains values of all registers that might be different between the tasks. Why don't we save all registers, but only x19 - x30 and sp ? ( fp is x29 and pc is x30 ). A short answer: to cater to the Armv8 calling convention. Because task switch happens only when a task calls cpu_switch_to function. From the point of view of the task that is being scheduled out (i.e. the \"switched-from\" task), it just calls cpu_switch_to function and it returns after some (potentially long) time. The \"switched from\" task is unaware of that another task (i.e. the \"switched-to\" task) happens to runs during this period. Accordingly to ARM calling conventions registers x0 - x18 can be overwritten by the callee (i.e. cpu_switch_to() in our case). Hence, the kernel doesn't have to save the contents of x0 - x18 for the caller (the \"switched-from\" task). state The state of the currently running task (NOT PSTATE -- an orthogonal concept). For a task just doing CPU work but not IO, the task state will always be TASK_RUNNING . For now, this is the only state supported by our kernel. Later we add a few additional states. For example, a task waiting for an interrupt should be in a different state, because it doesn't make sense to schedule the task when it is not ready to run yet. counter is used to determine how long the current task has been running. counter decreases by 1 each timer tick. When it reaches 0, the kernel will attempt to schedule another task. This supports our simple scheduling algorithm. priority When the kernel schedules a new task, the kernel copies the task's priority value counter . In this way, the kernel can regulate the amount of processor time the task gets relative to other tasks. preempt_count A flag. A non-zero value means that the current task is executing in a critical code region that cannot be interrupted, e.g. by switching to another task. Any timer tick should be ignored and not triggering rescheduling. After the kernel startup, there is only one task running: the one that runs kernel_main(). It is called \"init task\". Before the scheduler is enabled, we must fill task_struct of the init task. This is done in INIT_TASK . All task_struct s are stored in task (sched.c) array. This array has only 64 slots - that is the maximum number of simultaneous tasks the kernel can have. It won't suit a production OS, but it is ok for our goals. An important global variable is current (sched.c) that always points to task_struct of currently executing task. Both current and task array are initially set to hold a pointer to the init task. There is also a global variable nr_task - it contains the number of currently running tasks in the system.","title":"task_struct"},{"location":"lesson04a/rpi-os/#task-switch","text":"","title":"Task switch"},{"location":"lesson04a/rpi-os/#preparing-task_structs-kernelc","text":"void kernel_main(void) { uart_init(); init_printf(0, putc); irq_vector_init(); int res = copy_process((unsigned long)&process, (unsigned long)\"12345\"); if (res != 0) { printf(\"error while starting process 1\"); return; } res = copy_process((unsigned long)&process, (unsigned long)\"abcde\"); if (res != 0) { printf(\"error while starting process 2\"); return; } while (1){ schedule(); } } A new function copy_process is introduced. copy_process takes 2 arguments: a function to execute in a new thread and an argument passed to this function. copy_process allocates a new task_struct and makes it available for the scheduler. Another new function schedule . This is the core scheduler function: it checks whether there is a new task that needs to preempt the current one. In cooperative scheduling, a task voluntarily calls schedule if it doesn't have any work to do at the moment. For preemptive multitasking, schedule is also called from the timer interrupt handler. Try your self with QEMU: set a breakpoint at copy_process & launch the kernel. Examine task_struct with print *p . Examine the value of cpu_context.[pc|sp|fn|arg]. We are calling copy_process 2 times, each time passing a pointer to the process function as the first argument. process function is very simple. void process(char *array) { while (1){ for (int i = 0; i < 5; i++){ uart_send(array[i]); delay(100000); schedule(); } } } It just keeps printing characters from the array, which is passed as an argument. Task 1 is created with the argument \"12345\" and task 2 is with the argument \"abcde\". After printing out a string, a task yields to others by calling schedule() . If our scheduler implementation is correct, both threads will take turns to print strings.","title":"Preparing task_structs (kernel.c)"},{"location":"lesson04a/rpi-os/#switching-tasks-schedc-scheds","text":"This is where the magic happens. The code looks like this. void switch_to(struct task_struct * next) { if (current == next) return; struct task_struct * prev = current; current = next; cpu_switch_to(prev, next); } If the \"next\" process is not the same as the \"current\", the kernel updates current . The cpu_switch_to function is where the real context switch happens. To manipulates registers, it is in assembly. .globl cpu_switch_to cpu_switch_to: mov x10, #THREAD_CPU_CONTEXT add x8, x0, x10 mov x9, sp stp x19, x20, [x8], #16 // store callee-saved registers stp x21, x22, [x8], #16 stp x23, x24, [x8], #16 stp x25, x26, [x8], #16 stp x27, x28, [x8], #16 stp x29, x9, [x8], #16 str x30, [x8] add x8, x1, x10 ldp x19, x20, [x8], #16 // restore callee-saved registers ldp x21, x22, [x8], #16 ldp x23, x24, [x8], #16 ldp x25, x26, [x8], #16 ldp x27, x28, [x8], #16 ldp x29, x9, [x8], #16 ldr x30, [x8] mov sp, x9 ret Let's examine it line by line. mov x10, #THREAD_CPU_CONTEXT add x8, x0, x10 THREAD_CPU_CONTEXT constant contains offset of the cpu_context structure in the task_struct (the offset is 0 in the current implementation). x0 contains a pointer to the first argument, which is the current task_struct (i.e. the \"switch-from\" task). After the copied 2 lines are executed, x8 will contain a pointer to the current cpu_context . mov x9, sp stp x19, x20, [x8], #16 // store callee-saved registers stp x21, x22, [x8], #16 stp x23, x24, [x8], #16 stp x25, x26, [x8], #16 stp x27, x28, [x8], #16 stp x29, x9, [x8], #16 str x30, [x8] The figure above: During context switch, registers are being saved to task_struct.context Next all callee-saved registers are stored in the order, in which they are defined in cpu_context structure. The current stack pointer is saved as cpu_context.sp and x29 is saved as cpu_context.fp (frame pointer). Note: x30 , the link register containing function return address, is stored as cpu_context.pc . Why? Now we calculate the address of the next task's cpu_context : add x8, x1, x10 This a cute hack. x10 contains THREAD_CPU_CONTEXT , the offset of the cpu_context structure inside task_struct . x1 is a pointer to the next task_struct , so x8 will contain a pointer to the next cpu_context . Now, restore the CPU context of \"switch_to\" task from memory to CPU regs. A mirror procedure. ldp x19, x20, [x8], #16 // restore callee-saved registers ldp x21, x22, [x8], #16 ldp x23, x24, [x8], #16 ldp x25, x26, [x8], #16 ldp x27, x28, [x8], #16 ldp x29, x9, [x8], #16 ldr x30, [x8] mov sp, x9 ret The ret instruction will jump to the location pointed to by the link register ( x30 ). If we are switching to a task for the first time, this will be the beginning of the ret_from_fork function. More on that below. In all other cases this will be the location previously saved in the cpu_context.pc by the cpu_switch_to function. Think: which instruction does it point to?","title":"Switching tasks (sched.c &amp; sched.S)"},{"location":"lesson04a/rpi-os/#launching-a-new-task","text":"New task creation is implemented in the copy_process function. Keep in mind: after copy_process finishes execution, no context switch happens yet. The function only prepares new task_struct and adds it to the task array \u2014 this task will be executed only after schedule function is called. int copy_process(unsigned long fn, unsigned long arg) { struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) return 1; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)p + THREAD_SIZE; int pid = nr_tasks++; task[pid] = p; return 0; } We examine it in details. struct task_struct *p; The function starts with allocating a pointer for the new task. As interrupts are off, the kernel will not be interrupted in the middle of the copy_process function. p = (struct task_struct *) get_free_page(); if (!p) return 1; Next, a new page is allocated. At the bottom of this page, we are putting the task_struct for the newly created task. The rest of this page will be used as the task stack. A few lines below, context.sp is set as p + THREAD_SIZE . THREAD_SIZE is defined as 4KB. It is the total amount of kernel memory for a task. The name, again, is following the Linux kernel convention. Figure above: a task's task_struct in relative to its stack space p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; After the task_struct is allocated, we can initialize its properties. Priority and initial counters are set based on the current task priority. p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)p + THREAD_SIZE; This is the most important part of the function. Here cpu_context is initialized. The stack pointer is set to the top of the newly allocated memory page (see the figure above). pc is set to the ret_from_fork function. Details below.","title":"Launching a new task"},{"location":"lesson04a/rpi-os/#ret_from_fork-entrys","text":"This is the first piece of code executed by a newly created process. A new process P executes ret_from_fork after it is switched to for the first time. That is right after the scheduler picks P for the first time and restores P's CPU context from task_struct to CPU registers. Throughout its lifetime, P only executes ret_from_fork once. About naming: despite the name \"fork\", we are not doing fork() as in Linux/Unix. We are simply copying a task_struct while fork() does far more things like duplicating process address spaces. The naming follows the Linux kernel convention; and we will evolve our ret_from_fork in subsequent experiments. .globl ret_from_fork ret_from_fork: bl schedule_tail // will talk about this later mov x0, x20 blr x19 //should never return What are the initial values of x19 and x20 ? See code copy_process above, which saves fn (the process's main function) and arg (the argument passed to the process) to task_struct.x19 and x20 . When switching to P, the kernel restores fn and arg from task_struct to x19 and x20 . And here we are: ret_from_fork calls the function stored in x19 register with the argument stored in x20 . :wrench:Try your self with QEMU+GDB: set a breakpoint at ret_from_fork, launch the kernel, and single step into the new process function.","title":"ret_from_fork (entry.S)"},{"location":"lesson04a/rpi-os/#memory-allocation","text":"Each task in the system should have its dedicated stack. That's why when creating a new task we must have a way to allocate memory. For now, our memory allocator is extremely primitive. (The implementation can be found in mm.c file) static unsigned short mem_map [ PAGING_PAGES ] = {0,}; unsigned long get_free_page() { for (int i = 0; i < PAGING_PAGES; i++){ if (mem_map[i] == 0){ mem_map[i] = 1; return LOW_MEMORY + i*PAGE_SIZE; } } return 0; } void free_page(unsigned long p){ mem_map[(p - LOW_MEMORY) / PAGE_SIZE] = 0; } :wrench: Try it yourself with QEMU: ptype mem_map then print (short[10])*mem_map . The allocator can work only with memory pages (each page is 4 KB in size). There is an array called mem_map that for each page in the system holds its status: whether it is allocated or free. Whenever we need to allocate a new page, we just loop through this array and return the first free page. This implementation is based on 2 assumptions: We know the total amount of memory in the system. It is 1 GB - 1 MB (the last megabyte of memory is reserved for device registers.). This value is stored in the HIGH_MEMORY constant. First 4 MB of memory are reserved for the kernel image and init task stack. This value is stored in the LOW_MEMORY constant. All memory allocations start right after this point. Note: even with QEMU our kernel must start from 0x80000 (512KB), the above assumptions are good as there's still plenty room in 512KB -- LOW_MEMORY for our tiny kernel.","title":"Memory allocation"},{"location":"lesson04a/rpi-os/#the-scheduler","text":"Finally, we are ready to look at the scheduler algorithm. We almost precisely copied this algorithm from the first release of the Linux kernel. void _schedule(void) { int next,c; struct task_struct * p; while (1) { c = -1; next = 0; // try to pick a task for (int i = 0; i < NR_TASKS; i++){ p = task[i]; if (p && p->state == TASK_RUNNING && p->counter > c) { c = p->counter; next = i; } } if (c) { break; } // update counters for (int i = 0; i < NR_TASKS; i++) { p = task[i]; if (p) { p->counter = (p->counter >> 1) + p->priority; } } } switch_to(task[next]); } The simple algorithm works like the following: The first for loop iterates over all tasks and tries to find a task in TASK_RUNNING state with the maximum counter. If such a task is found, we immediately break from the while loop and switch to this task. If no such task is found, this is either because i) no task is in TASK_RUNNING state or ii) all such tasks have 0 counters. In a real OS, i) might happen, for example, when all tasks are waiting for an interrupt. In our current tiny kernel, all tasks are always in TASK_RUNNING (Why?) The scheduler moves to the 2nd for loop to \"recharge\" counters. It bumps counters for all tasks once. The increment depends on a task's priority. Note: a task counter can never get larger than 2 * priority . With updated counters, the scheduler goes back to the 1st for loop to pick a task. We will augment the scheduling algorithm for preemptive multitasking later.","title":"The scheduler"},{"location":"lesson04a/rpi-os/#conclusion","text":"We have seen important nuts & bolts of multitasking. The subsequent experiment will enable task preemption. We will show a detailed workflow of context switch there.","title":"Conclusion"},{"location":"lesson04a/rpi-os/#one-more-thing","text":"There's support for a graphical console. Works for both QEMU and Rpi3. Display required. See instructions .","title":"One more thing ..."},{"location":"lesson04b/rpi-os/","text":"4b: Preemptive Multitasking Objectives A minimum kernel that can schedule multiple tasks in a preemptive fashion. With this experiment, our tiny kernel is more like a \"real-time kernel\" commonly seen in embedded systems, e.g. FreeRTOS. Preempt tasks with time interrupts Understand context switch driven by interrupts, in particular switch to/from interrupt handlers Atomic kernel regions where preemption is disallowed Source code location: p1-kernel/src/lesson04b Roadmap We will turn on timer interrupts. In the interrupt handler, our kernel invokes its scheduler to switch among runnable tasks. In addition to switch_to , the kernel should save & restore CPU state upon entering/existing interrupt handling. Turn on timer interrupts! We turn on timer interrupts in kernel_main . void kernel_main(void) { uart_init(); init_printf(0, putc); irq_vector_init(); timer_init(); /* new addition */ enable_interrupt_controller(); /* new addition */ enable_irq(); /* new addition */ ... } With that, tasks no longer need to call schedule() voluntarily. void process(char *array) { while (1){ for (int i = 0; i < 5; i++){ uart_send(array[i]); delay(100000); } // schedule(); } } Calling schedule() in timer tick With preemptive scheduling, schedule() are called in two places. A task can call schedule voluntarily (as in cooperative scheduling). On a regular basis from the timer interrupt handler. Look at timer_tick() , which is called from the timer interrupt. void timer_tick() { --current->counter; if (current->counter>0 || current->preempt_count >0) { return; } current->counter=0; enable_irq(); _schedule(); disable_irq(); ... First of all, it decreases current task's counter. If the counter is greater than 0 or preemption is currently disabled the function returns. Otherwise schedule is called with interrupts enabled. (Note: we just came from an interrupt handler and CPU just automatically disabled all interrupts.) Why interrupts must be enabled in the scheduler? More on this later. How scheduling works with interrupt entry/exit? With preemptive scheduling, the kernel must save & restore CPU contexts for the task being interrupted. This is because, e.g. a task A may be interrupted at any point and get preempted (i.e. \"losing CPU\"). Later, when the kernel reschedules A, A should resume from where it was interrupted. Refresh your memory : in previous baremetal experiments with no multitasking, we have seen how kernel_entry and kernel_exit macros save and restore general-purpose CPU regs upon switch to/from an interrupt/exception handler. There, we rely on that the hardware automatically saves exception return address and CPU status in registers, elr_el1 register and spsr_el register. When eret is executed, CPU restores execution from these registers. Figure above: in previous experiments w/o multitasking, save/restore registers upon entering/leaving irq handlers. With multitasking, the kernel now has to create per-task copies of CPU context in memory: ALL general-purpose registers plus elr_el1 and spsr_el . Where to store the CPU context? We choose to store the CPU context on the current task's stack (NOT in its task_struct.cpu_context ). There are alternative designs to be examined later. An example workflow Kernel boots kernel_main function is executed. The initial stack is configured to start at LOW_MEMORY, which is at 0x0040:0000 (4 MB). Task 1 creation kernel_main calls copy_process for the first time. A new 4 KB page is allocated, and task_struct is placed at the bottom of this page. Task 2 creation kernel_main calls copy_process for the second time and the same process repeats. Task 2 is created and added to the task list. Switching to task 1; task 1 runs kernel_main calls the schedule function and it decides to switch to task 1. cpu_switch_to saves callee-saved registers in the init task cpu_context , which is located inside the kernel image. cpu_switch_to restores callee-saved registers from task 1's task_struct . At this point, cpu_context.sp points to 0x00401000 , lr points to ret_from_fork function, x19 contains a pointer to the start of process() and x20 a pointer to string \"12345\", which is located somewhere in the kernel image. cpu_switch_to executes ret , which jumps to the ret_from_fork function. ret_from_fork reads x19 and x20 registers and calls process function with the argument \"12345\". After process function starts, the stack of task 1 begins to grow. While task 1 runs, a timer interrupt occurred kernel_entry saves all general purpose registers & elr_el1 and spsr_el1 to the bottom of task 1 stack (\"saved regs\" in the figure below). The kernel now executes in the irq context. It continues to grow the current stack which belongs to task 1. The growth is below the \"saved regs\" region and is marked as \"irq frame\" on the figure (i.e. the stack frame created by the execution in the irq context). The kernel proceeds to schedule and picks task 2. Switching to task 2; task 2 runs cpu_switch_to executes exactly the same sequence of steps that it does for task 1. Task 2 started to execute and it stack grows. Note: until now, the kernel has NOT executed eret for the previous timer irq. This is fine as an intentional choice made for this experiment. How can we execute task 2 in the context of the previous irq? This is allowed because ARM64 CPU does not differentiate execution in an irq context vs. in an exception (i.e. syscall) context. All the CPU knows is the current EL (we always stay at EL1 before/after the irq) and the irq enable status. And irqs have been enabled previously in timer_tick before schedule was called. Nevertheless, there's a more common design in which the kernel finishes the previous irq handling (i.e. 'eret') before switching to a new task. See \"alternative design\" below. Another timer interrupt occurred while task 2 is running Same as above, kernel_entry saves all general purpose registers + elr_el1 and spsr_el1 at the bottom of task 2's stack. Task 2's irq frame begins to grow. Scheduling out task 2 The kernel calls schedule() . It observes that all tasks have their counters set to 0 and set counters to their tasks priorities. schedule selects init task to run. (This is because all tasks now have their counters set to 1 and init task is the first in the list). But actually, it would be fully legal for schedule to select task 1 or task 2 at this point, because their counters has equal values. We are more interested in the case when task 1 is selected so let's now assume that this is what had happened. Switching to task 1, exiting from the 1st irq cpu_switch_to is called and it restores previously saved callee-saved registers from task 1 cpu_context . Link register now points to the instruction right after cpu_switch_to , which was called last time when task 1 was executed. sp points to the bottom of task 1 interrupt stack. This is because task 1 finished handling the previous interrupt handler. From cpu_switch_to , task1 returns back to switch_to , to _schedule , and then to timer_tick . There, it disables interrupts and finally executes kernel_exit . There, task 1 irq frame (including the save regs) is unwound. Task 1 resumes normal execution kernel_exit restores all general purpose registers as well as elr_el1 and spsr_el1 . elr_el1 now points somewhere in the middle of the process function. sp points to the bottom of task 1 stack. (Note: the remaining task size depends on the size of local variables in process ) Finally, kernel_exit executes eret instruction which uses elr_el1 register to jump back to process function. Task 1 resumes it normal execution! Aside: An alternative design When an interrupt happens, the CPU saves irq stack frame automatically on the stack of the current task, e.g. A. This is the same as the design above. The kernel copies the auto saved register contents from the irq frame to the current task's task_struct , representing the CPU context when this task was interrupted by irq. The kernel calls its scheduler and returns from the irq (possibly to a different task). The irq stack on the A's stack is then unwound. Now irq is on. Later, when A is scheduled in, the kernel restores its CPU context from A's task_struct . Can you implement the alternative design? Disable preemption The kernel needs mechanism to (temporarily) disable preemption. Example: in creating a new task_struct , we do not want rescheduling to happen. Otherwise the scheduler may see an incomplete task_struct . In other words, the creation of task_struct should be atomic . To disable preemption, one method is to disable interrupts. Beyond that, the kernel also needs fine-grained control. Per-task preempt_count To task_struct , we add: struct task_struct { struct cpu_context cpu_context; long state; long counter; long priority; long preempt_count; // new addition }; preempt_count >0 indicates that right now the current task is non-preemptable. The following two functions operate on it: void preempt_disable(void) { current->preempt_count++;} void preempt_enable(void) { current->preempt_count--;} Seeing this flag, the kernel will not invoke scheduler() at all, let alone descheduling this task (i.e. switching to a different task). This is done via the following code. void timer_tick() { if (current->counter>0 || current->preempt_count >0) return; ... Why a count instead of a binary flag? This again mimics the Linux implementation. Individual kernel functions could increment & decrement preempt_count . If all kernel functions have finished decrementing preempt_count , the count drops to zero and the scheduler is free to deschedule the task. This mechanism is called reference count, which is common in system software. preempt_count does not prevent a task from shooting in its own foot, though. For instance, a misbehaving task calling schedule() when preempt_count > 0 will likely corrupt kernel data structures. Try it out! Creating a task_struct atomically Going back to making copy_process atomic: int copy_process(unsigned long fn, unsigned long arg) { preempt_disable(); /* new addition */ struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) return 1; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->preempt_count = 1; // new addition p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)p + THREAD_SIZE; int pid = nr_tasks++; task[pid] = p; preempt_enable(); /* new addition */ return 0; } preempt_count is set to 1, preventing the new task, once it starts to execute, from being preempted until it completes some initialization work. After that, the new task executes ret_from_fork , which calls schedule_tail() which will call preempt_enable() // entry.S .globl ret_from_fork ret_from_fork: bl schedule_tail ... Making the scheduling algorithm atomic The scheduler is non-reentrant . Making it atomic looks easy: we just call preempt_disable/enable() upon entering/leaving the scheduler. void _schedule(void) { preempt_disable(); /* new addition */ int next,c; struct task_struct * p; while (1) { c = -1; next = 0; for (int i = 0; i < NR_TASKS; i++){ p = task[i]; if (p && p->state == TASK_RUNNING && p->counter > c) { c = p->counter; next = i; } } if (c) { break; } for (int i = 0; i < NR_TASKS; i++) { p = task[i]; if (p) { p->counter = (p->counter >> 1) + p->priority; } } } switch_to(task[next]); preempt_enable(); /* new addition */ } Why does the kernel disable preemption , instead of disabling all interrupts? By design, if no TASK_RUNNING tasks are there, the scheduler will run its while loop over and over again until some of the tasks will move to TASK_RUNNING state. But if we are running on a single CPU, how then a task state can change while this loop is running? The answer is that if some task is waiting for an interrupt, this interrupt can happen while schedule function is executed and interrupt handler can change the state of the task. This actually explains why interrupts must be enabled during schedule execution. This also demonstrates an important distinction between disabling interrupts and disabling preemption. schedule disables preemption for the duration of the whole function. This ensures that nested schedule will not be called while we are in the middle of the original function execution. However, interrupts can legally happen during schedule function execution. Note: our kernel does not (yet) have the mechanism for tasks to wait for interrupts. It's a important mechanism to be added. I am not very satisfied with leaving interrupt on during schedule(). There shall be an idle task which does WFI when no other tasks are runnable. In that way, the scheduler can avoid spinning and can run with interrupt off. To implement the idle task, the kernel shall implement task wait state. Conclusion We are done with scheduling, but right now our kernel can manage only kernel threads: they are executed at EL1 and can directly access any kernel functions or data. In the next 2 lessons we are going fix this and introduce system calls and virtual memory.","title":"exp4b"},{"location":"lesson04b/rpi-os/#4b-preemptive-multitasking","text":"","title":"4b: Preemptive Multitasking"},{"location":"lesson04b/rpi-os/#objectives","text":"A minimum kernel that can schedule multiple tasks in a preemptive fashion. With this experiment, our tiny kernel is more like a \"real-time kernel\" commonly seen in embedded systems, e.g. FreeRTOS. Preempt tasks with time interrupts Understand context switch driven by interrupts, in particular switch to/from interrupt handlers Atomic kernel regions where preemption is disallowed Source code location: p1-kernel/src/lesson04b","title":"Objectives"},{"location":"lesson04b/rpi-os/#roadmap","text":"We will turn on timer interrupts. In the interrupt handler, our kernel invokes its scheduler to switch among runnable tasks. In addition to switch_to , the kernel should save & restore CPU state upon entering/existing interrupt handling.","title":"Roadmap"},{"location":"lesson04b/rpi-os/#turn-on-timer-interrupts","text":"We turn on timer interrupts in kernel_main . void kernel_main(void) { uart_init(); init_printf(0, putc); irq_vector_init(); timer_init(); /* new addition */ enable_interrupt_controller(); /* new addition */ enable_irq(); /* new addition */ ... } With that, tasks no longer need to call schedule() voluntarily. void process(char *array) { while (1){ for (int i = 0; i < 5; i++){ uart_send(array[i]); delay(100000); } // schedule(); } }","title":"Turn on timer interrupts!"},{"location":"lesson04b/rpi-os/#calling-schedule-in-timer-tick","text":"With preemptive scheduling, schedule() are called in two places. A task can call schedule voluntarily (as in cooperative scheduling). On a regular basis from the timer interrupt handler. Look at timer_tick() , which is called from the timer interrupt. void timer_tick() { --current->counter; if (current->counter>0 || current->preempt_count >0) { return; } current->counter=0; enable_irq(); _schedule(); disable_irq(); ... First of all, it decreases current task's counter. If the counter is greater than 0 or preemption is currently disabled the function returns. Otherwise schedule is called with interrupts enabled. (Note: we just came from an interrupt handler and CPU just automatically disabled all interrupts.) Why interrupts must be enabled in the scheduler? More on this later.","title":"Calling schedule() in timer tick"},{"location":"lesson04b/rpi-os/#how-scheduling-works-with-interrupt-entryexit","text":"With preemptive scheduling, the kernel must save & restore CPU contexts for the task being interrupted. This is because, e.g. a task A may be interrupted at any point and get preempted (i.e. \"losing CPU\"). Later, when the kernel reschedules A, A should resume from where it was interrupted. Refresh your memory : in previous baremetal experiments with no multitasking, we have seen how kernel_entry and kernel_exit macros save and restore general-purpose CPU regs upon switch to/from an interrupt/exception handler. There, we rely on that the hardware automatically saves exception return address and CPU status in registers, elr_el1 register and spsr_el register. When eret is executed, CPU restores execution from these registers. Figure above: in previous experiments w/o multitasking, save/restore registers upon entering/leaving irq handlers. With multitasking, the kernel now has to create per-task copies of CPU context in memory: ALL general-purpose registers plus elr_el1 and spsr_el . Where to store the CPU context? We choose to store the CPU context on the current task's stack (NOT in its task_struct.cpu_context ). There are alternative designs to be examined later.","title":"How scheduling works with interrupt entry/exit?"},{"location":"lesson04b/rpi-os/#an-example-workflow","text":"Kernel boots kernel_main function is executed. The initial stack is configured to start at LOW_MEMORY, which is at 0x0040:0000 (4 MB).","title":"An example workflow"},{"location":"lesson04b/rpi-os/#_1","text":"Task 1 creation kernel_main calls copy_process for the first time. A new 4 KB page is allocated, and task_struct is placed at the bottom of this page. Task 2 creation kernel_main calls copy_process for the second time and the same process repeats. Task 2 is created and added to the task list. Switching to task 1; task 1 runs kernel_main calls the schedule function and it decides to switch to task 1. cpu_switch_to saves callee-saved registers in the init task cpu_context , which is located inside the kernel image. cpu_switch_to restores callee-saved registers from task 1's task_struct . At this point, cpu_context.sp points to 0x00401000 , lr points to ret_from_fork function, x19 contains a pointer to the start of process() and x20 a pointer to string \"12345\", which is located somewhere in the kernel image. cpu_switch_to executes ret , which jumps to the ret_from_fork function. ret_from_fork reads x19 and x20 registers and calls process function with the argument \"12345\". After process function starts, the stack of task 1 begins to grow. While task 1 runs, a timer interrupt occurred kernel_entry saves all general purpose registers & elr_el1 and spsr_el1 to the bottom of task 1 stack (\"saved regs\" in the figure below). The kernel now executes in the irq context. It continues to grow the current stack which belongs to task 1. The growth is below the \"saved regs\" region and is marked as \"irq frame\" on the figure (i.e. the stack frame created by the execution in the irq context). The kernel proceeds to schedule and picks task 2. Switching to task 2; task 2 runs cpu_switch_to executes exactly the same sequence of steps that it does for task 1. Task 2 started to execute and it stack grows. Note: until now, the kernel has NOT executed eret for the previous timer irq. This is fine as an intentional choice made for this experiment. How can we execute task 2 in the context of the previous irq? This is allowed because ARM64 CPU does not differentiate execution in an irq context vs. in an exception (i.e. syscall) context. All the CPU knows is the current EL (we always stay at EL1 before/after the irq) and the irq enable status. And irqs have been enabled previously in timer_tick before schedule was called. Nevertheless, there's a more common design in which the kernel finishes the previous irq handling (i.e. 'eret') before switching to a new task. See \"alternative design\" below. Another timer interrupt occurred while task 2 is running Same as above, kernel_entry saves all general purpose registers + elr_el1 and spsr_el1 at the bottom of task 2's stack. Task 2's irq frame begins to grow. Scheduling out task 2 The kernel calls schedule() . It observes that all tasks have their counters set to 0 and set counters to their tasks priorities. schedule selects init task to run. (This is because all tasks now have their counters set to 1 and init task is the first in the list). But actually, it would be fully legal for schedule to select task 1 or task 2 at this point, because their counters has equal values. We are more interested in the case when task 1 is selected so let's now assume that this is what had happened. Switching to task 1, exiting from the 1st irq cpu_switch_to is called and it restores previously saved callee-saved registers from task 1 cpu_context . Link register now points to the instruction right after cpu_switch_to , which was called last time when task 1 was executed. sp points to the bottom of task 1 interrupt stack. This is because task 1 finished handling the previous interrupt handler. From cpu_switch_to , task1 returns back to switch_to , to _schedule , and then to timer_tick . There, it disables interrupts and finally executes kernel_exit . There, task 1 irq frame (including the save regs) is unwound. Task 1 resumes normal execution kernel_exit restores all general purpose registers as well as elr_el1 and spsr_el1 . elr_el1 now points somewhere in the middle of the process function. sp points to the bottom of task 1 stack. (Note: the remaining task size depends on the size of local variables in process ) Finally, kernel_exit executes eret instruction which uses elr_el1 register to jump back to process function. Task 1 resumes it normal execution!","title":""},{"location":"lesson04b/rpi-os/#aside-an-alternative-design","text":"When an interrupt happens, the CPU saves irq stack frame automatically on the stack of the current task, e.g. A. This is the same as the design above. The kernel copies the auto saved register contents from the irq frame to the current task's task_struct , representing the CPU context when this task was interrupted by irq. The kernel calls its scheduler and returns from the irq (possibly to a different task). The irq stack on the A's stack is then unwound. Now irq is on. Later, when A is scheduled in, the kernel restores its CPU context from A's task_struct . Can you implement the alternative design?","title":"Aside: An alternative design"},{"location":"lesson04b/rpi-os/#disable-preemption","text":"The kernel needs mechanism to (temporarily) disable preemption. Example: in creating a new task_struct , we do not want rescheduling to happen. Otherwise the scheduler may see an incomplete task_struct . In other words, the creation of task_struct should be atomic . To disable preemption, one method is to disable interrupts. Beyond that, the kernel also needs fine-grained control.","title":"Disable preemption"},{"location":"lesson04b/rpi-os/#per-task-preempt_count","text":"To task_struct , we add: struct task_struct { struct cpu_context cpu_context; long state; long counter; long priority; long preempt_count; // new addition }; preempt_count >0 indicates that right now the current task is non-preemptable. The following two functions operate on it: void preempt_disable(void) { current->preempt_count++;} void preempt_enable(void) { current->preempt_count--;} Seeing this flag, the kernel will not invoke scheduler() at all, let alone descheduling this task (i.e. switching to a different task). This is done via the following code. void timer_tick() { if (current->counter>0 || current->preempt_count >0) return; ... Why a count instead of a binary flag? This again mimics the Linux implementation. Individual kernel functions could increment & decrement preempt_count . If all kernel functions have finished decrementing preempt_count , the count drops to zero and the scheduler is free to deschedule the task. This mechanism is called reference count, which is common in system software. preempt_count does not prevent a task from shooting in its own foot, though. For instance, a misbehaving task calling schedule() when preempt_count > 0 will likely corrupt kernel data structures. Try it out!","title":"Per-task preempt_count"},{"location":"lesson04b/rpi-os/#creating-a-task_struct-atomically","text":"Going back to making copy_process atomic: int copy_process(unsigned long fn, unsigned long arg) { preempt_disable(); /* new addition */ struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) return 1; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->preempt_count = 1; // new addition p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)p + THREAD_SIZE; int pid = nr_tasks++; task[pid] = p; preempt_enable(); /* new addition */ return 0; } preempt_count is set to 1, preventing the new task, once it starts to execute, from being preempted until it completes some initialization work. After that, the new task executes ret_from_fork , which calls schedule_tail() which will call preempt_enable() // entry.S .globl ret_from_fork ret_from_fork: bl schedule_tail ...","title":"Creating a task_struct atomically"},{"location":"lesson04b/rpi-os/#making-the-scheduling-algorithm-atomic","text":"The scheduler is non-reentrant . Making it atomic looks easy: we just call preempt_disable/enable() upon entering/leaving the scheduler. void _schedule(void) { preempt_disable(); /* new addition */ int next,c; struct task_struct * p; while (1) { c = -1; next = 0; for (int i = 0; i < NR_TASKS; i++){ p = task[i]; if (p && p->state == TASK_RUNNING && p->counter > c) { c = p->counter; next = i; } } if (c) { break; } for (int i = 0; i < NR_TASKS; i++) { p = task[i]; if (p) { p->counter = (p->counter >> 1) + p->priority; } } } switch_to(task[next]); preempt_enable(); /* new addition */ } Why does the kernel disable preemption , instead of disabling all interrupts? By design, if no TASK_RUNNING tasks are there, the scheduler will run its while loop over and over again until some of the tasks will move to TASK_RUNNING state. But if we are running on a single CPU, how then a task state can change while this loop is running? The answer is that if some task is waiting for an interrupt, this interrupt can happen while schedule function is executed and interrupt handler can change the state of the task. This actually explains why interrupts must be enabled during schedule execution. This also demonstrates an important distinction between disabling interrupts and disabling preemption. schedule disables preemption for the duration of the whole function. This ensures that nested schedule will not be called while we are in the middle of the original function execution. However, interrupts can legally happen during schedule function execution. Note: our kernel does not (yet) have the mechanism for tasks to wait for interrupts. It's a important mechanism to be added. I am not very satisfied with leaving interrupt on during schedule(). There shall be an idle task which does WFI when no other tasks are runnable. In that way, the scheduler can avoid spinning and can run with interrupt off. To implement the idle task, the kernel shall implement task wait state.","title":"Making the scheduling algorithm atomic"},{"location":"lesson04b/rpi-os/#conclusion","text":"We are done with scheduling, but right now our kernel can manage only kernel threads: they are executed at EL1 and can directly access any kernel functions or data. In the next 2 lessons we are going fix this and introduce system calls and virtual memory.","title":"Conclusion"},{"location":"lesson05/rpi-os/","text":"5: User processes and system calls Objectives Our kernel is evolving from an \"embedded\" kernel which often lacks user/kernel separation to a multiprogrammed kernel. Run tasks in EL0 Add the syscall mechanism Implement a few basic syscalls NOTE: this experiment enables running user/kernel at different ELs. Yet, it does not NOT give each task its own address space \u2014 we are going to tackle this issue in lesson 6! Source code location: p1-kernel/src/lesson05 Roadmap Implement the syscall mechanism, in particular switch between EL0 and EL1 (you have already done something similar in previous experiments!) Implement two mechanisms that put user tasks to EL0: forking an existing user task at EL0 moving a kernel task EL1 -> EL0 Syscall implementation Each system call is a synchronous exception. A user program prepares all necessary arguments, and then run svc instruction. Such exceptions are handled at EL1 by the kernel. The kernel validates all arguments, does the syscall, and exists from the exception. After that, the user task resumes at EL0 right after the svc instruction. We have 4 simple syscalls: write outputs to UART. It accepts a buffer with the text to be printed as the first argument. clone creates a new user thread. The location of the stack for the newly created thread is passed as the first argument. malloc allocates a memory page for a user process. There is no analog of this syscall in Linux (and I think in any other OS as well.) The only reason that we have no virtual memory yet, and all user processes work with physical memory. Each process needs a way to figure out which memory page can be used. malloc syscall return pointer to the newly allocated page or -1 in case of an error. exit Each process must call this syscall after it finishes execution. It will do cleanup. All syscalls are defined in sys.c . There is also an array sys_call_table that contains pointers to all syscall handlers. Each syscall has a \"syscall number\" \u2014 this is just an index in the sys_call_table array. All syscall numbers are defined here \u2014 they are used by the assembler code to look up syscall. Let's use write syscall as an example: //sys.S, executed at the user level .globl call_sys_write call_sys_write: mov w8, #SYS_WRITE_NUMBER svc #0 ret Simple -- the wrapper stores the syscall number in the w8 register and does svc . Convention: registers x0 \u2014 x7 are used for syscall arguments and x8 is used to store syscall number. This allows a syscall to have up to 8 arguments. In commodity OSes, such wrapper functions are usually in user library such as glibc but not in the kernel. Switching between EL0 and EL1 We need this new mechanism. It's in the same spirit as we move from EL2/3 to EL1. (Recall: how did we do it?) Previously, our kernel runs at EL1; when an interrupt occurs, it takes the interrupt at EL1. Now, we need to take exception (svc) from EL0 to EL1. To accommodate this, both kernel_entry and kernel_exit macros accepts an additional argument el , indicating the EL an exception is taken from. The information is required to properly save/restore stack pointer. Here are the two relevant parts from the kernel_entry and kernel_exit macros. // kernel_entry .if \\el == 0 mrs x21, sp_el0 .else add x21, sp, #S_FRAME_SIZE .endif // kernel_exit .if \\el == 0 msr sp_el0, x21 .endif ... eret Even for the same task, we are using 2 distinct stacks for EL0 and EL1. This is a common design because we want to separate user/kernel. Supported by CPU hardware, after taking an exception from EL0 to EL1, the CPU automatically starts use the SP for EL1. The SP for EL0 can be found in the sp_el0 register. The value of this register must be stored and restored upon entering/exiting the kernel, even if the kernel does not use sp_el0 in the exception handler. Reason: we need to virtualize sp_el0 for each task because each task has its own user stack. Try to visualize this in your mind. When we do kernel_exit , how do we specify which EL to return to, EL0 or EL1? This EL level is encoded in the spsr_el1 register that was saved, e.g. when syscall enters the kernel. So we always return to the level from which the exception was taken. How did we treat SP when taking interrupts (from EL1)? Revisit the figures in previous experiments. Handling synchronous exceptions In the exception table, el0_sync is registered as the handler for sync exception taken at EL0. // entry.S el0_sync: kernel_entry 0 mrs x25, esr_el1 // read the syndrome register lsr x24, x25, #ESR_ELx_EC_SHIFT // exception class cmp x24, #ESR_ELx_EC_SVC64 // SVC in 64-bit state b.eq el0_svc handle_invalid_entry 0, SYNC_ERROR As for all exception handlers, kernel_entry macro is called. esr_el1 (Exception Syndrome Register) is checked. This register contains \"exception class\" field at offset ESR_ELx_EC_SHIFT . If exception class is equal to ESR_ELx_EC_SVC64 this means that the current exception is caused by the svc instruction and it is a system call. In this case, we jump to el0_svc label and show an error message otherwise. sc_nr .req x25 // number of system calls scno .req x26 // syscall number stbl .req x27 // syscall table pointer el0_svc: adr stbl, sys_call_table // load syscall table pointer uxtw scno, w8 // syscall number in w8 mov sc_nr, #__NR_syscalls bl enable_irq cmp scno, sc_nr // check upper syscall limit b.hs ni_sys ldr x16, [stbl, scno, lsl #3] // address in the syscall table blr x16 // call sys_* routine b ret_from_syscall ni_sys: handle_invalid_entry 0, SYSCALL_ERROR el0_svc first loads the address of the syscall table in the stbl (it is just an alias to the x27 register.) and syscall number in the scno variable. Then interrupts are enabled and syscall number is compared to the total number of syscalls in the system \u2014 if it is greater or equal an error message is shown. If syscall number falls within the required range, it is used as an index in the syscall table array to obtain a pointer to the syscall handler. Next, the handler is executed and after it finishes ret_from_syscall is called. Note, that we don't touch here registers x0 \u2013 x7 \u2014 they are transparently passed to the handler. (Why?) Fast forward to the completion of syscall. ret_from_syscall: bl disable_irq str x0, [sp, #S_X0] // returned x0 kernel_exit 0 ret_from_syscall first disables interrupts. Then it saves the value of x0 register on the stack. This is required because kernel_exit will restore all general purpose registers from their saved values, but x0 now contains return value of the syscall handler and we want this value to be passed to the user code. Finally kernel_exit is called, which returns to the user code. Executing a task in user mode Atop that, the kernel implements two complementary ways for launching a user process. Overview: Method 1: Forking user processes At the user level, user_process() calls call_sys_clone to spawn a new task. // sys.S .globl call_sys_clone call_sys_clone: /* Save args for the child. They will be preserved throughout syscall */ mov x10, x0 /*fn*/ mov x11, x1 /*arg*/ mov x12, x2 /*stack*/ /* Prep syscall args. Do the system call. */ mov x0, x2 /* stack */ mov x8, #SYS_CLONE_NUMBER svc 0x0 cmp x0, #0 beq thread_start ret thread_start: mov x29, 0 /* Pick up the function arg and execute. */ mov x0, x11 blr x10 /* We are done, pass the return value through x0. */ mov x8, #SYS_EXIT_NUMBER svc 0x0 The clone wrapper above mimics the coresponding function from in the glibc library. x0-x3 contain syscall arguments. They are intended for the child task. Save fn and arg to x10-x11. Why? The kernel syscall handler el0_svc does not preserve x0-x3. The new task will pick up x10 and x11 in thread_start . Save the pointer to the new task's stack in x2, as expected by sys_clone(unsigned long stack) . Starts syscall via svc . Upon returning from syscall, checks return value in x0: if 0, we are executing inside the child task. In this case, execution goes to thread_start label. If not 0, we are executing in the parent task. x0 is the PID of the child task. thread_start executes in the new task with the give entry function (x10) and the arg to the function (x11). Note x29 (FP) is cleared for correct stack unwinding at the user level. See here . After the function finishes, exit syscall is performed \u2014 it never returns. Implementing clone in kernel Inside the kernel, clone() goes to is sys_clone() (sys.c). It just calls copy_process() . This function, however, has been modified since the last lesson. int copy_process(unsigned long clone_flags, unsigned long fn, unsigned long arg, unsigned long stack) { preempt_disable(); struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) { return -1; } struct pt_regs *childregs = task_pt_regs(p); memzero((unsigned long)childregs, sizeof(struct pt_regs)); memzero((unsigned long)&p->cpu_context, sizeof(struct cpu_context)); // new addition if (clone_flags & PF_KTHREAD) { p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; } else { struct pt_regs * cur_regs = task_pt_regs(current); *childregs = *cur_regs; childregs->regs[0] = 0; childregs->sp = stack + PAGE_SIZE; p->stack = stack; } p->flags = clone_flags; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->preempt_count = 1; //disable preemtion until schedule_tail p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)childregs; int pid = nr_tasks++; task[pid] = p; preempt_enable(); return pid; } If creating a new kernel thread, the function does the same thing as before. If creating a user thread, the function takes care of pt_regs as it is unique to a user thread -- the state saved/restored upon entering/exiting the kernel. struct pt_regs * cur_regs = task_pt_regs(current); *childregs = *cur_regs; childregs->regs[0] = 0; childregs->sp = stack + PAGE_SIZE; p->stack = stack; We populate the CPU context, i.e. pt_regs , for the new task. Note that pt_regs is always at the top of the stack page (recall the figure above), because when syscall enters/exits the kernel, the kernel stack is empty. x0 in the new state is set to 0 , because x0 will be the return value of the clone syscall. We've just seen how clone wrapper function uses this value to determine whether we are in the parent or the child task. Next sp for the new task is set to point to the top of the new user stack page. We also save the pointer to the stack page in order to do a cleanup after the task finishes. Method 2: Moving an existing kernel task to EL0 Overview: upon its creation, the kernel task calls its main function, kernel_process() , which calls move_to_user_mode() . The later prepares CPU context for exiting to EL0. Then kernel_process() returns to ret_from_fork which invokes the familiar kernel_exit . Eventually, an eret instruction - boom! We land in EL0. Code walkthrough First create a process (i.e. a task) as we did before. This is a \"kernel\" process to execute at EL1. // kernel.c int res = copy_process(PF_KTHREAD, (unsigned long)&kernel_process, 0, 0); The kernel process invokes move_to_user_mode() , passing a function pointer to the user_process as the first argument. void kernel_process() { printf(\"Kernel process started. EL %d\\r\\n\", get_el()); int err = move_to_user_mode((unsigned long)&user_process); ... The move_to_user_mode function prepares pt_regs and the user stack, so the kernel process becomes a \"legit\" user process. int move_to_user_mode(unsigned long pc) { struct pt_regs *regs = task_pt_regs(current); memzero((unsigned long)regs, sizeof(*regs)); regs->pc = pc; regs->pstate = PSR_MODE_EL0t; unsigned long stack = get_free_page(); //allocate new user stack if (!stack) { return -1; } regs->sp = stack + PAGE_SIZE; current->stack = stack; return 0; } pt_regs: the exception stack frame In the previous experiment: when an interrupt happens, kernel_entry saves CPU context to a stack frame marked as \"saved regs\", which is somewhere in the middle of a kernel task's stack. Dump pt_regs in GDB: ``` p /x (struct pt_regs )((char *)current + 4096 - sizeof(struct pt_regs)) $7 = { regs = {[0x0] = 0x401fd0, [0x1] = 0x0, [0x2] = 0x401fe7, [0x3] = 0x401f40, [0x4] = 0x0 , [0x1d] = 0x401fc0, [0x1e] = 0x8088c}, sp = 0x401fc0, pc = 0x830cc, pstate = 0x60000000 } ``` Check where syscall happens: ``` info line *0x830cc Line 7 of \"src/sys.S\" starts at address 0x830cc and ends at 0x830d0 . ``` In this experiment, our kernel will additionally handle sync exceptions (syscalls). When a syscall happens, the CPU will create a stack frame in the same format called pt_regs . The name comes from Linux again. When syscall returns, the kernel unwinds pt_regs . For the first time return to EL0, move_to_user_mode() sets up pt_regs : pt_regs.pc This is the first instruction to be executed by the task once it lands in user mode via eret . pstate . This specifies the CPU state for the task. Later, kernel_exit copies this field to spsr_el1 . eret restores the CPU state from pstate . PSR_MODE_EL0t constant specifies that we will go to EL0. See manual . Furthermore, move_to_user_mode allocates a new page for the user stack and sets sp field to point to the page top. Where is pt_regs? It is at the top of the stack. See the figure above. Right before kernel_exit() , the task's stack is unwound just to the beginning of pt_regs . Therefore, kernel_exit() will restore CPU regs from the stack. task_pt_regs() calculates the address of a task's pt_regs . See the code below which is self-evident. Recall that THREAD_SIZE == 4KB which is the memory size for the task. struct pt_regs * task_pt_regs(struct task_struct *tsk){ unsigned long p = (unsigned long)tsk + THREAD_SIZE - sizeof(struct pt_regs); return (struct pt_regs *)p; } ret_from_fork(), augmented New addition is made to the middle of the ret_from_fork function: .globl ret_from_fork ret_from_fork: bl schedule_tail cbz x19, ret_to_user // not a kernel thread mov x0, x20 blr x19 ret_to_user: bl disable_irq kernel_exit 0 Why are x19 and x20? That is where copy_process() saves the fn and arg specified for a new user process. Now, after a kernel thread finishes, the execution jumps to ret_to_user , where it disables interrupts and performs exception return (kernel_exit), using previously prepared processor state. If you get confused, revisit the \"overview\" figure: Exiting a task Each user task calls the exit syscall at the end of its life cycle. In the current implementation, the call_sys_clone wrapper calls exit ; see above. Into the kernel, exit syscall goes to exit_process() , which deactivates a task. The function is listed below. void exit_process(){ preempt_disable(); for (int i = 0; i < NR_TASKS; i++){ if (task[i] == current) { task[i]->state = TASK_ZOMBIE; break; } } if (current->stack) { free_page(current->stack); } preempt_enable(); schedule(); } Following Linux convention, we are not deleting the task at once but set its state to TASK_ZOMBIE instead. This prevents the task from being selected and executed by the scheduler. In Linux such approach is used to allow parent process to query information about the child even after it finishes. exit_process also deletes now unnecessary user stack and calls schedule . After schedule is called new task will be selected, that's why this system call never returns. Conclusion Now that the kernel can manage user tasks, we become much closer to the full process isolation. But one important step is still missing: all user tasks share the same physical memory and can easily read one another's data. In the next lesson, we are going to introduce virtual memory and fix this issue.","title":"exp5"},{"location":"lesson05/rpi-os/#5-user-processes-and-system-calls","text":"","title":"5: User processes and system calls"},{"location":"lesson05/rpi-os/#objectives","text":"Our kernel is evolving from an \"embedded\" kernel which often lacks user/kernel separation to a multiprogrammed kernel. Run tasks in EL0 Add the syscall mechanism Implement a few basic syscalls NOTE: this experiment enables running user/kernel at different ELs. Yet, it does not NOT give each task its own address space \u2014 we are going to tackle this issue in lesson 6! Source code location: p1-kernel/src/lesson05","title":"Objectives"},{"location":"lesson05/rpi-os/#roadmap","text":"Implement the syscall mechanism, in particular switch between EL0 and EL1 (you have already done something similar in previous experiments!) Implement two mechanisms that put user tasks to EL0: forking an existing user task at EL0 moving a kernel task EL1 -> EL0","title":"Roadmap"},{"location":"lesson05/rpi-os/#syscall-implementation","text":"Each system call is a synchronous exception. A user program prepares all necessary arguments, and then run svc instruction. Such exceptions are handled at EL1 by the kernel. The kernel validates all arguments, does the syscall, and exists from the exception. After that, the user task resumes at EL0 right after the svc instruction. We have 4 simple syscalls: write outputs to UART. It accepts a buffer with the text to be printed as the first argument. clone creates a new user thread. The location of the stack for the newly created thread is passed as the first argument. malloc allocates a memory page for a user process. There is no analog of this syscall in Linux (and I think in any other OS as well.) The only reason that we have no virtual memory yet, and all user processes work with physical memory. Each process needs a way to figure out which memory page can be used. malloc syscall return pointer to the newly allocated page or -1 in case of an error. exit Each process must call this syscall after it finishes execution. It will do cleanup. All syscalls are defined in sys.c . There is also an array sys_call_table that contains pointers to all syscall handlers. Each syscall has a \"syscall number\" \u2014 this is just an index in the sys_call_table array. All syscall numbers are defined here \u2014 they are used by the assembler code to look up syscall. Let's use write syscall as an example: //sys.S, executed at the user level .globl call_sys_write call_sys_write: mov w8, #SYS_WRITE_NUMBER svc #0 ret Simple -- the wrapper stores the syscall number in the w8 register and does svc . Convention: registers x0 \u2014 x7 are used for syscall arguments and x8 is used to store syscall number. This allows a syscall to have up to 8 arguments. In commodity OSes, such wrapper functions are usually in user library such as glibc but not in the kernel.","title":"Syscall implementation"},{"location":"lesson05/rpi-os/#switching-between-el0-and-el1","text":"We need this new mechanism. It's in the same spirit as we move from EL2/3 to EL1. (Recall: how did we do it?) Previously, our kernel runs at EL1; when an interrupt occurs, it takes the interrupt at EL1. Now, we need to take exception (svc) from EL0 to EL1. To accommodate this, both kernel_entry and kernel_exit macros accepts an additional argument el , indicating the EL an exception is taken from. The information is required to properly save/restore stack pointer. Here are the two relevant parts from the kernel_entry and kernel_exit macros. // kernel_entry .if \\el == 0 mrs x21, sp_el0 .else add x21, sp, #S_FRAME_SIZE .endif // kernel_exit .if \\el == 0 msr sp_el0, x21 .endif ... eret Even for the same task, we are using 2 distinct stacks for EL0 and EL1. This is a common design because we want to separate user/kernel. Supported by CPU hardware, after taking an exception from EL0 to EL1, the CPU automatically starts use the SP for EL1. The SP for EL0 can be found in the sp_el0 register. The value of this register must be stored and restored upon entering/exiting the kernel, even if the kernel does not use sp_el0 in the exception handler. Reason: we need to virtualize sp_el0 for each task because each task has its own user stack. Try to visualize this in your mind. When we do kernel_exit , how do we specify which EL to return to, EL0 or EL1? This EL level is encoded in the spsr_el1 register that was saved, e.g. when syscall enters the kernel. So we always return to the level from which the exception was taken. How did we treat SP when taking interrupts (from EL1)? Revisit the figures in previous experiments.","title":"Switching between EL0 and EL1"},{"location":"lesson05/rpi-os/#handling-synchronous-exceptions","text":"In the exception table, el0_sync is registered as the handler for sync exception taken at EL0. // entry.S el0_sync: kernel_entry 0 mrs x25, esr_el1 // read the syndrome register lsr x24, x25, #ESR_ELx_EC_SHIFT // exception class cmp x24, #ESR_ELx_EC_SVC64 // SVC in 64-bit state b.eq el0_svc handle_invalid_entry 0, SYNC_ERROR As for all exception handlers, kernel_entry macro is called. esr_el1 (Exception Syndrome Register) is checked. This register contains \"exception class\" field at offset ESR_ELx_EC_SHIFT . If exception class is equal to ESR_ELx_EC_SVC64 this means that the current exception is caused by the svc instruction and it is a system call. In this case, we jump to el0_svc label and show an error message otherwise. sc_nr .req x25 // number of system calls scno .req x26 // syscall number stbl .req x27 // syscall table pointer el0_svc: adr stbl, sys_call_table // load syscall table pointer uxtw scno, w8 // syscall number in w8 mov sc_nr, #__NR_syscalls bl enable_irq cmp scno, sc_nr // check upper syscall limit b.hs ni_sys ldr x16, [stbl, scno, lsl #3] // address in the syscall table blr x16 // call sys_* routine b ret_from_syscall ni_sys: handle_invalid_entry 0, SYSCALL_ERROR el0_svc first loads the address of the syscall table in the stbl (it is just an alias to the x27 register.) and syscall number in the scno variable. Then interrupts are enabled and syscall number is compared to the total number of syscalls in the system \u2014 if it is greater or equal an error message is shown. If syscall number falls within the required range, it is used as an index in the syscall table array to obtain a pointer to the syscall handler. Next, the handler is executed and after it finishes ret_from_syscall is called. Note, that we don't touch here registers x0 \u2013 x7 \u2014 they are transparently passed to the handler. (Why?) Fast forward to the completion of syscall. ret_from_syscall: bl disable_irq str x0, [sp, #S_X0] // returned x0 kernel_exit 0 ret_from_syscall first disables interrupts. Then it saves the value of x0 register on the stack. This is required because kernel_exit will restore all general purpose registers from their saved values, but x0 now contains return value of the syscall handler and we want this value to be passed to the user code. Finally kernel_exit is called, which returns to the user code.","title":"Handling synchronous exceptions"},{"location":"lesson05/rpi-os/#executing-a-task-in-user-mode","text":"Atop that, the kernel implements two complementary ways for launching a user process. Overview:","title":"Executing a task in user mode"},{"location":"lesson05/rpi-os/#method-1-forking-user-processes","text":"At the user level, user_process() calls call_sys_clone to spawn a new task. // sys.S .globl call_sys_clone call_sys_clone: /* Save args for the child. They will be preserved throughout syscall */ mov x10, x0 /*fn*/ mov x11, x1 /*arg*/ mov x12, x2 /*stack*/ /* Prep syscall args. Do the system call. */ mov x0, x2 /* stack */ mov x8, #SYS_CLONE_NUMBER svc 0x0 cmp x0, #0 beq thread_start ret thread_start: mov x29, 0 /* Pick up the function arg and execute. */ mov x0, x11 blr x10 /* We are done, pass the return value through x0. */ mov x8, #SYS_EXIT_NUMBER svc 0x0 The clone wrapper above mimics the coresponding function from in the glibc library. x0-x3 contain syscall arguments. They are intended for the child task. Save fn and arg to x10-x11. Why? The kernel syscall handler el0_svc does not preserve x0-x3. The new task will pick up x10 and x11 in thread_start . Save the pointer to the new task's stack in x2, as expected by sys_clone(unsigned long stack) . Starts syscall via svc . Upon returning from syscall, checks return value in x0: if 0, we are executing inside the child task. In this case, execution goes to thread_start label. If not 0, we are executing in the parent task. x0 is the PID of the child task. thread_start executes in the new task with the give entry function (x10) and the arg to the function (x11). Note x29 (FP) is cleared for correct stack unwinding at the user level. See here . After the function finishes, exit syscall is performed \u2014 it never returns.","title":"Method 1: Forking user processes"},{"location":"lesson05/rpi-os/#implementing-clone-in-kernel","text":"Inside the kernel, clone() goes to is sys_clone() (sys.c). It just calls copy_process() . This function, however, has been modified since the last lesson. int copy_process(unsigned long clone_flags, unsigned long fn, unsigned long arg, unsigned long stack) { preempt_disable(); struct task_struct *p; p = (struct task_struct *) get_free_page(); if (!p) { return -1; } struct pt_regs *childregs = task_pt_regs(p); memzero((unsigned long)childregs, sizeof(struct pt_regs)); memzero((unsigned long)&p->cpu_context, sizeof(struct cpu_context)); // new addition if (clone_flags & PF_KTHREAD) { p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; } else { struct pt_regs * cur_regs = task_pt_regs(current); *childregs = *cur_regs; childregs->regs[0] = 0; childregs->sp = stack + PAGE_SIZE; p->stack = stack; } p->flags = clone_flags; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->preempt_count = 1; //disable preemtion until schedule_tail p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)childregs; int pid = nr_tasks++; task[pid] = p; preempt_enable(); return pid; } If creating a new kernel thread, the function does the same thing as before. If creating a user thread, the function takes care of pt_regs as it is unique to a user thread -- the state saved/restored upon entering/exiting the kernel. struct pt_regs * cur_regs = task_pt_regs(current); *childregs = *cur_regs; childregs->regs[0] = 0; childregs->sp = stack + PAGE_SIZE; p->stack = stack; We populate the CPU context, i.e. pt_regs , for the new task. Note that pt_regs is always at the top of the stack page (recall the figure above), because when syscall enters/exits the kernel, the kernel stack is empty. x0 in the new state is set to 0 , because x0 will be the return value of the clone syscall. We've just seen how clone wrapper function uses this value to determine whether we are in the parent or the child task. Next sp for the new task is set to point to the top of the new user stack page. We also save the pointer to the stack page in order to do a cleanup after the task finishes.","title":"Implementing clone in kernel"},{"location":"lesson05/rpi-os/#method-2-moving-an-existing-kernel-task-to-el0","text":"Overview: upon its creation, the kernel task calls its main function, kernel_process() , which calls move_to_user_mode() . The later prepares CPU context for exiting to EL0. Then kernel_process() returns to ret_from_fork which invokes the familiar kernel_exit . Eventually, an eret instruction - boom! We land in EL0. Code walkthrough First create a process (i.e. a task) as we did before. This is a \"kernel\" process to execute at EL1. // kernel.c int res = copy_process(PF_KTHREAD, (unsigned long)&kernel_process, 0, 0); The kernel process invokes move_to_user_mode() , passing a function pointer to the user_process as the first argument. void kernel_process() { printf(\"Kernel process started. EL %d\\r\\n\", get_el()); int err = move_to_user_mode((unsigned long)&user_process); ... The move_to_user_mode function prepares pt_regs and the user stack, so the kernel process becomes a \"legit\" user process. int move_to_user_mode(unsigned long pc) { struct pt_regs *regs = task_pt_regs(current); memzero((unsigned long)regs, sizeof(*regs)); regs->pc = pc; regs->pstate = PSR_MODE_EL0t; unsigned long stack = get_free_page(); //allocate new user stack if (!stack) { return -1; } regs->sp = stack + PAGE_SIZE; current->stack = stack; return 0; } pt_regs: the exception stack frame In the previous experiment: when an interrupt happens, kernel_entry saves CPU context to a stack frame marked as \"saved regs\", which is somewhere in the middle of a kernel task's stack. Dump pt_regs in GDB: ``` p /x (struct pt_regs )((char *)current + 4096 - sizeof(struct pt_regs)) $7 = { regs = {[0x0] = 0x401fd0, [0x1] = 0x0, [0x2] = 0x401fe7, [0x3] = 0x401f40, [0x4] = 0x0 , [0x1d] = 0x401fc0, [0x1e] = 0x8088c}, sp = 0x401fc0, pc = 0x830cc, pstate = 0x60000000 } ``` Check where syscall happens: ``` info line *0x830cc Line 7 of \"src/sys.S\" starts at address 0x830cc and ends at 0x830d0 . ``` In this experiment, our kernel will additionally handle sync exceptions (syscalls). When a syscall happens, the CPU will create a stack frame in the same format called pt_regs . The name comes from Linux again. When syscall returns, the kernel unwinds pt_regs . For the first time return to EL0, move_to_user_mode() sets up pt_regs : pt_regs.pc This is the first instruction to be executed by the task once it lands in user mode via eret . pstate . This specifies the CPU state for the task. Later, kernel_exit copies this field to spsr_el1 . eret restores the CPU state from pstate . PSR_MODE_EL0t constant specifies that we will go to EL0. See manual . Furthermore, move_to_user_mode allocates a new page for the user stack and sets sp field to point to the page top. Where is pt_regs? It is at the top of the stack. See the figure above. Right before kernel_exit() , the task's stack is unwound just to the beginning of pt_regs . Therefore, kernel_exit() will restore CPU regs from the stack. task_pt_regs() calculates the address of a task's pt_regs . See the code below which is self-evident. Recall that THREAD_SIZE == 4KB which is the memory size for the task. struct pt_regs * task_pt_regs(struct task_struct *tsk){ unsigned long p = (unsigned long)tsk + THREAD_SIZE - sizeof(struct pt_regs); return (struct pt_regs *)p; }","title":"Method 2: Moving an existing kernel task to EL0"},{"location":"lesson05/rpi-os/#ret_from_fork-augmented","text":"New addition is made to the middle of the ret_from_fork function: .globl ret_from_fork ret_from_fork: bl schedule_tail cbz x19, ret_to_user // not a kernel thread mov x0, x20 blr x19 ret_to_user: bl disable_irq kernel_exit 0 Why are x19 and x20? That is where copy_process() saves the fn and arg specified for a new user process. Now, after a kernel thread finishes, the execution jumps to ret_to_user , where it disables interrupts and performs exception return (kernel_exit), using previously prepared processor state. If you get confused, revisit the \"overview\" figure:","title":"ret_from_fork(), augmented"},{"location":"lesson05/rpi-os/#exiting-a-task","text":"Each user task calls the exit syscall at the end of its life cycle. In the current implementation, the call_sys_clone wrapper calls exit ; see above. Into the kernel, exit syscall goes to exit_process() , which deactivates a task. The function is listed below. void exit_process(){ preempt_disable(); for (int i = 0; i < NR_TASKS; i++){ if (task[i] == current) { task[i]->state = TASK_ZOMBIE; break; } } if (current->stack) { free_page(current->stack); } preempt_enable(); schedule(); } Following Linux convention, we are not deleting the task at once but set its state to TASK_ZOMBIE instead. This prevents the task from being selected and executed by the scheduler. In Linux such approach is used to allow parent process to query information about the child even after it finishes. exit_process also deletes now unnecessary user stack and calls schedule . After schedule is called new task will be selected, that's why this system call never returns.","title":"Exiting a task"},{"location":"lesson05/rpi-os/#conclusion","text":"Now that the kernel can manage user tasks, we become much closer to the full process isolation. But one important step is still missing: all user tasks share the same physical memory and can easily read one another's data. In the next lesson, we are going to introduce virtual memory and fix this issue.","title":"Conclusion"},{"location":"lesson06/rpi-os/","text":"6: Virtual memory (VM) Objectives Make our tiny kernel capable of: enforcing separate virtual address spaces, and user-level demand paging. Roadmap Source code location: p1-kernel/src/lesson06 Prior to this experiment, our kernel can run and schedule user processes, but the isolation between them is not complete - all processes and the kernel itself share the same memory. This allows any process to easily access somebody else's data and even kernel data. And even if we assume that all our processes are not malicious, there is another drawback: before allocating memory each process need to know which memory regions are already occupied - this makes memory allocation for a process more complicated. We take the following steps. Set up a pgtable for kernel. Using linear mapping. Turn on MMU shortly after kernel boots. This is a common kernel design. Set up pgtables for user processes Implement fork() for user processes Implement demand paging Background: ARM64 translation process The Arm's document is well written. (\"Armv8-A Address Translation\", link ) Page table format This experiment introduces VM to our kernel. With VM, we can formally call tasks \"processes\". Each task will have its own address space. They issue memory access with virtual addresses. The MMU transparently translates virtual addresses to physical addresses. The MMU uses page table (or pgtable, or \"translation table\" in ARM's manual). The following diagram summarizes ARM64 address translation with uses 4-level pgtables. Virtual address Physical Memory +-----------------------------------------------------------------------+ +-----------------_+ | | PGD Index | PUD Index | PMD Index | PTE Index | Page offset | | | +-----------------------------------------------------------------------+ | | 63 47 | 38 | 29 | 20 | 11 | 0 | Page N | | | | | +--------------------+ +---->+------------------+ | | | +---------------------+ | | | | +------+ | | | | | | | | | +----------+ | | | |------------------| +------+ | PGD | | | +---------------->| Physical address | |TTBRx |---->+-------------+ | PUD | | | |------------------| +-EL1--+ | | entry #511 | | +->+-------------+ | PMD | | | | | +-------------+ | | | #511 | | +->+-------------+ | PTE | +------------------+ +->| PUD address |----+ +-------------+ | | | #511 | | +->+--------------+ | | | +-------------+ +--->| PMD address |----+ +-------------+ | | | #511 | | | | | entry #0 | +-------------+ +--->| PTE address |----+ +-------------_+ | | | +-------------+ | #0 | +-------------+ +--->| Page address |----+ | | +-------------+ | #0 | +--------------+ | | +-------------+ | #0 | | | +--------------+ +------------------+ Notable points: Page tables have a hierarchical structure, i.e. a tree. An item in any of the tables contains an address of the next table in the hierarchy. Note: strictly speaking a pgtable means a contiguous array of entries at any of the four levels. So a tree has many pgtables. Some documents casually use \"pgtable\" to refer to an entire pgtable tree. Be careful. There are 4 levels in the table hierarchy: PGD (Page Global Directory), PUD (Page Upper Directory), PMD (Page Middle Directory), PTE (Page Table Entry). PTE is the last table in the hierarchy and it points to the actual page in the physical memory. Don't read too much into the terms, which just represent lv1, 2, ... pgtables. Them terms come from the Linux kernel (x86), not ARM64. Over years, they became a common lingo among kernel hackers. Besides holding a physical address, each pgtable item holds extra bits crucial for translation. Will examine the format below. MMU starts memory translation process by locating the base address of PGD. MMU locates the base address from the TTBRx_EL1 register which should be set by the kernel. TTBR = translation table base register. bits [63-47] = 0xffff (all 1s). MMU uses ttbr1_el1 . This is meant for the kernel space. bits [63-47] = 0x0 (all 1s). MMU uses ttbr0_el1 . This is meant for the user process. Each process has its own address space. Therefore, it has its own copy of page table tree, starting from PGD. Therefore, the kernel keeps a separate PGD base address for each process. That is, the kernel virtualizes PGD for processes. During a context switch, the kernel loads the PGD base of the next process to ttbr0_el1 . MMU walks the pgtable tree to look up the physical address. A virtual address uses only 48 out of 64 available bits. When doing a translation, MMU splits an address into 4 parts: 9 bits [39 - 47] contain an index in the PGD table. MMU uses this index to find the location of the PUD. 9 bits [30 - 38] contain an index in the PUD table. MMU uses this index to find the location of the PMD. 9 bits [21 - 29] contain an index in the PMD table. MMU uses this index to find the location of the PTE. 9 bits [12 - 20] contain an index in the PTE table. MMU uses this index to find a page in the physical memory. Bits [0 - 11] contain an offset in the physical page. MMU uses this offset to determine the exact position in the previously found page that corresponds to the original virtual address. Memory for a user process is always allocated in pages. A page is a contiguous memory region 4KB in size (ARM processors support larger pages, but 4KB is the most common case and we are going to limit our discussion only to this page size). Exercise: how large is a page table? From the diagram above we know that index in a page table occupies 9 bits (this is true for all page table levels). This means that each page table contains 2^9 = 512 items. Each item in a page table is an address of either the next page table in the hierarchy or a physical page in case of PTE. As we are using a 64-bit processor, each address must be 64 bit or 8 bytes in size. This means that each pgtable is 512 * 8 = 4096 bytes or 4 KB. A pgtable is exactly a page! This might give you an intuition why MMU designers chose such numbers. Section (2MB) mapping This is specific to ARM64 for mapping large, continuous physical memory. Instead of 4 KB pages, we directly map 2MB blocks called sections. This eliminates one level of translation. The translation diagram, in this case, looks like the following. Virtual address Physical Memory +-----------------------------------------------------------------------+ +-----------------_+ | | PGD Index | PUD Index | PMD Index | Section offset | | | +-----------------------------------------------------------------------+ | | 63 47 | 38 | 29 | 20 | 0 | Section N | | | | | +---->+------------------+ | | | | | | | +------+ | | | | | | | | +----------+ | | |------------------| +------+ | PGD | | +------------------------->| Physical address | | TTBRx|---->+-------------+ | PUD | | |------------------| +--EL1-+ | | | | +->+-------------+ | PMD | | | | +-------------+ | | | | | +->+-----------------+ | +------------------+ +->| PUD address |----+ +-------------+ | | | | | | | +-------------+ +--->| PMD address |----+ +-----------------+ | | | | | +-------------+ +--->| Section address |-----+ | | +-------------+ | | +-----------------+ | | +-------------+ | | | | +-----------------+ | | +------------------+ As you can see the difference here is that now PMD contains a pointer to the physical section. Also, the offset occupies 21 bits instead of 12 bits (this is because we need 21 bits to encode a 2MB range) Page descriptor format An item in a page table is called \"descriptor\". A description has a special format as mandated by MMU hardware. A descriptor contains an address of either next page table or a physical page. The key thing to understand : each descriptor always points to something that is page-aligned (either a physical page, a section or the next page table in the hierarchy). This means that last 12 bits of the address, stored in a descriptor, will always be 0. MMU uses those bits to store additional information (\"attributes\") for translation. Descriptor format `+------------------------------------------------------------------------------------------+ | Upper attributes | Address (bits 47:12) | Lower attributes | Block/table bit | Valid bit | +------------------------------------------------------------------------------------------+ 63 47 11 2 1 0 Bit 0 This bit must be set to 1 for all valid descriptors. If MMU encounter non-valid descriptor during translation process a synchronous exception is generated. If this invalid bit was set by kernel on purpose, the kernel shall handle this exception, allocate a new page, and prepare a correct descriptor (We will look in details on how this works a little bit later) Bit 1 This bit indicates whether the current descriptor points to a next page table in the hierarchy (we call such descriptor a \" table descriptor \") or it points instead to a physical page or a section (such descriptors are called \" block descriptors \"). Bits [11:2] Those bits are ignored for table descriptors. For block descriptors they contain some attributes that control, for example, whether the mapped page is readable/writeable (AP), executable (XN), etc. Here also comes the MemAttr bits. See below. Bits [47:12] . This is the place where the address that a descriptor points to is stored. As I mentioned previously, only bits [47:12] of the address need to be stored, because all other bits are always 0. Bits [63:48] Another set of attributes. See Arm's official page . Configuring page attributes As I mentioned in the previous section, each block descriptor contains a set of attributes (called MemAttr, bits[5:2]) that controls various virtual page parameters, notably cacheability or shareability. However, the attributes that are most important for our discussion are NOT encoded in the descriptor. Instead, ARM processors implement a trick for compressing descriptor attributes commonly used. (The days of simpler ARM hardware were gone) Memory attribute indirection ARMv8 architecture introduces mair_el1 register. See its definition . This register consists of 8 slots, each spanning 8 bits. Each slot configures a common set of attributes. A descriptor then specifies just an index of the mair slot, instead of specifying all attributes directly. This allows using only 3 bits in the descriptor to reference a mair slot. We are using only a few of available attribute options. Here is the code that prepares values for the mair register. /* * Memory region attributes: * * n = AttrIndx[2:0] * n MAIR * DEVICE_nGnRnE 000 00000000 * NORMAL_NC 001 01000100 */ #define MT_DEVICE_nGnRnE 0x0 #define MT_NORMAL_NC 0x1 #define MT_DEVICE_nGnRnE_FLAGS 0x00 #define MT_NORMAL_NC_FLAGS 0x44 #define MAIR_VALUE (MT_DEVICE_nGnRnE_FLAGS << (8 * MT_DEVICE_nGnRnE)) | (MT_NORMAL_NC_FLAGS << (8 * MT_NORMAL_NC)) Here we are using only 2 out of 8 available slots in the mair registers. The first one corresponds to device memory (IO registers) and second to normal non-cacheable memory. MT_DEVICE_nGnRnE and MT_NORMAL_NC are indexes that we are going to use in block descriptors, MT_DEVICE_nGnRnE_FLAGS and MT_NORMAL_NC_FLAGS are values that we are storing in the first 2 slots of the mair_el1 register. Kernel vs user virtual memory After the MMU is switched on, each memory access issued by kernel must use virtual address instead of physical. One consequence is that the kernel itself must maintain its own set of page tables. One possible solution could be to reload ttbr (pointing to the PGD base) each time we switch from user to kernel mode. Reloading ttbr can be costly. (Why?) This makes syscalls and page faults expensive. Commodity kernels therefore avoid frequent reloads of PGD base. A kernel splits the virtual address space into 2 parts: user portion and kernel portion. When switching among user tasks, the kernel only changes the mapping of the user portion while keeping the kernel mapping unchanged. This classic kernel design turns out to lead to most severe security holes in recent years. Google \"spectre and meltdown\". On 32-bit CPUs, a kernel usually allocate first 3 GB of the address space for user and reserve last 1 GB for the kernel. 64-bit architectures are much more favorable in this regard because of huge virtual address space (how large?). And even more: ARMv8 architecture comes with a native feature that can be used to easily implement user/kernel address split. ARM64 defines 2 TTBR registers for holding PGD base addresses: TTBR0_EL1 points to a user PGD; TTBR1_EL1 points to the kernel PGD. MMU uses only 48 bits out of 64 bits in the virtual addresses for translation. MMU uses the upper 16 bits in a given virtual address to decide whether it uses TTBR0 or TTBR1. User virtual addresses : upper 16 bits == 0. MMU uses the PGD base stored in TTBR0_EL1. This value shall be changed according to process switch. Kernel virtual addresses : upper 16 bits == 0xffff . MMU uses the PGD base stored in TTBR1_EL1. This value shall remain unchanged throughout the life of the kernel. The CPU also enforces that software at EL0 can never access virtual addresses started with 0xffff . Doing so triggers a synchronous exception. Here is a picture the memory layout. Source: Arm's document \"ARMv8-A Address Translation\". Adjusting kernel addresses All absolute kernel addresses must start with 0xffff... . There are 2 places in the kernel source code shall be changed. In the linker script we specify base address of the image as 0xffff000000000000 . This will make the linker think that our image is going to be loaded at 0xffff000000000000 address, and therefore whenever it needs to generate an absolute address it will make it right. (There are a few more changes to the linker script, but we will discuss them later.) We hardcode absolute kernel base addresses in the header where we define device base address. After switching on MMU, kernel has to access all IO via virtual addresses. We can map them starting from 0xffff00003F000000 . In the next section we will explore in detail the code that creates this mapping. Kernel boot: initializing kernel page tables Important: the linker is completely oblivious to kernel physical address , e.g. the physical base (0x0 or 0x80000) where the kernel will be loaded. Two Implications: the linker links all kernel symbols at virtual addresses starting from 0xffff000000000000 ; Before kernel boots and before it turns on MMU, the kernel will operate on physical addresses starting from 0x0 (or 0x80000 for QEMU). Keep this key constraint in mind. See below. Right after kernel switches to EL1 and clears the BSS, the kernel populates its pgtables via __create_page_tables function. // boot.S __create_page_tables: mov x29, x30 // save return address First, the function saves x30 (LR). As we are going to call other functions from __create_page_tables , x30 will be overwritten. As we know that no code will use x29 during __create_page_tables execution, preserving LR in x29 works fine. Q: What could go wrong if we push x30 to stack here? adrp x0, pg_dir // adrp: form PC-relative address to 4KB page mov x1, #PG_DIR_SIZE bl memzero Next, we clear the initial page tables area. An important thing to understand here is where this area is located (x0) and how do we know its size (x1)? Initial page tables area is defined in the linker script - this means that we are allocating the spot for this area in the kernel image itself. Calculating the size of this area is a little bit trickier. First, we need to understand the structure of the initial kernel page tables. We know that all our mappings are all inside 1 GB region (this is the size of RPi3 physical memory). One PGD descriptor can cover 2^39 = 512 GB and one PUD descriptor can cover 2^30 = 1 GB of continuous virtual mapping area. (Those values are calculated based on the PGD and PUD indexes location in the virtual address.) This means that we need just one PGD and one PUD to map the whole RPi memory, and even more - both PGD and PUD will contain a single descriptor (of course we still need to allocate at least one page for them each). If we have a single PUD entry there also must be a single PMD table, to which this entry will point. (Single PMD entry covers 2 MB, there are 512 items in a PMD, so in total the whole PMD table covers the same 1 GB of memory that is covered by a single PUD descriptor.) Next, we know that we need to map 1 GB region of memory, which is a multiple of 2 MB. This allows us to keep things simple -- using section mapping. This means that we don't need PTE at all. So in total, we need 3 pages: one for PGD, PUD and PMD - this is precisely the size of the initial page table area. Q: here, MMU is off and everything should be physical address. How could the kernel possibly address functions/variables like memzero, which are linked at virtual addresses? (Hint: check the disassembly of the kernel binary) Allocating & installing a new pgtable Now we are going to step outside __create_page_tables function and take a look on 2 essential macros: create_table_entry and create_block_map . create_table_entry is responsible for allocating a new page table (In our case either PGD or PUD) The source code is listed below. .macro create_table_entry, tbl, virt, shift, tmp1, tmp2 lsr \\tmp1, \\virt, #\\shift and \\tmp1, \\tmp1, #PTRS_PER_TABLE - 1 // table index add \\tmp2, \\tbl, #PAGE_SIZE orr \\tmp2, \\tmp2, #MM_TYPE_PAGE_TABLE str \\tmp2, [\\tbl, \\tmp1, lsl #3] add \\tbl, \\tbl, #PAGE_SIZE // next level table page .endm This macro accepts the following arguments. tbl - a pointer to a memory region where new table has to be allocated. virt - virtual address that we are currently mapping. shift - shift that we need to apply to the virtual address in order to extract current table index. (39 in case of PGD and 30 in case of PUD) tmp1 , tmp2 - temporary registers. This macro is very important, so we are going to spend some time understanding it. lsr \\tmp1, \\virt, #\\shift and \\tmp1, \\tmp1, #PTRS_PER_TABLE - 1 // table index The first two lines of the macro are responsible for extracting table index from the virtual address. We are applying right shift first to strip everything to the right of the index and then using and operation to strip everything to the left. add \\tmp2, \\tbl, #PAGE_SIZE Then the address of the next page table is calculated. Here we are using the convention that all our initial page tables are located in one continuous memory region. We simply assume that the next page table in the hierarchy will be adjacent to the current page table. orr \\tmp2, \\tmp2, #MM_TYPE_PAGE_TABLE Next, a pointer to the next page table in the hierarchy is converted to a table descriptor. (A descriptor must have 2 lower bits set to 1 ) str \\tmp2, [\\tbl, \\tmp1, lsl #3] Then the descriptor is stored in the current page table. We use previously calculated index to find the right spot in the table. add \\tbl, \\tbl, #PAGE_SIZE // next level table page Finally, we change tbl parameter to point to the next page table in the hierarchy. This is convenient because now we can call create_table_entry one more time for the next table in the hierarchy without making any adjustments to the tbl parameter. This is precisely what we are doing in the create_pgd_entry macro, which is just a wrapper that allocates both PGD and PUD. Populating a PMD table Next important macro is create_block_map . As you might guess this macro is responsible for populating entries of the PMD table. It looks like the following. .macro create_block_map, tbl, phys, start, end, flags, tmp1 lsr \\start, \\start, #SECTION_SHIFT and \\start, \\start, #PTRS_PER_TABLE - 1 // table index lsr \\end, \\end, #SECTION_SHIFT and \\end, \\end, #PTRS_PER_TABLE - 1 // table end index lsr \\phys, \\phys, #SECTION_SHIFT mov \\tmp1, #\\flags orr \\phys, \\tmp1, \\phys, lsl #SECTION_SHIFT // table entry 9999: str \\phys, [\\tbl, \\start, lsl #3] // store the entry add \\start, \\start, #1 // next entry add \\phys, \\phys, #SECTION_SIZE // next block cmp \\start, \\end b.ls 9999b .endm Parameters here are a little bit different. tbl - a pointer to the PMD table. phys - the start of the physical region to be mapped. start - virtual address of the first section to be mapped. end - virtual address of the last section to be mapped. flags - flags that need to be copied into lower attributes of the block descriptor. tmp1 - temporary register. Now, let's examine the source. lsr \\start, \\start, #SECTION_SHIFT and \\start, \\start, #PTRS_PER_TABLE - 1 // table index Those 2 lines extract the table index from start virtual address. This is done exactly in the same way as we did it before in the create_table_entry macro. lsr \\end, \\end, #SECTION_SHIFT and \\end, \\end, #PTRS_PER_TABLE - 1 // table end index The same thing is repeated for the end address. Now both start and end contains not virtual addresses, but indexes in the PMD table, corresponding to the original addresses. lsr \\phys, \\phys, #SECTION_SHIFT mov \\tmp1, #\\flags orr \\phys, \\tmp1, \\phys, lsl #SECTION_SHIFT // table entry Next, block descriptor is prepared and stored in the tmp1 variable. In order to prepare the descriptor phys parameter is first shifted to right then shifted back and merged with the flags parameter using orr instruction. If you wonder why do we have to shift the address back and forth - the answer is that this clears first 21 bit in the phys address and makes our macro universal, allowing it to be used with any address, not just the first address of the section. 9999: str \\phys, [\\tbl, \\start, lsl #3] // store the entry add \\start, \\start, #1 // next entry add \\phys, \\phys, #SECTION_SIZE // next block cmp \\start, \\end b.ls 9999b // jump back if \"Unsigned Less than or equal\" The final part of the function is executed inside a loop. Here we first store current descriptor at the right index in the PMD table. Next, we increase current index by 1 and update the descriptor to point to the next section. We repeat the same process until current index becomes equal to the last index. Putting it together: __create_page_tables() Now, when you understand how create_table_entry and create_block_map macros work, it will be straightforward to understand the rest of the __create_page_tables function. adrp x0, pg_dir mov x1, #VA_START create_pgd_entry x0, x1, x2, x3 Here we create both PGD and PUD. We configure them to start mapping from VA_START virtual address. Because of the semantics of the create_table_entry macro, after create_pgd_entry finishes x0 will contain the address of the next table in the hierarchy - namely PMD. /* Mapping kernel and init stack*/ mov x1, xzr // start mapping from physical offset 0 mov x2, #VA_START // first virtual address ldr x3, =(VA_START + DEVICE_BASE - SECTION_SIZE) // last virtual address create_block_map x0, x1, x2, x3, MMU_FLAGS, x4 Next, we create virtual mapping of the whole memory, excluding device registers region. We use MMU_FLAGS constant as flags parameter - this marks all sections to be mapped as normal noncacheable memory. (Note, that MM_ACCESS flag is also specified as part of MMU_FLAGS constant. Without this flag each memory access will generate a synchronous exception.) /* Mapping device memory*/ mov x1, #DEVICE_BASE // start mapping from device base address ldr x2, =(VA_START + DEVICE_BASE) // first virtual address ldr x3, =(VA_START + PHYS_MEMORY_SIZE - SECTION_SIZE) // last virtual address create_block_map x0, x1, x2, x3, MMU_DEVICE_FLAGS, x4 Then device registers region is mapped. This is done exactly in the same way as in the previous code sample, with the exception that we are now using different start and end addresses and different flags. mov x30, x29 // restore return address ret Finally, the function restored link register and returns to the caller. Configuring page translation Now page tables are created and we are back to the el1_entry function. But there is still some work to be done before we can switch on the MMU. mov x0, #VA_START add sp, x0, #LOW_MEMORY We are updating init task stack pointer. Now it uses a virtual address, instead of a physical one. Therefore it could be used only after MMU is on. Recall that our kernel uses linear mapping therefore an offset is simply applied. adrp x0, pg_dir msr ttbr1_el1, x0 ttbr1_el1 is updated to point to the previously populated PGD table. Q: Isn't pg_dir a virtual address (e.g. ffff000000083000) set by the linker? ttbr shall expect a physical address, right? How could this work? ldr x0, =(TCR_VALUE) msr tcr_el1, x0 tcr_el1 of Translation Control Register is responsible for configuring some general parameters of the MMU. (For example, here we configure that both kernel and user page tables should use 4 KB pages.) ldr x0, =(MAIR_VALUE) msr mair_el1, x0 We already discussed mair register in the \"Configuring page attributes\" section. Here we just set its value. ldr x2, =kernel_main mov x0, #SCTLR_MMU_ENABLED msr sctlr_el1, x0 // BOOM! br x2 msr sctlr_el1, x0 is the line where MMU is actually enabled. Now we can jump to the kernel_main function. From this moment onward kernel runs on virtual addresses completely. An interesting question is why can't we just execute br kernel_main instruction? Indeed, we can't. Before the MMU was enabled we have been working with physical memory, the kernel is loaded at a physical offset 0 - this means that current program counter (PC) is very close to 0. Switching on the MMU doesn't update PC. br kernel_main uses offset relative to the current PC and jumps to the place were kernel_main would have been if we don't turn on the MMU. Example: in generating the kernel binary, the linker starts from base address 0xffff000000000000 as controlled by our linker script. It assigns the instruction \"br kernel_main\" to address 0xffff000000000080; it assigns kernel_main to 0xffff000000003190. The instruction \"br kernel_main\" will be a relative jump, and will be emitted as \"br #0x3110\" (we can verify this by disassembling the kernel binary). At run time, when we reach \"br kernel_main\", PC is 0x80. Executing the instruction will update PC is to 0x3190. As MMU is on now, CPU fetches instruction at 0x3190 via MMU. A translation fault! ldr x2, =kernel_main does not suffer from the problem. CPU loads x2 with the link address of kernel_main , e.g. 0xffff000000003190. Different from br kernel_main which uses PC-based offset, br x2 jumps to an absolute address stored in x2 (this is called long jmp). Therefore, PC will be updated with the link address of kernel_main which can be translated via MMU. In other words, by executing a long jmp, we \"synchronize\" the PC value with virtual addresses. Another question: why ldr x2, =kernel_main itself must be executed before we turn on the MMU? The reason is that ldr also uses pc relative offset. See the manual . On my build, it emitted as ldr x2, #0x10c . So if we execute this instruction after MMU is on but before we \"synchronize\" PC, MMU will give another translation fault. Compiling & loading user programs Commodity kernels load user programs as ELF from filesystems. We won't be building a filesystem or ELF loader in this experiment. As a workaround, we will embed user programs in the kernel binary at link time, and load them at run time. For easy loading, we will store the user program in a separate ELF section of the kernel binary. Here is the relevant section of the linker script that is responsible for doing this. . = ALIGN(0x00001000); user_begin = .; .text.user : { build/user* (.text) } .rodata.user : { build/user* (.rodata) } .data.user : { build/user* (.data) } .bss.user : { build/user* (.bss) } user_end = .; I made a convention: user level source code should be defined in C source files named as \"userXXX\". The linker script then can isolate all user related code in a continuous region, of which the start and end are marked with user_begin and user_end symbols. At run time, the kernel simply copies everything between user_begin and user_end to the newly allocated process address space, thus simulating loading a user program. A simple hack, but suffice for our current purpose. Aside: our user symbol addresses As user programs will be linked as part the kernel binary, the linker will place all user symbols (functions & variables) in the kernel's address space (0xffff000000000000 onwards). You can verify this by, e.g. nm kernel8.elf|grep \" user_\" . How could such user programs work? We rely on an assumption: our user programs are simple enough; they always address memory with register-relative offsets but not absolute address. You can verify this by disassembly. However, if our programs, e.g. call functions via pointers, the entailed long jmp will target absolute virtual address inside kernel and will trigger exception. This assumption can't go a long way. The right solution would be linking user programs and kernel separately. Right now there are 2 files that are compiled in the user region. user_sys.S This file contains definitions of the syscall wrapper functions. The RPi OS still supports the same syscalls as in the previous lesson, with the exception that now instead of clone syscall we are going to use fork syscall. The difference is that fork copies process virtual memory, and that is something we want to try doing. user.c User program source code. Almost the same as we've used in the previous lesson. Creating first user process As it was the case in the previous lesson, move_to_user_mode function is responsible for creating the first user process. We call this function from a kernel thread. Here is how we do this. void kernel_process(){ printf(\"Kernel process started. EL %d\\r\\n\", get_el()); unsigned long begin = (unsigned long)&user_begin; unsigned long end = (unsigned long)&user_end; unsigned long process = (unsigned long)&user_process; int err = move_to_user_mode(begin, end - begin, process - begin); if (err < 0){ printf(\"Error while moving process to user mode\\n\\r\"); } } Now we need 3 arguments to call move_to_user_mode : a pointer to the beginning of the user code area, size of the area and offset of the startup function inside it. This information is calculated based on the previously discussed user_begin and user_end symbols (as global variables). move_to_user_mode function is listed below. int move_to_user_mode(unsigned long start, unsigned long size, unsigned long pc) { struct pt_regs *regs = task_pt_regs(current); regs->pstate = PSR_MODE_EL0t; regs->pc = pc; regs->sp = 2 * PAGE_SIZE; unsigned long code_page = allocate_user_page(current, 0); if (code_page == 0) { return -1; } memcpy(code_page, start, size); set_pgd(current->mm.pgd); return 0; } Now let's try to inspect in details what is going on here. struct pt_regs *regs = task_pt_regs(current); As it was the case in the previous lesson, we obtain a pointer to pt_regs area and set pstate , so that after kernel_exit we will end up in EL0. regs->pc = pc; pc now points to the offset of the startup function in the user region. regs->sp = 2 * PAGE_SIZE; We made a simple convention that our user program will not exceed 1 page in size. We allocate the second page to the stack. unsigned long code_page = allocate_user_page(current, 0); if (code_page == 0) { return -1; } allocate_user_page reserves 1 memory page and maps it to the virtual address, provided as a second argument. In the process of mapping it populates page tables, associated with the current process. We will investigate in details how this function works later in this chapter. memcpy(code_page, start, size); Next, we are going to copy the whole user region to the new address space (in the page that we have just mapped), starting from offset 0, so the offset in the user region will become an actual virtual address of the starting point. set_pgd(current->mm.pgd); Finally, we call set_pgd , which updates ttbr0_el1 register and thus activate cu4rrent process translation tables. Aside: TLB If you take a look at the set_pgd function you will see that after it sets ttbr0_el1 it also clears TLB (Translation lookaside buffer). TLB is a cache that is designed specifically to store the mapping between physical and virtual pages. The first time some virtual address is mapped into a physical one this mapping is stored in TLB. Next time we need to access the same page we no longer need to perform full page table walk. Therefore it makes perfect sense that we invalidate TLB after updating page tables - otherwise our change will not be applied for the pages already stored in the TLB. Usually, we try to avoid using all caches for simplicity, but without TLB any memory access would become extremely inefficient, and I don't think that it is even possible to completely disable TLB. Besides, TLB doesn't add any other complexity to the OS, in spite of the fact that we must clean it after switching ttbr0_el1 . Mapping a virtual page to user We have seen previously how allocate_user_page function is used - now it is time to see what is inside it. unsigned long allocate_user_page(struct task_struct *task, unsigned long va) { unsigned long page = get_free_page(); if (page == 0) { return 0; } map_page(task, va, page); return page + VA_START; } This function allocates a new page, maps it to the provided virtual address and returns a pointer to the page. When we say \"a pointer\" now we need to distinguish between 3 things: a pointer to a physical page, a pointer inside kernel address space and a pointer inside user address space - all these 3 different pointers can lead to the same location in memory. In our case page variable is a physical pointer (note its \"unsigned long\" type -- not a C pointer!) and the return value is a pointer inside kernel address space. This pointer can be easily calculated because we linearly map the whole physical memory starting at VA_START virtual address. Through the pointer, our kernel copies the user program to the page. Does our kernel have a virtual mapping for the new page? We do not have to worry, because kernel maps the entire physical memory in boot.S . User mapping is still required to be created and this happens in the map_page function, which we will explore next. void map_page(struct task_struct *task, unsigned long va, unsigned long page){ unsigned long pgd; if (!task->mm.pgd) { task->mm.pgd = get_free_page(); task->mm.kernel_pages[++task->mm.kernel_pages_count] = task->mm.pgd; } pgd = task->mm.pgd; int new_table; unsigned long pud = map_table((unsigned long *)(pgd + VA_START), PGD_SHIFT, va, &new_table); if (new_table) { task->mm.kernel_pages[++task->mm.kernel_pages_count] = pud; } unsigned long pmd = map_table((unsigned long *)(pud + VA_START) , PUD_SHIFT, va, &new_table); if (new_table) { task->mm.kernel_pages[++task->mm.kernel_pages_count] = pmd; } unsigned long pte = map_table((unsigned long *)(pmd + VA_START), PMD_SHIFT, va, &new_table); if (new_table) { task->mm.kernel_pages[++task->mm.kernel_pages_count] = pte; } map_table_entry((unsigned long *)(pte + VA_START), va, page); struct user_page p = {page, va}; task->mm.user_pages[task->mm.user_pages_count++] = p; } map_page in some way duplicates what we've been doing in the __create_page_tables function: it allocates and populates a page table hierarchy. There are 3 important difference, however: now we are doing this in C, instead of assembler. map_page maps a single page, instead of the whole memory, and use normal page mapping, instead of section mapping. There are 2 important functions involved in the process: map_table and map_table_entry . map_table is listed below. unsigned long map_table(unsigned long *table, unsigned long shift, unsigned long va, int* new_table) { unsigned long index = va >> shift; index = index & (PTRS_PER_TABLE - 1); if (!table[index]){ *new_table = 1; unsigned long next_level_table = get_free_page(); unsigned long entry = next_level_table | MM_TYPE_PAGE_TABLE; table[index] = entry; return next_level_table; } else { *new_table = 0; } return table[index] & PAGE_MASK; } This function has the following arguments. table This is a pointer to the parent page table. This page table is assumed to be already allocated, but might be empty. shift This argument is used to extract table index from the provided virtual address. va Virtual address itself. new_table This is an output parameter. It is set to 1 if a new child table has been allocated and left 0 otherwise. You can think of this function as an analog of the create_table_entry macro. It extracts table index from the virtual address and prepares a descriptor in the parent table that points to the child table. Unlike create_table_entry macro we don't assume that the child table should be adjacent into memory with the parent table - instead, we rely on get_free_table function to return whatever page is available. It also might be the case that child table was already allocated (This might happen if child page table covers the region where another page has been allocated previously.). In this case we set new_table to 0 and read child page table address from the parent table. map_page calls map_table 3 times: once for PGD, PUD and PMD. The last call allocates PTE and sets a descriptor in the PMD. Next, map_table_entry is called. You can see this function below. void map_table_entry(unsigned long *pte, unsigned long va, unsigned long pa) { unsigned long index = va >> PAGE_SHIFT; index = index & (PTRS_PER_TABLE - 1); unsigned long entry = pa | MMU_PTE_FLAGS; pte[index] = entry; } map_table_entry extracts PTE index from the virtual address and then prepares and sets PTE descriptor. It is similar to what we've been doing in the create_block_map macro. That's it about user page tables allocation, but map_page is responsible for one more important role: it keeps track of the pages that have been allocated during the process of virtual address mapping. All such pages are stored in the kernel_pages array. We need this array to be able to clean up allocated pages after a task exits. There is also user_pages array, which is also populated by the map_page function. This array store information about the correspondence between process virtual pages any physical pages. We need this information in order to be able to copy process virtual memory during fork (More on this later). Forking a user process Let's summarize where we are so far: we've seen how first user process is created, its page tables populated, code & data copied to the proper location and stack initialized. After all of this preparation, the process is ready to run. The code that is executed inside user process is listed below. void loop(char* str) { char buf[2] = {\"\"}; while (1){ for (int i = 0; i < 5; i++){ buf[0] = str[i]; call_sys_write(buf); user_delay(1000000); } } } void user_process() { call_sys_write(\"User process\\n\\r\"); int pid = call_sys_fork(); if (pid < 0) { call_sys_write(\"Error during fork\\n\\r\"); call_sys_exit(); return; } if (pid == 0){ loop(\"abcde\"); } else { loop(\"12345\"); } } The familiar fork() semantics The code itself is very simple as we expect. Unlike clone , when doing fork we don't need to provide the function that needs to be executed in a new process. Also, the fork wrapper function is much easier than the clone one. All of this is possible because of the fact that fork make a full copy of the process virtual address space, so the fork wrapper function return twice: one time in the original process and one time in the new one. At this point, we have two identical processes, with identical stacks and pc positions. The only difference is the return value of the fork syscall: it returns child PID in the parent process and 0 in the child process. Starting from this point both processes begin completely independent life and can modify their stacks and write different things using same addresses in memory - all of this without affecting one another. Implementation Now let's see how fork system call is implemented. copy_process function does most of the job. int copy_process(unsigned long clone_flags, unsigned long fn, unsigned long arg) { preempt_disable(); struct task_struct *p; unsigned long page = allocate_kernel_page(); p = (struct task_struct *) page; struct pt_regs *childregs = task_pt_regs(p); if (!p) return -1; if (clone_flags & PF_KTHREAD) { p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; } else { struct pt_regs * cur_regs = task_pt_regs(current); *childregs = *cur_regs; childregs->regs[0] = 0; copy_virt_memory(p); } p->flags = clone_flags; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->preempt_count = 1; //disable preemtion until schedule_tail p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)childregs; int pid = nr_tasks++; task[pid] = p; preempt_enable(); return pid; } This function looks almost exactly the same as in the previous lesson with one exception: when copying user processes, now, instead of modifying new process stack pointer and program counter, we instead call copy_virt_memory . copy_virt_memory looks like this. int copy_virt_memory(struct task_struct *dst) { struct task_struct* src = current; for (int i = 0; i < src->mm.user_pages_count; i++) { unsigned long kernel_va = allocate_user_page(dst, src->mm.user_pages[i].virt_addr); if( kernel_va == 0) { return -1; } memcpy(kernel_va, src->mm.user_pages[i].virt_addr, PAGE_SIZE); } return 0; } It iterates over user_pages array, which contains all pages, allocated by the current process. Note, that in user_pages array we store only pages that are actually available to the process and contain its source code or data; we don't include here page table pages, which are stored in kernel_pages array. Next, for each page, we allocate another empty page and copy the original page content there. We also map the new page using the same virtual address, that is used by the original one. This is how we get the exact copy of the original process address space. All other details of the forking procedure work exactly in the same way, as they have been in the previous lesson. Q: does our fork() implement COW? Demand paging If you go back and take a look at the move_to_user_mode function, you may notice that we only map a single page, starting at offset 0. But we also assume that the second page will be used as a stack. Our kernel will map stack page, as well as any other page that a process needs to access as soon as it will be requested for the first time. Now we are going to explore the inner-workings of this mechanism. Setting up page faults When a process tries to access some address which belongs to the page that is not yet mapped, a synchronous exception is generated. This is the second type of synchronous exception that we are going to support (the first type is an exception generated by the svc instruction which is a system call). Synchronous exception handler now looks like the following. el0_sync: kernel_entry 0 mrs x25, esr_el1 // read the syndrome register lsr x24, x25, #ESR_ELx_EC_SHIFT // exception class cmp x24, #ESR_ELx_EC_SVC64 // SVC in 64-bit state b.eq el0_svc cmp x24, #ESR_ELx_EC_DABT_LOW // data abort in EL0 b.eq el0_da handle_invalid_entry 0, SYNC_ERROR Here we use esr_el1 register to determine exception type. If it is a page fault exception (or, which is the same, data access exception) el0_da function is called. el0_da: bl enable_irq mrs x0, far_el1 mrs x1, esr_el1 bl do_mem_abort cmp x0, 0 b.eq 1f handle_invalid_entry 0, DATA_ABORT_ERROR 1: bl disable_irq kernel_exit 0 el0_da redirects the main work to the do_mem_abort function. This function takes two arguments 1. The memory address which we tried to access. This address is taken from far_el1 register (Fault address register) 1. The content of the esr_el1 (Exception syndrome register) Handling page faults do_mem_abort is listed below. int do_mem_abort(unsigned long addr, unsigned long esr) { unsigned long dfs = (esr & 0b111111); if ((dfs & 0b111100) == 0b100) { unsigned long page = get_free_page(); if (page == 0) { return -1; } map_page(current, addr & PAGE_MASK, page); ind++; if (ind > 2){ return -1; } return 0; } return -1; } In order to understand this function, you need to know a little bit about the specifics of that esr_el1 register. Bits [32:26] of this register are called \"Exception Class\". We check those bits in the el0_sync handler to determine whether it is a syscall, or a data abort exception or potentially something else. Exception class determines the meaning of bits [24:0] - those bits are usually used to provide additional information about the exception. The meaning of [24:0] bits in case of the data abort exception is described on the page 2460 of the AArch64-Reference-Manual . In general, data abort exception can happen in many different scenarios (it could be a permission fault, or address size fault or a lot of other things). We are only interested in a translation fault which happens when some of the page tables for the current virtual address are not initialized. So in the first 2 lines of the do_mem_abort function, we check whether the current exception is actually a translation fault. If yes we allocate a new page and map it to the requested virtual address. All of this happens completely transparent for the user program - it doesn't notice that some of the memory accesses were interrupted and new page tables were allocated in the meantime. Conclusion This was a long and difficult chapter, but I hope it was useful as well. Virtual memory is really one of the most fundamental pieces of any operating system and I am glad we've passed through this chapter and, hopefully, started to understand how it works at the lowest level. With the introduction of virtual memory we now have full process isolation, but the RPi OS is still far from completion. It still doesn't support file systems, drivers, signals and interrupt waitlists, networking and a lot of other useful concepts, and we will continue to uncover them in the upcoming lessons.","title":"exp6"},{"location":"lesson06/rpi-os/#6-virtual-memory-vm","text":"","title":"6: Virtual memory (VM)"},{"location":"lesson06/rpi-os/#objectives","text":"Make our tiny kernel capable of: enforcing separate virtual address spaces, and user-level demand paging.","title":"Objectives"},{"location":"lesson06/rpi-os/#roadmap","text":"Source code location: p1-kernel/src/lesson06 Prior to this experiment, our kernel can run and schedule user processes, but the isolation between them is not complete - all processes and the kernel itself share the same memory. This allows any process to easily access somebody else's data and even kernel data. And even if we assume that all our processes are not malicious, there is another drawback: before allocating memory each process need to know which memory regions are already occupied - this makes memory allocation for a process more complicated. We take the following steps. Set up a pgtable for kernel. Using linear mapping. Turn on MMU shortly after kernel boots. This is a common kernel design. Set up pgtables for user processes Implement fork() for user processes Implement demand paging","title":"Roadmap"},{"location":"lesson06/rpi-os/#background-arm64-translation-process","text":"The Arm's document is well written. (\"Armv8-A Address Translation\", link )","title":"Background: ARM64 translation process"},{"location":"lesson06/rpi-os/#page-table-format","text":"This experiment introduces VM to our kernel. With VM, we can formally call tasks \"processes\". Each task will have its own address space. They issue memory access with virtual addresses. The MMU transparently translates virtual addresses to physical addresses. The MMU uses page table (or pgtable, or \"translation table\" in ARM's manual). The following diagram summarizes ARM64 address translation with uses 4-level pgtables. Virtual address Physical Memory +-----------------------------------------------------------------------+ +-----------------_+ | | PGD Index | PUD Index | PMD Index | PTE Index | Page offset | | | +-----------------------------------------------------------------------+ | | 63 47 | 38 | 29 | 20 | 11 | 0 | Page N | | | | | +--------------------+ +---->+------------------+ | | | +---------------------+ | | | | +------+ | | | | | | | | | +----------+ | | | |------------------| +------+ | PGD | | | +---------------->| Physical address | |TTBRx |---->+-------------+ | PUD | | | |------------------| +-EL1--+ | | entry #511 | | +->+-------------+ | PMD | | | | | +-------------+ | | | #511 | | +->+-------------+ | PTE | +------------------+ +->| PUD address |----+ +-------------+ | | | #511 | | +->+--------------+ | | | +-------------+ +--->| PMD address |----+ +-------------+ | | | #511 | | | | | entry #0 | +-------------+ +--->| PTE address |----+ +-------------_+ | | | +-------------+ | #0 | +-------------+ +--->| Page address |----+ | | +-------------+ | #0 | +--------------+ | | +-------------+ | #0 | | | +--------------+ +------------------+ Notable points: Page tables have a hierarchical structure, i.e. a tree. An item in any of the tables contains an address of the next table in the hierarchy. Note: strictly speaking a pgtable means a contiguous array of entries at any of the four levels. So a tree has many pgtables. Some documents casually use \"pgtable\" to refer to an entire pgtable tree. Be careful. There are 4 levels in the table hierarchy: PGD (Page Global Directory), PUD (Page Upper Directory), PMD (Page Middle Directory), PTE (Page Table Entry). PTE is the last table in the hierarchy and it points to the actual page in the physical memory. Don't read too much into the terms, which just represent lv1, 2, ... pgtables. Them terms come from the Linux kernel (x86), not ARM64. Over years, they became a common lingo among kernel hackers. Besides holding a physical address, each pgtable item holds extra bits crucial for translation. Will examine the format below. MMU starts memory translation process by locating the base address of PGD. MMU locates the base address from the TTBRx_EL1 register which should be set by the kernel. TTBR = translation table base register. bits [63-47] = 0xffff (all 1s). MMU uses ttbr1_el1 . This is meant for the kernel space. bits [63-47] = 0x0 (all 1s). MMU uses ttbr0_el1 . This is meant for the user process. Each process has its own address space. Therefore, it has its own copy of page table tree, starting from PGD. Therefore, the kernel keeps a separate PGD base address for each process. That is, the kernel virtualizes PGD for processes. During a context switch, the kernel loads the PGD base of the next process to ttbr0_el1 . MMU walks the pgtable tree to look up the physical address. A virtual address uses only 48 out of 64 available bits. When doing a translation, MMU splits an address into 4 parts: 9 bits [39 - 47] contain an index in the PGD table. MMU uses this index to find the location of the PUD. 9 bits [30 - 38] contain an index in the PUD table. MMU uses this index to find the location of the PMD. 9 bits [21 - 29] contain an index in the PMD table. MMU uses this index to find the location of the PTE. 9 bits [12 - 20] contain an index in the PTE table. MMU uses this index to find a page in the physical memory. Bits [0 - 11] contain an offset in the physical page. MMU uses this offset to determine the exact position in the previously found page that corresponds to the original virtual address. Memory for a user process is always allocated in pages. A page is a contiguous memory region 4KB in size (ARM processors support larger pages, but 4KB is the most common case and we are going to limit our discussion only to this page size). Exercise: how large is a page table? From the diagram above we know that index in a page table occupies 9 bits (this is true for all page table levels). This means that each page table contains 2^9 = 512 items. Each item in a page table is an address of either the next page table in the hierarchy or a physical page in case of PTE. As we are using a 64-bit processor, each address must be 64 bit or 8 bytes in size. This means that each pgtable is 512 * 8 = 4096 bytes or 4 KB. A pgtable is exactly a page! This might give you an intuition why MMU designers chose such numbers.","title":"Page table format"},{"location":"lesson06/rpi-os/#section-2mb-mapping","text":"This is specific to ARM64 for mapping large, continuous physical memory. Instead of 4 KB pages, we directly map 2MB blocks called sections. This eliminates one level of translation. The translation diagram, in this case, looks like the following. Virtual address Physical Memory +-----------------------------------------------------------------------+ +-----------------_+ | | PGD Index | PUD Index | PMD Index | Section offset | | | +-----------------------------------------------------------------------+ | | 63 47 | 38 | 29 | 20 | 0 | Section N | | | | | +---->+------------------+ | | | | | | | +------+ | | | | | | | | +----------+ | | |------------------| +------+ | PGD | | +------------------------->| Physical address | | TTBRx|---->+-------------+ | PUD | | |------------------| +--EL1-+ | | | | +->+-------------+ | PMD | | | | +-------------+ | | | | | +->+-----------------+ | +------------------+ +->| PUD address |----+ +-------------+ | | | | | | | +-------------+ +--->| PMD address |----+ +-----------------+ | | | | | +-------------+ +--->| Section address |-----+ | | +-------------+ | | +-----------------+ | | +-------------+ | | | | +-----------------+ | | +------------------+ As you can see the difference here is that now PMD contains a pointer to the physical section. Also, the offset occupies 21 bits instead of 12 bits (this is because we need 21 bits to encode a 2MB range)","title":"Section (2MB) mapping"},{"location":"lesson06/rpi-os/#page-descriptor-format","text":"An item in a page table is called \"descriptor\". A description has a special format as mandated by MMU hardware. A descriptor contains an address of either next page table or a physical page. The key thing to understand : each descriptor always points to something that is page-aligned (either a physical page, a section or the next page table in the hierarchy). This means that last 12 bits of the address, stored in a descriptor, will always be 0. MMU uses those bits to store additional information (\"attributes\") for translation. Descriptor format `+------------------------------------------------------------------------------------------+ | Upper attributes | Address (bits 47:12) | Lower attributes | Block/table bit | Valid bit | +------------------------------------------------------------------------------------------+ 63 47 11 2 1 0 Bit 0 This bit must be set to 1 for all valid descriptors. If MMU encounter non-valid descriptor during translation process a synchronous exception is generated. If this invalid bit was set by kernel on purpose, the kernel shall handle this exception, allocate a new page, and prepare a correct descriptor (We will look in details on how this works a little bit later) Bit 1 This bit indicates whether the current descriptor points to a next page table in the hierarchy (we call such descriptor a \" table descriptor \") or it points instead to a physical page or a section (such descriptors are called \" block descriptors \"). Bits [11:2] Those bits are ignored for table descriptors. For block descriptors they contain some attributes that control, for example, whether the mapped page is readable/writeable (AP), executable (XN), etc. Here also comes the MemAttr bits. See below. Bits [47:12] . This is the place where the address that a descriptor points to is stored. As I mentioned previously, only bits [47:12] of the address need to be stored, because all other bits are always 0. Bits [63:48] Another set of attributes. See Arm's official page .","title":"Page descriptor format"},{"location":"lesson06/rpi-os/#configuring-page-attributes","text":"As I mentioned in the previous section, each block descriptor contains a set of attributes (called MemAttr, bits[5:2]) that controls various virtual page parameters, notably cacheability or shareability. However, the attributes that are most important for our discussion are NOT encoded in the descriptor. Instead, ARM processors implement a trick for compressing descriptor attributes commonly used. (The days of simpler ARM hardware were gone) Memory attribute indirection ARMv8 architecture introduces mair_el1 register. See its definition . This register consists of 8 slots, each spanning 8 bits. Each slot configures a common set of attributes. A descriptor then specifies just an index of the mair slot, instead of specifying all attributes directly. This allows using only 3 bits in the descriptor to reference a mair slot. We are using only a few of available attribute options. Here is the code that prepares values for the mair register. /* * Memory region attributes: * * n = AttrIndx[2:0] * n MAIR * DEVICE_nGnRnE 000 00000000 * NORMAL_NC 001 01000100 */ #define MT_DEVICE_nGnRnE 0x0 #define MT_NORMAL_NC 0x1 #define MT_DEVICE_nGnRnE_FLAGS 0x00 #define MT_NORMAL_NC_FLAGS 0x44 #define MAIR_VALUE (MT_DEVICE_nGnRnE_FLAGS << (8 * MT_DEVICE_nGnRnE)) | (MT_NORMAL_NC_FLAGS << (8 * MT_NORMAL_NC)) Here we are using only 2 out of 8 available slots in the mair registers. The first one corresponds to device memory (IO registers) and second to normal non-cacheable memory. MT_DEVICE_nGnRnE and MT_NORMAL_NC are indexes that we are going to use in block descriptors, MT_DEVICE_nGnRnE_FLAGS and MT_NORMAL_NC_FLAGS are values that we are storing in the first 2 slots of the mair_el1 register.","title":"Configuring page attributes"},{"location":"lesson06/rpi-os/#kernel-vs-user-virtual-memory","text":"After the MMU is switched on, each memory access issued by kernel must use virtual address instead of physical. One consequence is that the kernel itself must maintain its own set of page tables. One possible solution could be to reload ttbr (pointing to the PGD base) each time we switch from user to kernel mode. Reloading ttbr can be costly. (Why?) This makes syscalls and page faults expensive. Commodity kernels therefore avoid frequent reloads of PGD base. A kernel splits the virtual address space into 2 parts: user portion and kernel portion. When switching among user tasks, the kernel only changes the mapping of the user portion while keeping the kernel mapping unchanged. This classic kernel design turns out to lead to most severe security holes in recent years. Google \"spectre and meltdown\". On 32-bit CPUs, a kernel usually allocate first 3 GB of the address space for user and reserve last 1 GB for the kernel. 64-bit architectures are much more favorable in this regard because of huge virtual address space (how large?). And even more: ARMv8 architecture comes with a native feature that can be used to easily implement user/kernel address split. ARM64 defines 2 TTBR registers for holding PGD base addresses: TTBR0_EL1 points to a user PGD; TTBR1_EL1 points to the kernel PGD. MMU uses only 48 bits out of 64 bits in the virtual addresses for translation. MMU uses the upper 16 bits in a given virtual address to decide whether it uses TTBR0 or TTBR1. User virtual addresses : upper 16 bits == 0. MMU uses the PGD base stored in TTBR0_EL1. This value shall be changed according to process switch. Kernel virtual addresses : upper 16 bits == 0xffff . MMU uses the PGD base stored in TTBR1_EL1. This value shall remain unchanged throughout the life of the kernel. The CPU also enforces that software at EL0 can never access virtual addresses started with 0xffff . Doing so triggers a synchronous exception. Here is a picture the memory layout. Source: Arm's document \"ARMv8-A Address Translation\".","title":"Kernel vs user virtual memory"},{"location":"lesson06/rpi-os/#adjusting-kernel-addresses","text":"All absolute kernel addresses must start with 0xffff... . There are 2 places in the kernel source code shall be changed. In the linker script we specify base address of the image as 0xffff000000000000 . This will make the linker think that our image is going to be loaded at 0xffff000000000000 address, and therefore whenever it needs to generate an absolute address it will make it right. (There are a few more changes to the linker script, but we will discuss them later.) We hardcode absolute kernel base addresses in the header where we define device base address. After switching on MMU, kernel has to access all IO via virtual addresses. We can map them starting from 0xffff00003F000000 . In the next section we will explore in detail the code that creates this mapping.","title":"Adjusting kernel addresses"},{"location":"lesson06/rpi-os/#kernel-boot-initializing-kernel-page-tables","text":"Important: the linker is completely oblivious to kernel physical address , e.g. the physical base (0x0 or 0x80000) where the kernel will be loaded. Two Implications: the linker links all kernel symbols at virtual addresses starting from 0xffff000000000000 ; Before kernel boots and before it turns on MMU, the kernel will operate on physical addresses starting from 0x0 (or 0x80000 for QEMU). Keep this key constraint in mind. See below. Right after kernel switches to EL1 and clears the BSS, the kernel populates its pgtables via __create_page_tables function. // boot.S __create_page_tables: mov x29, x30 // save return address First, the function saves x30 (LR). As we are going to call other functions from __create_page_tables , x30 will be overwritten. As we know that no code will use x29 during __create_page_tables execution, preserving LR in x29 works fine. Q: What could go wrong if we push x30 to stack here? adrp x0, pg_dir // adrp: form PC-relative address to 4KB page mov x1, #PG_DIR_SIZE bl memzero Next, we clear the initial page tables area. An important thing to understand here is where this area is located (x0) and how do we know its size (x1)? Initial page tables area is defined in the linker script - this means that we are allocating the spot for this area in the kernel image itself. Calculating the size of this area is a little bit trickier. First, we need to understand the structure of the initial kernel page tables. We know that all our mappings are all inside 1 GB region (this is the size of RPi3 physical memory). One PGD descriptor can cover 2^39 = 512 GB and one PUD descriptor can cover 2^30 = 1 GB of continuous virtual mapping area. (Those values are calculated based on the PGD and PUD indexes location in the virtual address.) This means that we need just one PGD and one PUD to map the whole RPi memory, and even more - both PGD and PUD will contain a single descriptor (of course we still need to allocate at least one page for them each). If we have a single PUD entry there also must be a single PMD table, to which this entry will point. (Single PMD entry covers 2 MB, there are 512 items in a PMD, so in total the whole PMD table covers the same 1 GB of memory that is covered by a single PUD descriptor.) Next, we know that we need to map 1 GB region of memory, which is a multiple of 2 MB. This allows us to keep things simple -- using section mapping. This means that we don't need PTE at all. So in total, we need 3 pages: one for PGD, PUD and PMD - this is precisely the size of the initial page table area. Q: here, MMU is off and everything should be physical address. How could the kernel possibly address functions/variables like memzero, which are linked at virtual addresses? (Hint: check the disassembly of the kernel binary)","title":"Kernel boot: initializing kernel page tables"},{"location":"lesson06/rpi-os/#allocating-installing-a-new-pgtable","text":"Now we are going to step outside __create_page_tables function and take a look on 2 essential macros: create_table_entry and create_block_map . create_table_entry is responsible for allocating a new page table (In our case either PGD or PUD) The source code is listed below. .macro create_table_entry, tbl, virt, shift, tmp1, tmp2 lsr \\tmp1, \\virt, #\\shift and \\tmp1, \\tmp1, #PTRS_PER_TABLE - 1 // table index add \\tmp2, \\tbl, #PAGE_SIZE orr \\tmp2, \\tmp2, #MM_TYPE_PAGE_TABLE str \\tmp2, [\\tbl, \\tmp1, lsl #3] add \\tbl, \\tbl, #PAGE_SIZE // next level table page .endm This macro accepts the following arguments. tbl - a pointer to a memory region where new table has to be allocated. virt - virtual address that we are currently mapping. shift - shift that we need to apply to the virtual address in order to extract current table index. (39 in case of PGD and 30 in case of PUD) tmp1 , tmp2 - temporary registers. This macro is very important, so we are going to spend some time understanding it. lsr \\tmp1, \\virt, #\\shift and \\tmp1, \\tmp1, #PTRS_PER_TABLE - 1 // table index The first two lines of the macro are responsible for extracting table index from the virtual address. We are applying right shift first to strip everything to the right of the index and then using and operation to strip everything to the left. add \\tmp2, \\tbl, #PAGE_SIZE Then the address of the next page table is calculated. Here we are using the convention that all our initial page tables are located in one continuous memory region. We simply assume that the next page table in the hierarchy will be adjacent to the current page table. orr \\tmp2, \\tmp2, #MM_TYPE_PAGE_TABLE Next, a pointer to the next page table in the hierarchy is converted to a table descriptor. (A descriptor must have 2 lower bits set to 1 ) str \\tmp2, [\\tbl, \\tmp1, lsl #3] Then the descriptor is stored in the current page table. We use previously calculated index to find the right spot in the table. add \\tbl, \\tbl, #PAGE_SIZE // next level table page Finally, we change tbl parameter to point to the next page table in the hierarchy. This is convenient because now we can call create_table_entry one more time for the next table in the hierarchy without making any adjustments to the tbl parameter. This is precisely what we are doing in the create_pgd_entry macro, which is just a wrapper that allocates both PGD and PUD.","title":"Allocating &amp; installing a new pgtable"},{"location":"lesson06/rpi-os/#populating-a-pmd-table","text":"Next important macro is create_block_map . As you might guess this macro is responsible for populating entries of the PMD table. It looks like the following. .macro create_block_map, tbl, phys, start, end, flags, tmp1 lsr \\start, \\start, #SECTION_SHIFT and \\start, \\start, #PTRS_PER_TABLE - 1 // table index lsr \\end, \\end, #SECTION_SHIFT and \\end, \\end, #PTRS_PER_TABLE - 1 // table end index lsr \\phys, \\phys, #SECTION_SHIFT mov \\tmp1, #\\flags orr \\phys, \\tmp1, \\phys, lsl #SECTION_SHIFT // table entry 9999: str \\phys, [\\tbl, \\start, lsl #3] // store the entry add \\start, \\start, #1 // next entry add \\phys, \\phys, #SECTION_SIZE // next block cmp \\start, \\end b.ls 9999b .endm Parameters here are a little bit different. tbl - a pointer to the PMD table. phys - the start of the physical region to be mapped. start - virtual address of the first section to be mapped. end - virtual address of the last section to be mapped. flags - flags that need to be copied into lower attributes of the block descriptor. tmp1 - temporary register. Now, let's examine the source. lsr \\start, \\start, #SECTION_SHIFT and \\start, \\start, #PTRS_PER_TABLE - 1 // table index Those 2 lines extract the table index from start virtual address. This is done exactly in the same way as we did it before in the create_table_entry macro. lsr \\end, \\end, #SECTION_SHIFT and \\end, \\end, #PTRS_PER_TABLE - 1 // table end index The same thing is repeated for the end address. Now both start and end contains not virtual addresses, but indexes in the PMD table, corresponding to the original addresses. lsr \\phys, \\phys, #SECTION_SHIFT mov \\tmp1, #\\flags orr \\phys, \\tmp1, \\phys, lsl #SECTION_SHIFT // table entry Next, block descriptor is prepared and stored in the tmp1 variable. In order to prepare the descriptor phys parameter is first shifted to right then shifted back and merged with the flags parameter using orr instruction. If you wonder why do we have to shift the address back and forth - the answer is that this clears first 21 bit in the phys address and makes our macro universal, allowing it to be used with any address, not just the first address of the section. 9999: str \\phys, [\\tbl, \\start, lsl #3] // store the entry add \\start, \\start, #1 // next entry add \\phys, \\phys, #SECTION_SIZE // next block cmp \\start, \\end b.ls 9999b // jump back if \"Unsigned Less than or equal\" The final part of the function is executed inside a loop. Here we first store current descriptor at the right index in the PMD table. Next, we increase current index by 1 and update the descriptor to point to the next section. We repeat the same process until current index becomes equal to the last index.","title":"Populating a PMD table"},{"location":"lesson06/rpi-os/#putting-it-together-__create_page_tables","text":"Now, when you understand how create_table_entry and create_block_map macros work, it will be straightforward to understand the rest of the __create_page_tables function. adrp x0, pg_dir mov x1, #VA_START create_pgd_entry x0, x1, x2, x3 Here we create both PGD and PUD. We configure them to start mapping from VA_START virtual address. Because of the semantics of the create_table_entry macro, after create_pgd_entry finishes x0 will contain the address of the next table in the hierarchy - namely PMD. /* Mapping kernel and init stack*/ mov x1, xzr // start mapping from physical offset 0 mov x2, #VA_START // first virtual address ldr x3, =(VA_START + DEVICE_BASE - SECTION_SIZE) // last virtual address create_block_map x0, x1, x2, x3, MMU_FLAGS, x4 Next, we create virtual mapping of the whole memory, excluding device registers region. We use MMU_FLAGS constant as flags parameter - this marks all sections to be mapped as normal noncacheable memory. (Note, that MM_ACCESS flag is also specified as part of MMU_FLAGS constant. Without this flag each memory access will generate a synchronous exception.) /* Mapping device memory*/ mov x1, #DEVICE_BASE // start mapping from device base address ldr x2, =(VA_START + DEVICE_BASE) // first virtual address ldr x3, =(VA_START + PHYS_MEMORY_SIZE - SECTION_SIZE) // last virtual address create_block_map x0, x1, x2, x3, MMU_DEVICE_FLAGS, x4 Then device registers region is mapped. This is done exactly in the same way as in the previous code sample, with the exception that we are now using different start and end addresses and different flags. mov x30, x29 // restore return address ret Finally, the function restored link register and returns to the caller.","title":"Putting it together: __create_page_tables()"},{"location":"lesson06/rpi-os/#configuring-page-translation","text":"Now page tables are created and we are back to the el1_entry function. But there is still some work to be done before we can switch on the MMU. mov x0, #VA_START add sp, x0, #LOW_MEMORY We are updating init task stack pointer. Now it uses a virtual address, instead of a physical one. Therefore it could be used only after MMU is on. Recall that our kernel uses linear mapping therefore an offset is simply applied. adrp x0, pg_dir msr ttbr1_el1, x0 ttbr1_el1 is updated to point to the previously populated PGD table. Q: Isn't pg_dir a virtual address (e.g. ffff000000083000) set by the linker? ttbr shall expect a physical address, right? How could this work? ldr x0, =(TCR_VALUE) msr tcr_el1, x0 tcr_el1 of Translation Control Register is responsible for configuring some general parameters of the MMU. (For example, here we configure that both kernel and user page tables should use 4 KB pages.) ldr x0, =(MAIR_VALUE) msr mair_el1, x0 We already discussed mair register in the \"Configuring page attributes\" section. Here we just set its value. ldr x2, =kernel_main mov x0, #SCTLR_MMU_ENABLED msr sctlr_el1, x0 // BOOM! br x2 msr sctlr_el1, x0 is the line where MMU is actually enabled. Now we can jump to the kernel_main function. From this moment onward kernel runs on virtual addresses completely. An interesting question is why can't we just execute br kernel_main instruction? Indeed, we can't. Before the MMU was enabled we have been working with physical memory, the kernel is loaded at a physical offset 0 - this means that current program counter (PC) is very close to 0. Switching on the MMU doesn't update PC. br kernel_main uses offset relative to the current PC and jumps to the place were kernel_main would have been if we don't turn on the MMU. Example: in generating the kernel binary, the linker starts from base address 0xffff000000000000 as controlled by our linker script. It assigns the instruction \"br kernel_main\" to address 0xffff000000000080; it assigns kernel_main to 0xffff000000003190. The instruction \"br kernel_main\" will be a relative jump, and will be emitted as \"br #0x3110\" (we can verify this by disassembling the kernel binary). At run time, when we reach \"br kernel_main\", PC is 0x80. Executing the instruction will update PC is to 0x3190. As MMU is on now, CPU fetches instruction at 0x3190 via MMU. A translation fault! ldr x2, =kernel_main does not suffer from the problem. CPU loads x2 with the link address of kernel_main , e.g. 0xffff000000003190. Different from br kernel_main which uses PC-based offset, br x2 jumps to an absolute address stored in x2 (this is called long jmp). Therefore, PC will be updated with the link address of kernel_main which can be translated via MMU. In other words, by executing a long jmp, we \"synchronize\" the PC value with virtual addresses. Another question: why ldr x2, =kernel_main itself must be executed before we turn on the MMU? The reason is that ldr also uses pc relative offset. See the manual . On my build, it emitted as ldr x2, #0x10c . So if we execute this instruction after MMU is on but before we \"synchronize\" PC, MMU will give another translation fault.","title":"Configuring page translation"},{"location":"lesson06/rpi-os/#compiling-loading-user-programs","text":"Commodity kernels load user programs as ELF from filesystems. We won't be building a filesystem or ELF loader in this experiment. As a workaround, we will embed user programs in the kernel binary at link time, and load them at run time. For easy loading, we will store the user program in a separate ELF section of the kernel binary. Here is the relevant section of the linker script that is responsible for doing this. . = ALIGN(0x00001000); user_begin = .; .text.user : { build/user* (.text) } .rodata.user : { build/user* (.rodata) } .data.user : { build/user* (.data) } .bss.user : { build/user* (.bss) } user_end = .; I made a convention: user level source code should be defined in C source files named as \"userXXX\". The linker script then can isolate all user related code in a continuous region, of which the start and end are marked with user_begin and user_end symbols. At run time, the kernel simply copies everything between user_begin and user_end to the newly allocated process address space, thus simulating loading a user program. A simple hack, but suffice for our current purpose.","title":"Compiling &amp; loading user programs"},{"location":"lesson06/rpi-os/#aside-our-user-symbol-addresses","text":"As user programs will be linked as part the kernel binary, the linker will place all user symbols (functions & variables) in the kernel's address space (0xffff000000000000 onwards). You can verify this by, e.g. nm kernel8.elf|grep \" user_\" . How could such user programs work? We rely on an assumption: our user programs are simple enough; they always address memory with register-relative offsets but not absolute address. You can verify this by disassembly. However, if our programs, e.g. call functions via pointers, the entailed long jmp will target absolute virtual address inside kernel and will trigger exception. This assumption can't go a long way. The right solution would be linking user programs and kernel separately. Right now there are 2 files that are compiled in the user region. user_sys.S This file contains definitions of the syscall wrapper functions. The RPi OS still supports the same syscalls as in the previous lesson, with the exception that now instead of clone syscall we are going to use fork syscall. The difference is that fork copies process virtual memory, and that is something we want to try doing. user.c User program source code. Almost the same as we've used in the previous lesson.","title":"Aside: our user symbol addresses"},{"location":"lesson06/rpi-os/#creating-first-user-process","text":"As it was the case in the previous lesson, move_to_user_mode function is responsible for creating the first user process. We call this function from a kernel thread. Here is how we do this. void kernel_process(){ printf(\"Kernel process started. EL %d\\r\\n\", get_el()); unsigned long begin = (unsigned long)&user_begin; unsigned long end = (unsigned long)&user_end; unsigned long process = (unsigned long)&user_process; int err = move_to_user_mode(begin, end - begin, process - begin); if (err < 0){ printf(\"Error while moving process to user mode\\n\\r\"); } } Now we need 3 arguments to call move_to_user_mode : a pointer to the beginning of the user code area, size of the area and offset of the startup function inside it. This information is calculated based on the previously discussed user_begin and user_end symbols (as global variables). move_to_user_mode function is listed below. int move_to_user_mode(unsigned long start, unsigned long size, unsigned long pc) { struct pt_regs *regs = task_pt_regs(current); regs->pstate = PSR_MODE_EL0t; regs->pc = pc; regs->sp = 2 * PAGE_SIZE; unsigned long code_page = allocate_user_page(current, 0); if (code_page == 0) { return -1; } memcpy(code_page, start, size); set_pgd(current->mm.pgd); return 0; } Now let's try to inspect in details what is going on here. struct pt_regs *regs = task_pt_regs(current); As it was the case in the previous lesson, we obtain a pointer to pt_regs area and set pstate , so that after kernel_exit we will end up in EL0. regs->pc = pc; pc now points to the offset of the startup function in the user region. regs->sp = 2 * PAGE_SIZE; We made a simple convention that our user program will not exceed 1 page in size. We allocate the second page to the stack. unsigned long code_page = allocate_user_page(current, 0); if (code_page == 0) { return -1; } allocate_user_page reserves 1 memory page and maps it to the virtual address, provided as a second argument. In the process of mapping it populates page tables, associated with the current process. We will investigate in details how this function works later in this chapter. memcpy(code_page, start, size); Next, we are going to copy the whole user region to the new address space (in the page that we have just mapped), starting from offset 0, so the offset in the user region will become an actual virtual address of the starting point. set_pgd(current->mm.pgd); Finally, we call set_pgd , which updates ttbr0_el1 register and thus activate cu4rrent process translation tables.","title":"Creating first user process"},{"location":"lesson06/rpi-os/#aside-tlb","text":"If you take a look at the set_pgd function you will see that after it sets ttbr0_el1 it also clears TLB (Translation lookaside buffer). TLB is a cache that is designed specifically to store the mapping between physical and virtual pages. The first time some virtual address is mapped into a physical one this mapping is stored in TLB. Next time we need to access the same page we no longer need to perform full page table walk. Therefore it makes perfect sense that we invalidate TLB after updating page tables - otherwise our change will not be applied for the pages already stored in the TLB. Usually, we try to avoid using all caches for simplicity, but without TLB any memory access would become extremely inefficient, and I don't think that it is even possible to completely disable TLB. Besides, TLB doesn't add any other complexity to the OS, in spite of the fact that we must clean it after switching ttbr0_el1 .","title":"Aside: TLB"},{"location":"lesson06/rpi-os/#mapping-a-virtual-page-to-user","text":"We have seen previously how allocate_user_page function is used - now it is time to see what is inside it. unsigned long allocate_user_page(struct task_struct *task, unsigned long va) { unsigned long page = get_free_page(); if (page == 0) { return 0; } map_page(task, va, page); return page + VA_START; } This function allocates a new page, maps it to the provided virtual address and returns a pointer to the page. When we say \"a pointer\" now we need to distinguish between 3 things: a pointer to a physical page, a pointer inside kernel address space and a pointer inside user address space - all these 3 different pointers can lead to the same location in memory. In our case page variable is a physical pointer (note its \"unsigned long\" type -- not a C pointer!) and the return value is a pointer inside kernel address space. This pointer can be easily calculated because we linearly map the whole physical memory starting at VA_START virtual address. Through the pointer, our kernel copies the user program to the page. Does our kernel have a virtual mapping for the new page? We do not have to worry, because kernel maps the entire physical memory in boot.S . User mapping is still required to be created and this happens in the map_page function, which we will explore next. void map_page(struct task_struct *task, unsigned long va, unsigned long page){ unsigned long pgd; if (!task->mm.pgd) { task->mm.pgd = get_free_page(); task->mm.kernel_pages[++task->mm.kernel_pages_count] = task->mm.pgd; } pgd = task->mm.pgd; int new_table; unsigned long pud = map_table((unsigned long *)(pgd + VA_START), PGD_SHIFT, va, &new_table); if (new_table) { task->mm.kernel_pages[++task->mm.kernel_pages_count] = pud; } unsigned long pmd = map_table((unsigned long *)(pud + VA_START) , PUD_SHIFT, va, &new_table); if (new_table) { task->mm.kernel_pages[++task->mm.kernel_pages_count] = pmd; } unsigned long pte = map_table((unsigned long *)(pmd + VA_START), PMD_SHIFT, va, &new_table); if (new_table) { task->mm.kernel_pages[++task->mm.kernel_pages_count] = pte; } map_table_entry((unsigned long *)(pte + VA_START), va, page); struct user_page p = {page, va}; task->mm.user_pages[task->mm.user_pages_count++] = p; } map_page in some way duplicates what we've been doing in the __create_page_tables function: it allocates and populates a page table hierarchy. There are 3 important difference, however: now we are doing this in C, instead of assembler. map_page maps a single page, instead of the whole memory, and use normal page mapping, instead of section mapping. There are 2 important functions involved in the process: map_table and map_table_entry . map_table is listed below. unsigned long map_table(unsigned long *table, unsigned long shift, unsigned long va, int* new_table) { unsigned long index = va >> shift; index = index & (PTRS_PER_TABLE - 1); if (!table[index]){ *new_table = 1; unsigned long next_level_table = get_free_page(); unsigned long entry = next_level_table | MM_TYPE_PAGE_TABLE; table[index] = entry; return next_level_table; } else { *new_table = 0; } return table[index] & PAGE_MASK; } This function has the following arguments. table This is a pointer to the parent page table. This page table is assumed to be already allocated, but might be empty. shift This argument is used to extract table index from the provided virtual address. va Virtual address itself. new_table This is an output parameter. It is set to 1 if a new child table has been allocated and left 0 otherwise. You can think of this function as an analog of the create_table_entry macro. It extracts table index from the virtual address and prepares a descriptor in the parent table that points to the child table. Unlike create_table_entry macro we don't assume that the child table should be adjacent into memory with the parent table - instead, we rely on get_free_table function to return whatever page is available. It also might be the case that child table was already allocated (This might happen if child page table covers the region where another page has been allocated previously.). In this case we set new_table to 0 and read child page table address from the parent table. map_page calls map_table 3 times: once for PGD, PUD and PMD. The last call allocates PTE and sets a descriptor in the PMD. Next, map_table_entry is called. You can see this function below. void map_table_entry(unsigned long *pte, unsigned long va, unsigned long pa) { unsigned long index = va >> PAGE_SHIFT; index = index & (PTRS_PER_TABLE - 1); unsigned long entry = pa | MMU_PTE_FLAGS; pte[index] = entry; } map_table_entry extracts PTE index from the virtual address and then prepares and sets PTE descriptor. It is similar to what we've been doing in the create_block_map macro. That's it about user page tables allocation, but map_page is responsible for one more important role: it keeps track of the pages that have been allocated during the process of virtual address mapping. All such pages are stored in the kernel_pages array. We need this array to be able to clean up allocated pages after a task exits. There is also user_pages array, which is also populated by the map_page function. This array store information about the correspondence between process virtual pages any physical pages. We need this information in order to be able to copy process virtual memory during fork (More on this later).","title":"Mapping a virtual page to user"},{"location":"lesson06/rpi-os/#forking-a-user-process","text":"Let's summarize where we are so far: we've seen how first user process is created, its page tables populated, code & data copied to the proper location and stack initialized. After all of this preparation, the process is ready to run. The code that is executed inside user process is listed below. void loop(char* str) { char buf[2] = {\"\"}; while (1){ for (int i = 0; i < 5; i++){ buf[0] = str[i]; call_sys_write(buf); user_delay(1000000); } } } void user_process() { call_sys_write(\"User process\\n\\r\"); int pid = call_sys_fork(); if (pid < 0) { call_sys_write(\"Error during fork\\n\\r\"); call_sys_exit(); return; } if (pid == 0){ loop(\"abcde\"); } else { loop(\"12345\"); } }","title":"Forking a user process"},{"location":"lesson06/rpi-os/#the-familiar-fork-semantics","text":"The code itself is very simple as we expect. Unlike clone , when doing fork we don't need to provide the function that needs to be executed in a new process. Also, the fork wrapper function is much easier than the clone one. All of this is possible because of the fact that fork make a full copy of the process virtual address space, so the fork wrapper function return twice: one time in the original process and one time in the new one. At this point, we have two identical processes, with identical stacks and pc positions. The only difference is the return value of the fork syscall: it returns child PID in the parent process and 0 in the child process. Starting from this point both processes begin completely independent life and can modify their stacks and write different things using same addresses in memory - all of this without affecting one another.","title":"The familiar fork() semantics"},{"location":"lesson06/rpi-os/#implementation","text":"Now let's see how fork system call is implemented. copy_process function does most of the job. int copy_process(unsigned long clone_flags, unsigned long fn, unsigned long arg) { preempt_disable(); struct task_struct *p; unsigned long page = allocate_kernel_page(); p = (struct task_struct *) page; struct pt_regs *childregs = task_pt_regs(p); if (!p) return -1; if (clone_flags & PF_KTHREAD) { p->cpu_context.x19 = fn; p->cpu_context.x20 = arg; } else { struct pt_regs * cur_regs = task_pt_regs(current); *childregs = *cur_regs; childregs->regs[0] = 0; copy_virt_memory(p); } p->flags = clone_flags; p->priority = current->priority; p->state = TASK_RUNNING; p->counter = p->priority; p->preempt_count = 1; //disable preemtion until schedule_tail p->cpu_context.pc = (unsigned long)ret_from_fork; p->cpu_context.sp = (unsigned long)childregs; int pid = nr_tasks++; task[pid] = p; preempt_enable(); return pid; } This function looks almost exactly the same as in the previous lesson with one exception: when copying user processes, now, instead of modifying new process stack pointer and program counter, we instead call copy_virt_memory . copy_virt_memory looks like this. int copy_virt_memory(struct task_struct *dst) { struct task_struct* src = current; for (int i = 0; i < src->mm.user_pages_count; i++) { unsigned long kernel_va = allocate_user_page(dst, src->mm.user_pages[i].virt_addr); if( kernel_va == 0) { return -1; } memcpy(kernel_va, src->mm.user_pages[i].virt_addr, PAGE_SIZE); } return 0; } It iterates over user_pages array, which contains all pages, allocated by the current process. Note, that in user_pages array we store only pages that are actually available to the process and contain its source code or data; we don't include here page table pages, which are stored in kernel_pages array. Next, for each page, we allocate another empty page and copy the original page content there. We also map the new page using the same virtual address, that is used by the original one. This is how we get the exact copy of the original process address space. All other details of the forking procedure work exactly in the same way, as they have been in the previous lesson. Q: does our fork() implement COW?","title":"Implementation"},{"location":"lesson06/rpi-os/#demand-paging","text":"If you go back and take a look at the move_to_user_mode function, you may notice that we only map a single page, starting at offset 0. But we also assume that the second page will be used as a stack. Our kernel will map stack page, as well as any other page that a process needs to access as soon as it will be requested for the first time. Now we are going to explore the inner-workings of this mechanism.","title":"Demand paging"},{"location":"lesson06/rpi-os/#setting-up-page-faults","text":"When a process tries to access some address which belongs to the page that is not yet mapped, a synchronous exception is generated. This is the second type of synchronous exception that we are going to support (the first type is an exception generated by the svc instruction which is a system call). Synchronous exception handler now looks like the following. el0_sync: kernel_entry 0 mrs x25, esr_el1 // read the syndrome register lsr x24, x25, #ESR_ELx_EC_SHIFT // exception class cmp x24, #ESR_ELx_EC_SVC64 // SVC in 64-bit state b.eq el0_svc cmp x24, #ESR_ELx_EC_DABT_LOW // data abort in EL0 b.eq el0_da handle_invalid_entry 0, SYNC_ERROR Here we use esr_el1 register to determine exception type. If it is a page fault exception (or, which is the same, data access exception) el0_da function is called. el0_da: bl enable_irq mrs x0, far_el1 mrs x1, esr_el1 bl do_mem_abort cmp x0, 0 b.eq 1f handle_invalid_entry 0, DATA_ABORT_ERROR 1: bl disable_irq kernel_exit 0 el0_da redirects the main work to the do_mem_abort function. This function takes two arguments 1. The memory address which we tried to access. This address is taken from far_el1 register (Fault address register) 1. The content of the esr_el1 (Exception syndrome register)","title":"Setting up page faults"},{"location":"lesson06/rpi-os/#handling-page-faults","text":"do_mem_abort is listed below. int do_mem_abort(unsigned long addr, unsigned long esr) { unsigned long dfs = (esr & 0b111111); if ((dfs & 0b111100) == 0b100) { unsigned long page = get_free_page(); if (page == 0) { return -1; } map_page(current, addr & PAGE_MASK, page); ind++; if (ind > 2){ return -1; } return 0; } return -1; } In order to understand this function, you need to know a little bit about the specifics of that esr_el1 register. Bits [32:26] of this register are called \"Exception Class\". We check those bits in the el0_sync handler to determine whether it is a syscall, or a data abort exception or potentially something else. Exception class determines the meaning of bits [24:0] - those bits are usually used to provide additional information about the exception. The meaning of [24:0] bits in case of the data abort exception is described on the page 2460 of the AArch64-Reference-Manual . In general, data abort exception can happen in many different scenarios (it could be a permission fault, or address size fault or a lot of other things). We are only interested in a translation fault which happens when some of the page tables for the current virtual address are not initialized. So in the first 2 lines of the do_mem_abort function, we check whether the current exception is actually a translation fault. If yes we allocate a new page and map it to the requested virtual address. All of this happens completely transparent for the user program - it doesn't notice that some of the memory accesses were interrupted and new page tables were allocated in the meantime.","title":"Handling page faults"},{"location":"lesson06/rpi-os/#conclusion","text":"This was a long and difficult chapter, but I hope it was useful as well. Virtual memory is really one of the most fundamental pieces of any operating system and I am glad we've passed through this chapter and, hopefully, started to understand how it works at the lowest level. With the introduction of virtual memory we now have full process isolation, but the RPi OS is still far from completion. It still doesn't support file systems, drivers, signals and interrupt waitlists, networking and a lot of other useful concepts, and we will continue to uncover them in the upcoming lessons.","title":"Conclusion"}]}